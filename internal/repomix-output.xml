This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
client/
  client_pool_test.go
  client_pool.go
  client_test.go
  client.go
  dual_agent_client_test.go
  dual_agent_client.go
  factory_test.go
  factory.go
  interface.go
  mock_client_pool.go
  mock_spire_client.go
  pool_interface.go
config/
  config_test.go
  config.go
hmac/
  hmac_test.go
  hmac.go
metrics/
  metrics.go
provider/
  provider_test.go
  provider.go
server/
  server_test.go
  server.go
version/
  version_test.go
  version.go
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="client/client_pool_test.go">
package client

import (
	"context"
	"fmt"
	"strings"
	"sync"
	"testing"
	"time"

	"github.com/golang/mock/gomock"
	"github.com/hashicorp/go-hclog"
	typesapi "github.com/spiffe/spire-api-sdk/proto/spire/api/types"
)

func TestNewClientPool(t *testing.T) {
	tests := []struct {
		name   string
		config PoolConfig
	}{
		{
			name: "with custom timeouts",
			config: PoolConfig{
				StaleTimeout:    5 * time.Minute,
				CleanupInterval: 1 * time.Minute,
			},
		},
		{
			name: "with zero timeouts uses defaults",
			config: PoolConfig{
				StaleTimeout:    0,
				CleanupInterval: 0,
			},
		},
		{
			name: "with negative timeouts uses defaults",
			config: PoolConfig{
				StaleTimeout:    -1 * time.Minute,
				CleanupInterval: -1 * time.Minute,
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			pool := NewClientPool(logger, tt.config)

			if pool == nil {
				t.Fatal("Expected pool to be created")
			}

			if pool.clients == nil {
				t.Error("Clients map should be initialized")
			}

			if tt.config.StaleTimeout <= 0 && pool.staleTimeout != 10*time.Minute {
				t.Error("Expected default stale timeout")
			}

			if tt.config.CleanupInterval <= 0 && pool.cleanupInterval != 1*time.Minute {
				t.Error("Expected default cleanup interval")
			}

			// Cleanup
			pool.Shutdown()
		})
	}
}

func TestClientPool_AcquireClient(t *testing.T) {
	tests := []struct {
		name            string
		config1         Config
		config2         Config
		expectSameKey   bool
		expectNewClient bool
	}{
		{
			name: "same config returns same client",
			config1: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
					{Type: "k8s", Value: "sa:test"},
				},
			},
			config2: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
					{Type: "k8s", Value: "sa:test"},
				},
			},
			expectSameKey:   true,
			expectNewClient: false,
		},
		{
			name: "different socket path creates new client",
			config1: Config{
				SpireSocketPath:   "/socket1",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
				},
			},
			config2: Config{
				SpireSocketPath:   "/socket2",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
				},
			},
			expectSameKey:   false,
			expectNewClient: true,
		},
		{
			name: "different trust domain creates new client",
			config1: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors:         []*typesapi.Selector{},
			},
			config2: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "test.org",
				Selectors:         []*typesapi.Selector{},
			},
			expectSameKey:   false,
			expectNewClient: true,
		},
		{
			name: "different selectors creates new client",
			config1: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
				},
			},
			config2: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:production"},
				},
			},
			expectSameKey:   false,
			expectNewClient: true,
		},
		{
			name: "selectors in different order but same content",
			config1: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "sa:test"},
					{Type: "k8s", Value: "ns:default"},
				},
			},
			config2: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
					{Type: "k8s", Value: "sa:test"},
				},
			},
			expectSameKey:   true,
			expectNewClient: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			pool := NewClientPool(logger, PoolConfig{})

			// Mock factory for creating clients
			mockClient1 := NewMockSpireClient(ctrl)
			mockClient1.EXPECT().Start(gomock.Any()).Return(nil).AnyTimes()
			mockClient1.EXPECT().Stop().Return(nil).AnyTimes() // Add Stop expectation

			mockClient2 := NewMockSpireClient(ctrl)
			mockClient2.EXPECT().Start(gomock.Any()).Return(nil).AnyTimes()
			mockClient2.EXPECT().Stop().Return(nil).AnyTimes() // Add Stop expectation

			// Inject test factory
			clientCount := 0
			pool.clientFactory = func(logger hclog.Logger, config Config) (SpireClient, error) {
				clientCount++
				if clientCount == 1 {
					return mockClient1, nil
				}
				return mockClient2, nil
			}

			ctx := context.Background()

			// Acquire first client
			client1, err1 := pool.AcquireClient(ctx, tt.config1)
			if err1 != nil {
				t.Fatalf("Failed to acquire first client: %v", err1)
			}

			// Acquire second client
			client2, err2 := pool.AcquireClient(ctx, tt.config2)
			if err2 != nil {
				t.Fatalf("Failed to acquire second client: %v", err2)
			}

			if tt.expectSameKey {
				if client1 != client2 {
					t.Error("Expected same client instance for same config")
				}
				if len(pool.clients) != 1 {
					t.Errorf("Expected 1 client in pool, got %d", len(pool.clients))
				}
			} else {
				if client1 == client2 {
					t.Error("Expected different client instances for different configs")
				}
				if len(pool.clients) != 2 {
					t.Errorf("Expected 2 clients in pool, got %d", len(pool.clients))
				}
			}

			// Cleanup
			pool.Shutdown()
		})
	}
}

func TestClientPool_ReleaseClient(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	pool := NewClientPool(logger, PoolConfig{})

	config := Config{
		SpireSocketPath:   "/socket",
		SpiffeTrustDomain: "example.org",
		Selectors: []*typesapi.Selector{
			{Type: "k8s", Value: "ns:default"},
		},
	}

	// Mock client
	mockClient := NewMockSpireClient(ctrl)
	mockClient.EXPECT().Start(gomock.Any()).Return(nil)
	mockClient.EXPECT().Stop().Return(nil).AnyTimes() // Add Stop expectation

	// Inject test factory
	pool.clientFactory = func(logger hclog.Logger, cfg Config) (SpireClient, error) {
		return mockClient, nil
	}

	ctx := context.Background()

	// Acquire client multiple times
	pool.AcquireClient(ctx, config)
	pool.AcquireClient(ctx, config)
	pool.AcquireClient(ctx, config)

	key := pool.buildClientKey(config)
	entry := pool.clients[key]
	if entry.refCount != 3 {
		t.Errorf("Expected refCount 3, got %d", entry.refCount)
	}

	// Release client
	pool.ReleaseClient(config)
	if entry.refCount != 2 {
		t.Errorf("Expected refCount 2 after release, got %d", entry.refCount)
	}

	// Release multiple times
	pool.ReleaseClient(config)
	pool.ReleaseClient(config)
	if entry.refCount != 0 {
		t.Errorf("Expected refCount 0, got %d", entry.refCount)
	}

	// Release when already 0 should not go negative
	pool.ReleaseClient(config)
	if entry.refCount != 0 {
		t.Errorf("Expected refCount to remain 0, got %d", entry.refCount)
	}

	// Cleanup
	pool.Shutdown()
}

func TestClientPool_Cleanup(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	pool := NewClientPool(logger, PoolConfig{
		StaleTimeout:    100 * time.Millisecond,
		CleanupInterval: 50 * time.Millisecond,
	})

	config := Config{
		SpireSocketPath:   "/socket",
		SpiffeTrustDomain: "example.org",
		Selectors:         []*typesapi.Selector{},
	}

	// Mock client
	mockClient := NewMockSpireClient(ctrl)
	mockClient.EXPECT().Start(gomock.Any()).Return(nil)
	mockClient.EXPECT().Stop().Return(nil) // Expect Stop to be called during cleanup

	// Inject test factory
	pool.clientFactory = func(logger hclog.Logger, cfg Config) (SpireClient, error) {
		return mockClient, nil
	}

	ctx := context.Background()

	// Acquire and immediately release client
	pool.AcquireClient(ctx, config)
	pool.ReleaseClient(config)

	// Verify client is in pool with refCount 0
	key := pool.buildClientKey(config)
	if pool.clients[key].refCount != 0 {
		t.Error("Expected refCount 0 after release")
	}

	// Wait for cleanup to run
	time.Sleep(200 * time.Millisecond)

	// Check that stale client was removed
	pool.mu.RLock()
	_, exists := pool.clients[key]
	pool.mu.RUnlock()

	if exists {
		t.Error("Expected stale client to be removed")
	}

	// Cleanup
	pool.Shutdown()
}

func TestClientPool_ConcurrentAccess(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	pool := NewClientPool(logger, PoolConfig{})

	// Create multiple mock clients
	mockClients := make([]SpireClient, 10)
	for i := 0; i < 10; i++ {
		mock := NewMockSpireClient(ctrl)
		mock.EXPECT().Start(gomock.Any()).Return(nil).AnyTimes()
		mock.EXPECT().Stop().Return(nil).AnyTimes()
		mockClients[i] = mock
	}

	clientIndex := 0
	clientMutex := sync.Mutex{}

	// Inject test factory
	pool.clientFactory = func(logger hclog.Logger, config Config) (SpireClient, error) {
		clientMutex.Lock()
		defer clientMutex.Unlock()
		if clientIndex >= len(mockClients) {
			clientIndex = 0
		}
		client := mockClients[clientIndex]
		clientIndex++
		return client, nil
	}

	ctx := context.Background()
	var wg sync.WaitGroup

	// Concurrent acquire and release
	for i := 0; i < 100; i++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()

			config := Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: fmt.Sprintf("ns:ns%d", id%5)},
				},
			}

			_, err := pool.AcquireClient(ctx, config)
			if err != nil {
				t.Errorf("Failed to acquire client: %v", err)
				return
			}

			// Simulate some work
			time.Sleep(10 * time.Millisecond)

			pool.ReleaseClient(config)
		}(i)
	}

	wg.Wait()

	// Verify pool state
	stats := pool.GetPoolStats()
	t.Logf("Pool stats after concurrent access: %+v", stats)

	// Cleanup
	pool.Shutdown()
}

func TestClientPool_GetPoolStats(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	pool := NewClientPool(logger, PoolConfig{})

	// Create mock clients
	mockClient1 := NewMockSpireClient(ctrl)
	mockClient1.EXPECT().Start(gomock.Any()).Return(nil)
	mockClient1.EXPECT().Stop().Return(nil).AnyTimes() // Add Stop expectation

	mockClient2 := NewMockSpireClient(ctrl)
	mockClient2.EXPECT().Start(gomock.Any()).Return(nil)
	mockClient2.EXPECT().Stop().Return(nil).AnyTimes() // Add Stop expectation

	// Inject test factory
	clientCount := 0
	pool.clientFactory = func(logger hclog.Logger, config Config) (SpireClient, error) {
		clientCount++
		if clientCount == 1 {
			return mockClient1, nil
		}
		return mockClient2, nil
	}

	ctx := context.Background()

	// Acquire clients
	config1 := Config{
		SpireSocketPath:   "/socket",
		SpiffeTrustDomain: "example.org",
		Selectors: []*typesapi.Selector{
			{Type: "k8s", Value: "ns:ns1"},
		},
	}

	config2 := Config{
		SpireSocketPath:   "/socket",
		SpiffeTrustDomain: "example.org",
		Selectors: []*typesapi.Selector{
			{Type: "k8s", Value: "ns:ns2"},
		},
	}

	pool.AcquireClient(ctx, config1)
	pool.AcquireClient(ctx, config1) // Same config, increases ref count
	pool.AcquireClient(ctx, config2)

	stats := pool.GetPoolStats()

	if stats["total_clients"].(int) != 2 {
		t.Errorf("Expected 2 total clients, got %d", stats["total_clients"])
	}

	if stats["active_clients"].(int) != 2 {
		t.Errorf("Expected 2 active clients, got %d", stats["active_clients"])
	}

	if stats["total_refs"].(int) != 3 {
		t.Errorf("Expected 3 total refs, got %d", stats["total_refs"])
	}

	// Release one reference
	pool.ReleaseClient(config1)

	stats = pool.GetPoolStats()
	if stats["total_refs"].(int) != 2 {
		t.Errorf("Expected 2 total refs after release, got %d", stats["total_refs"])
	}

	// Cleanup
	pool.Shutdown()
}

func TestClientPool_BuildClientKey(t *testing.T) {
	logger := hclog.NewNullLogger()
	pool := NewClientPool(logger, PoolConfig{})

	tests := []struct {
		name     string
		config   Config
		expected string
	}{
		{
			name: "basic config",
			config: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
					{Type: "k8s", Value: "sa:test"},
				},
			},
			expected: "/socket||example.org|k8s:ns:default|k8s:sa:test",
		},
		{
			name: "with secondary socket",
			config: Config{
				SpireSocketPath:   "/socket1",
				SpireSocketPath2:  "/socket2",
				SpiffeTrustDomain: "example.org",
				Selectors:         []*typesapi.Selector{},
			},
			expected: "/socket1|/socket2|example.org",
		},
		{
			name: "selectors sorted",
			config: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "sa:test"},
					{Type: "k8s", Value: "ns:default"},
					{Type: "k8s", Value: "pod-uid:123"},
				},
			},
			expected: "/socket||example.org|k8s:ns:default|k8s:pod-uid:123|k8s:sa:test",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			key := pool.buildClientKey(tt.config)
			if key != tt.expected {
				t.Errorf("Expected key %q, got %q", tt.expected, key)
			}
		})
	}

	// Cleanup
	pool.Shutdown()
}

func TestClientPool_AcquireClient_Error(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	pool := NewClientPool(logger, PoolConfig{})

	config := Config{
		SpireSocketPath:   "/socket",
		SpiffeTrustDomain: "example.org",
	}

	t.Run("factory returns error", func(t *testing.T) {
		// Inject factory that returns error
		pool.clientFactory = func(logger hclog.Logger, cfg Config) (SpireClient, error) {
			return nil, fmt.Errorf("failed to create client")
		}

		ctx := context.Background()
		client, err := pool.AcquireClient(ctx, config)

		if err == nil {
			t.Fatal("Expected error but got none")
		}
		if client != nil {
			t.Error("Expected nil client on error")
		}
		if !strings.Contains(err.Error(), "failed to create client") {
			t.Errorf("Expected error message about client creation, got: %v", err)
		}
	})

	t.Run("start returns error", func(t *testing.T) {
		mockClient := NewMockSpireClient(ctrl)
		mockClient.EXPECT().Start(gomock.Any()).Return(fmt.Errorf("failed to start"))

		// Inject factory that returns mock client
		pool.clientFactory = func(logger hclog.Logger, cfg Config) (SpireClient, error) {
			return mockClient, nil
		}

		ctx := context.Background()
		client, err := pool.AcquireClient(ctx, config)

		if err == nil {
			t.Fatal("Expected error but got none")
		}
		if client != nil {
			t.Error("Expected nil client on error")
		}
		if !strings.Contains(err.Error(), "failed to start") {
			t.Errorf("Expected error message about start failure, got: %v", err)
		}
	})

	// Cleanup
	pool.Shutdown()
}

func TestClientPool_Shutdown(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	pool := NewClientPool(logger, PoolConfig{
		CleanupInterval: 50 * time.Millisecond,
	})

	// Create mock clients
	mockClient1 := NewMockSpireClient(ctrl)
	mockClient1.EXPECT().Start(gomock.Any()).Return(nil).Times(1) // Only called once
	mockClient1.EXPECT().Stop().Return(nil).Times(1)              // Called exactly once during shutdown

	mockClient2 := NewMockSpireClient(ctrl)
	mockClient2.EXPECT().Start(gomock.Any()).Return(nil).Times(1) // Only called once
	mockClient2.EXPECT().Stop().Return(nil).Times(1)              // Called exactly once during shutdown

	clientCount := 0
	pool.clientFactory = func(logger hclog.Logger, config Config) (SpireClient, error) {
		clientCount++
		if clientCount == 1 {
			return mockClient1, nil
		}
		return mockClient2, nil
	}

	ctx := context.Background()

	// Acquire clients
	config1 := Config{
		SpireSocketPath:   "/socket",
		SpiffeTrustDomain: "example.org",
		Selectors: []*typesapi.Selector{
			{Type: "k8s", Value: "ns:ns1"},
		},
	}

	config2 := Config{
		SpireSocketPath:   "/socket",
		SpiffeTrustDomain: "example.org",
		Selectors: []*typesapi.Selector{
			{Type: "k8s", Value: "ns:ns2"},
		},
	}

	pool.AcquireClient(ctx, config1)
	pool.AcquireClient(ctx, config2)

	// Verify clients are in pool
	if len(pool.clients) != 2 {
		t.Errorf("Expected 2 clients in pool before shutdown, got %d", len(pool.clients))
	}

	// Shutdown pool
	err := pool.Shutdown()
	if err != nil {
		t.Errorf("Unexpected error during shutdown: %v", err)
	}

	// Verify all clients were stopped and removed
	if len(pool.clients) != 0 {
		t.Errorf("Expected 0 clients after shutdown, got %d", len(pool.clients))
	}

	// Verify that trying to acquire after shutdown fails
	_, err = pool.AcquireClient(ctx, config1)
	if err == nil {
		t.Error("Expected error when acquiring client after shutdown")
	}
}

func TestClientPool_MultipleReleasesAndCleanup(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	pool := NewClientPool(logger, PoolConfig{
		StaleTimeout:    100 * time.Millisecond,
		CleanupInterval: 50 * time.Millisecond,
	})

	config := Config{
		SpireSocketPath:   "/socket",
		SpiffeTrustDomain: "example.org",
	}

	mockClient := NewMockSpireClient(ctrl)
	mockClient.EXPECT().Start(gomock.Any()).Return(nil)
	mockClient.EXPECT().Stop().Return(nil).MaxTimes(1) // Should only be called once

	pool.clientFactory = func(logger hclog.Logger, cfg Config) (SpireClient, error) {
		return mockClient, nil
	}

	ctx := context.Background()

	// Acquire and release multiple times
	for i := 0; i < 5; i++ {
		client, err := pool.AcquireClient(ctx, config)
		if err != nil {
			t.Fatalf("Failed to acquire client on iteration %d: %v", i, err)
		}
		if client == nil {
			t.Fatalf("Got nil client on iteration %d", i)
		}
		pool.ReleaseClient(config)
	}

	// Verify client is still in pool with refCount 0
	key := pool.buildClientKey(config)
	pool.mu.RLock()
	entry, exists := pool.clients[key]
	pool.mu.RUnlock()

	if !exists {
		t.Error("Client should still be in pool")
	}
	if entry.refCount != 0 {
		t.Errorf("Expected refCount 0, got %d", entry.refCount)
	}

	// Wait for cleanup
	time.Sleep(200 * time.Millisecond)

	// Verify client was removed
	pool.mu.RLock()
	_, exists = pool.clients[key]
	pool.mu.RUnlock()

	if exists {
		t.Error("Expected client to be removed after cleanup")
	}

	// Cleanup
	pool.Shutdown()
}
</file>

<file path="client/client_pool.go">
package client

import (
	"context"
	"fmt"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/hashicorp/go-hclog"
	typesapi "github.com/spiffe/spire-api-sdk/proto/spire/api/types"
	"spire-csi-provider/internal/metrics"
)

// ClientPool manages a pool of SPIRE clients for reuse across mount requests
type ClientPool struct {
	logger  hclog.Logger
	clients map[string]*poolEntry
	mu      sync.RWMutex

	staleTimeout    time.Duration
	cleanupInterval time.Duration

	cleanupCancel context.CancelFunc

	clientFactory func(hclog.Logger, Config) (SpireClient, error)
}

type poolEntry struct {
	client       SpireClient
	key          string
	lastAccessed time.Time
	refCount     int
}

type PoolConfig struct {
	StaleTimeout    time.Duration
	CleanupInterval time.Duration
}

func NewClientPool(logger hclog.Logger, config PoolConfig) *ClientPool {
	if config.StaleTimeout <= 0 {
		config.StaleTimeout = 10 * time.Minute
	}
	if config.CleanupInterval <= 0 {
		config.CleanupInterval = 1 * time.Minute
	}

	pool := &ClientPool{
		logger:          logger.Named("spire-client-pool"),
		clients:         make(map[string]*poolEntry),
		staleTimeout:    config.StaleTimeout,
		cleanupInterval: config.CleanupInterval,
		clientFactory:   NewSpireClient,
	}

	ctx, cancel := context.WithCancel(context.Background())
	pool.cleanupCancel = cancel
	go pool.cleanupRoutine(ctx)

	return pool
}

func (p *ClientPool) AcquireClient(ctx context.Context, config Config) (SpireClient, error) {
	key := p.buildClientKey(config)

	p.mu.RLock()
	entry, exists := p.clients[key]
	if exists {
		entry.lastAccessed = time.Now()
		entry.refCount++
		p.mu.RUnlock()

		p.logger.Debug("acquired existing SPIRE client from pool",
			"key", key,
			"pool_size", len(p.clients),
			"ref_count", entry.refCount,
		)

		metrics.RecordProviderPoolHit(config.SpiffeTrustDomain,
			extractNamespace(config.Selectors),
			extractServiceAccount(config.Selectors))

		return entry.client, nil
	}
	p.mu.RUnlock()

	p.mu.Lock()
	defer p.mu.Unlock()

	// Double-check after acquiring write lock
	if entry, exists := p.clients[key]; exists {
		entry.lastAccessed = time.Now()
		entry.refCount++
		return entry.client, nil
	}

	p.logger.Info("creating new SPIRE client",
		"key", key,
		"socket_path", config.SpireSocketPath,
		"trust_domain", config.SpiffeTrustDomain,
		"pool_size", len(p.clients),
	)

	client, err := p.clientFactory(p.logger.Named("spire-client"), config)
	if err != nil {
		return nil, fmt.Errorf("failed to create SPIRE client: %w", err)
	}

	if err := client.Start(ctx); err != nil {
		return nil, fmt.Errorf("failed to start SPIRE client: %w", err)
	}

	entry = &poolEntry{
		client:       client,
		key:          key,
		lastAccessed: time.Now(),
		refCount:     1,
	}
	p.clients[key] = entry

	metrics.RecordProviderPoolMiss(config.SpiffeTrustDomain,
		extractNamespace(config.Selectors),
		extractServiceAccount(config.Selectors))
	metrics.UpdateProviderPoolSize(config.SpiffeTrustDomain, len(p.clients))

	p.logger.Info("added new SPIRE client to pool",
		"key", key,
		"pool_size", len(p.clients),
	)

	return client, nil
}

func (p *ClientPool) ReleaseClient(config Config) {
	key := p.buildClientKey(config)

	p.mu.Lock()
	defer p.mu.Unlock()

	if entry, exists := p.clients[key]; exists {
		entry.refCount--
		if entry.refCount < 0 {
			entry.refCount = 0
		}

		p.logger.Debug("released SPIRE client",
			"key", key,
			"ref_count", entry.refCount,
		)
	}
}

// buildClientKey creates a unique key for client pooling
// Format: socketPath|socketPath2|trustDomain|selector1|selector2|...
func (p *ClientPool) buildClientKey(config Config) string {
	parts := []string{
		config.SpireSocketPath,
		config.SpireSocketPath2,
		config.SpiffeTrustDomain,
	}

	var selectorStrings []string
	for _, selector := range config.Selectors {
		selectorStrings = append(selectorStrings, fmt.Sprintf("%s:%s", selector.Type, selector.Value))
	}
	sort.Strings(selectorStrings)

	parts = append(parts, selectorStrings...)
	return strings.Join(parts, "|")
}

func (p *ClientPool) cleanupRoutine(ctx context.Context) {
	ticker := time.NewTicker(p.cleanupInterval)
	defer ticker.Stop()

	p.logger.Info("started client pool cleanup routine",
		"interval", p.cleanupInterval,
		"stale_timeout", p.staleTimeout,
	)

	for {
		select {
		case <-ctx.Done():
			p.logger.Info("stopping client pool cleanup routine")
			return
		case <-ticker.C:
			p.performCleanup()
		}
	}
}

func (p *ClientPool) performCleanup() {
	p.mu.Lock()
	defer p.mu.Unlock()

	if len(p.clients) == 0 {
		return
	}

	now := time.Now()
	toRemove := []string{}

	for key, entry := range p.clients {
		// Only remove if refCount is 0 and it's stale
		if entry.refCount == 0 && now.Sub(entry.lastAccessed) > p.staleTimeout {
			toRemove = append(toRemove, key)
		}
	}

	removed := 0
	for _, key := range toRemove {
		if entry, exists := p.clients[key]; exists {
			p.logger.Info("removing stale client from pool",
				"key", key,
				"last_accessed", entry.lastAccessed,
				"age_minutes", int(now.Sub(entry.lastAccessed).Minutes()),
			)

			if err := entry.client.Stop(); err != nil {
				p.logger.Error("failed to stop stale client",
					"key", key,
					"error", err,
				)
			}

			delete(p.clients, key)
			removed++
			metrics.RecordProviderEviction("stale")
		}
	}

	if removed > 0 {
		p.logger.Info("client pool cleanup completed",
			"removed", removed,
			"remaining", len(p.clients),
		)

		for key := range p.clients {
			parts := strings.Split(key, "|")
			if len(parts) >= 2 {
				trustDomain := parts[1]
				metrics.UpdateProviderPoolSize(trustDomain, len(p.clients))
			}
		}
	}
}

func (p *ClientPool) Shutdown() error {
	p.logger.Info("shutting down client pool")

	if p.cleanupCancel != nil {
		p.cleanupCancel()
	}

	p.mu.Lock()
	defer p.mu.Unlock()

	for key, entry := range p.clients {
		p.logger.Debug("stopping client", "key", key)
		if err := entry.client.Stop(); err != nil {
			p.logger.Error("failed to stop client during shutdown",
				"key", key,
				"error", err,
			)
		}
		metrics.RecordProviderEviction("shutdown")
	}

	p.clients = make(map[string]*poolEntry)

	return nil
}

func (p *ClientPool) GetPoolStats() map[string]interface{} {
	p.mu.RLock()
	defer p.mu.RUnlock()

	activeClients := 0
	totalRefCount := 0

	for _, entry := range p.clients {
		if entry.refCount > 0 {
			activeClients++
		}
		totalRefCount += entry.refCount
	}

	return map[string]interface{}{
		"total_clients":  len(p.clients),
		"active_clients": activeClients,
		"total_refs":     totalRefCount,
	}
}

func extractNamespace(selectors []*typesapi.Selector) string {
	for _, selector := range selectors {
		if selector.Type == "k8s" && strings.HasPrefix(selector.Value, "ns:") {
			return strings.TrimPrefix(selector.Value, "ns:")
		}
	}
	return ""
}

func extractServiceAccount(selectors []*typesapi.Selector) string {
	for _, selector := range selectors {
		if selector.Type == "k8s" && strings.HasPrefix(selector.Value, "sa:") {
			return strings.TrimPrefix(selector.Value, "sa:")
		}
	}
	return ""
}
</file>

<file path="client/client_test.go">
package client

import (
	"context"
	"crypto/rand"
	"crypto/rsa"
	"crypto/x509"
	"crypto/x509/pkix"
	"errors"
	"fmt"
	"github.com/golang/mock/gomock"
	"math/big"
	mocks "spire-csi-provider"
	"strings"
	"sync"
	"testing"
	"time"

	"github.com/hashicorp/go-hclog"
	delegatedapi "github.com/spiffe/spire-api-sdk/proto/spire/api/agent/delegatedidentity/v1"
	typesapi "github.com/spiffe/spire-api-sdk/proto/spire/api/types"
	"spire-csi-provider/internal/metrics"
)

func TestNew(t *testing.T) {
	tests := []struct {
		name    string
		config  Config
		wantErr bool
		errMsg  string
	}{
		{
			name: "valid config",
			config: Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
				},
				RotatedQueueSize: 100,
			},
			wantErr: false,
		},
		{
			name: "missing socket path",
			config: Config{
				SpiffeTrustDomain: "example.org",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
				},
			},
			wantErr: true,
			errMsg:  "SPIRE socket path not specified",
		},
		{
			name: "missing trust domain",
			config: Config{
				SpireSocketPath: "/run/spire/socket",
				Selectors: []*typesapi.Selector{
					{Type: "k8s", Value: "ns:default"},
				},
			},
			wantErr: true,
			errMsg:  "SPIRE trust domain not specified",
		},
		{
			name: "zero rotated queue size uses default",
			config: Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
				RotatedQueueSize:  0,
			},
			wantErr: false,
		},
		{
			name: "negative rotated queue size uses default",
			config: Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
				RotatedQueueSize:  -1,
			},
			wantErr: false,
		},
		{
			name: "with pod context",
			config: Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
				PodContext: metrics.PodContext{
					Namespace:      "kube-system",
					ServiceAccount: "admin",
					PodUID:         "123",
					PodName:        "test-pod",
				},
			},
			wantErr: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			client, err := New(logger, tt.config)

			if tt.wantErr {
				if err == nil {
					t.Error("Expected error but got none")
				} else if tt.errMsg != "" && err.Error() != tt.errMsg {
					t.Errorf("Expected error %q, got %q", tt.errMsg, err.Error())
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
				if client == nil {
					t.Error("Expected client to be created")
				} else {
					if client.config.SpireSocketPath != tt.config.SpireSocketPath {
						t.Error("Socket path not set correctly")
					}
					if client.config.SpiffeTrustDomain != tt.config.SpiffeTrustDomain {
						t.Error("Trust domain not set correctly")
					}
					if tt.config.RotatedQueueSize <= 0 && client.config.RotatedQueueSize != 1024 {
						t.Error("Default rotated queue size not set")
					}
				}
			}
		})
	}
}

func TestClient_WaitForSVID(t *testing.T) {
	tests := []struct {
		name           string
		spiffeID       string
		timeout        time.Duration
		preloadSVID    bool
		simulateUpdate bool
		expectTimeout  bool
		expectError    bool
	}{
		{
			name:        "SVID already available",
			spiffeID:    "spiffe://example.org/test",
			timeout:     1 * time.Second,
			preloadSVID: true,
			expectError: false,
		},
		{
			name:           "SVID becomes available",
			spiffeID:       "spiffe://example.org/test",
			timeout:        2 * time.Second,
			preloadSVID:    false,
			simulateUpdate: true,
			expectError:    false,
		},
		{
			name:          "timeout waiting for SVID",
			spiffeID:      "spiffe://example.org/test",
			timeout:       100 * time.Millisecond,
			preloadSVID:   false,
			expectTimeout: true,
			expectError:   true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			config := Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
			}

			client, _ := New(logger, config)
			ctx := context.Background()

			if tt.preloadSVID {
				// Preload SVID in store
				client.svidStore[tt.spiffeID] = &delegatedapi.X509SVIDWithKey{
					X509Svid: &typesapi.X509SVID{
						Id: &typesapi.SPIFFEID{
							TrustDomain: "example.org",
							Path:        "/test",
						},
						ExpiresAt: time.Now().Add(1 * time.Hour).Unix(),
					},
				}
			}

			if tt.simulateUpdate {
				// Simulate SVID becoming available after a delay
				go func() {
					time.Sleep(100 * time.Millisecond)
					client.svidStoreMutex.Lock()
					client.svidStore[tt.spiffeID] = &delegatedapi.X509SVIDWithKey{
						X509Svid: &typesapi.X509SVID{
							Id: &typesapi.SPIFFEID{
								TrustDomain: "example.org",
								Path:        "/test",
							},
							ExpiresAt: time.Now().Add(1 * time.Hour).Unix(),
						},
					}
					client.svidStoreMutex.Unlock()

					// Notify waiter
					client.svidWaitersMutex.Lock()
					if waitChan, exists := client.svidWaiters[tt.spiffeID]; exists {
						close(waitChan)
						delete(client.svidWaiters, tt.spiffeID)
					}
					client.svidWaitersMutex.Unlock()
				}()
			}

			err := client.WaitForSVID(ctx, tt.spiffeID, tt.timeout)

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				}
				if tt.expectTimeout && !errors.Is(err, context.DeadlineExceeded) && !contains(err.Error(), "timeout") {
					t.Errorf("Expected timeout error, got: %v", err)
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
			}
		})
	}
}

func TestClient_WaitForTrustBundle(t *testing.T) {
	tests := []struct {
		name           string
		timeout        time.Duration
		preloadBundle  bool
		simulateUpdate bool
		expectTimeout  bool
		expectError    bool
	}{
		{
			name:          "bundle already available",
			timeout:       1 * time.Second,
			preloadBundle: true,
			expectError:   false,
		},
		{
			name:           "bundle becomes available",
			timeout:        2 * time.Second,
			preloadBundle:  false,
			simulateUpdate: true,
			expectError:    false,
		},
		{
			name:          "timeout waiting for bundle",
			timeout:       100 * time.Millisecond,
			preloadBundle: false,
			expectTimeout: true,
			expectError:   true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			config := Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
			}

			client, _ := New(logger, config)
			ctx := context.Background()

			if tt.preloadBundle {
				// Preload trust bundle
				cert := generateTestCACertificate(t)
				client.parsedCerts["example.org"] = []*x509.Certificate{cert}
			}

			if tt.simulateUpdate {
				// Simulate bundle becoming available after a delay
				go func() {
					time.Sleep(100 * time.Millisecond)
					cert := generateTestCACertificate(t)
					client.parsedCertsMutex.Lock()
					client.parsedCerts["example.org"] = []*x509.Certificate{cert}
					client.parsedCertsMutex.Unlock()

					// Signal bundle ready
					client.trustBundleOnce.Do(func() {
						client.trustBundleReady = make(chan struct{})
					})
					select {
					case <-client.trustBundleReady:
					default:
						close(client.trustBundleReady)
					}
				}()
			}

			err := client.WaitForTrustBundle(ctx, tt.timeout)

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				}
				if tt.expectTimeout && !contains(err.Error(), "timeout") {
					t.Errorf("Expected timeout error, got: %v", err)
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
			}
		})
	}
}

func TestClient_GetCACertificates(t *testing.T) {
	tests := []struct {
		name          string
		setupCerts    map[string][]*x509.Certificate
		expectError   bool
		expectedCount int
	}{
		{
			name: "single trust domain",
			setupCerts: map[string][]*x509.Certificate{
				"example.org": {
					generateTestCACertificate(t),
					generateTestCACertificate(t),
				},
			},
			expectError:   false,
			expectedCount: 2,
		},
		{
			name: "multiple trust domains",
			setupCerts: map[string][]*x509.Certificate{
				"example.org": {
					generateTestCACertificate(t),
				},
				"test.org": {
					generateTestCACertificate(t),
					generateTestCACertificate(t),
				},
			},
			expectError:   false,
			expectedCount: 3,
		},
		{
			name:          "no certificates available",
			setupCerts:    map[string][]*x509.Certificate{},
			expectError:   true,
			expectedCount: 0,
		},
		{
			name:          "nil parsed certs",
			setupCerts:    nil,
			expectError:   true,
			expectedCount: 0,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			config := Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
			}

			client, _ := New(logger, config)
			client.parsedCerts = tt.setupCerts

			ctx := context.Background()
			certs, err := client.GetCACertificates(ctx)

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
				if len(certs) != tt.expectedCount {
					t.Errorf("Expected %d certificates, got %d", tt.expectedCount, len(certs))
				}
			}
		})
	}
}

func TestClient_GetCertificateForIdentity(t *testing.T) {
	tests := []struct {
		name        string
		spiffeID    string
		setupSVID   bool
		invalidCert bool
		emptyChain  bool
		badKey      bool
		expectError bool
		errorMsg    string
	}{
		{
			name:        "valid certificate",
			spiffeID:    "spiffe://example.org/test",
			setupSVID:   true,
			expectError: false,
		},
		{
			name:        "SVID not found",
			spiffeID:    "spiffe://example.org/missing",
			setupSVID:   false,
			expectError: true,
			errorMsg:    "no SPIFFE ID for",
		},
		{
			name:        "empty certificate chain",
			spiffeID:    "spiffe://example.org/test",
			setupSVID:   true,
			emptyChain:  true,
			expectError: true,
			errorMsg:    "no certificate chain",
		},
		{
			name:        "invalid certificate in chain",
			spiffeID:    "spiffe://example.org/test",
			setupSVID:   true,
			invalidCert: true,
			expectError: true,
			errorMsg:    "failed to parse certificate",
		},
		{
			name:        "invalid private key",
			spiffeID:    "spiffe://example.org/test",
			setupSVID:   true,
			badKey:      true,
			expectError: true,
			errorMsg:    "failed to parse private key",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			config := Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
			}

			client, _ := New(logger, config)

			if tt.setupSVID {
				cert, key := generateTestCertificate(t)
				keyBytes, _ := x509.MarshalPKCS8PrivateKey(key)

				svid := &delegatedapi.X509SVIDWithKey{
					X509Svid: &typesapi.X509SVID{
						Id: &typesapi.SPIFFEID{
							TrustDomain: "example.org",
							Path:        "/test",
						},
						ExpiresAt: time.Now().Add(1 * time.Hour).Unix(),
					},
					X509SvidKey: keyBytes,
				}

				if tt.emptyChain {
					svid.X509Svid.CertChain = [][]byte{}
				} else if tt.invalidCert {
					svid.X509Svid.CertChain = [][]byte{[]byte("invalid-cert")}
				} else {
					svid.X509Svid.CertChain = [][]byte{cert.Raw}
				}

				if tt.badKey {
					svid.X509SvidKey = []byte("invalid-key")
				}

				client.svidStore[tt.spiffeID] = svid
			}

			tlsCert, err := client.GetCertificateForIdentity(tt.spiffeID)

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				} else if tt.errorMsg != "" && !contains(err.Error(), tt.errorMsg) {
					t.Errorf("Expected error containing %q, got %q", tt.errorMsg, err.Error())
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
				if tlsCert == nil {
					t.Error("Expected certificate but got nil")
				}
			}
		})
	}
}

func TestClient_FetchJWTSVID(t *testing.T) {
	tests := []struct {
		name           string
		spiffeID       string
		audiences      []string
		cachedToken    string
		cachedExpiry   time.Time
		fetchResponse  *delegatedapi.FetchJWTSVIDsResponse
		fetchError     error
		expectCacheHit bool
		expectError    bool
		errorMsg       string
	}{
		{
			name:      "successful fetch",
			spiffeID:  "spiffe://example.org/test",
			audiences: []string{"audience1"},
			fetchResponse: &delegatedapi.FetchJWTSVIDsResponse{
				Svids: []*typesapi.JWTSVID{
					{
						Token:     "test-token",
						ExpiresAt: time.Now().Add(2 * time.Hour).Unix(),
					},
				},
			},
			expectError: false,
		},
		{
			name:           "cache hit",
			spiffeID:       "spiffe://example.org/test",
			audiences:      []string{"audience1"},
			cachedToken:    "cached-token",
			cachedExpiry:   time.Now().Add(2 * time.Hour),
			expectCacheHit: true,
			expectError:    false,
		},
		{
			name:           "cache miss - expired",
			spiffeID:       "spiffe://example.org/test",
			audiences:      []string{"audience1"},
			cachedToken:    "expired-token",
			cachedExpiry:   time.Now().Add(-1 * time.Hour),
			expectCacheHit: false,
			fetchResponse: &delegatedapi.FetchJWTSVIDsResponse{
				Svids: []*typesapi.JWTSVID{
					{
						Token:     "new-token",
						ExpiresAt: time.Now().Add(2 * time.Hour).Unix(),
					},
				},
			},
			expectError: false,
		},
		{
			name:        "fetch error",
			spiffeID:    "spiffe://example.org/test",
			audiences:   []string{"audience1"},
			fetchError:  errors.New("fetch failed"),
			expectError: true,
			errorMsg:    "failed to fetch JWT-SVID",
		},
		{
			name:      "empty response",
			spiffeID:  "spiffe://example.org/test",
			audiences: []string{"audience1"},
			fetchResponse: &delegatedapi.FetchJWTSVIDsResponse{
				Svids: []*typesapi.JWTSVID{},
			},
			expectError: true,
			errorMsg:    "no JWT-SVIDs returned",
		},
		{
			name:        "nil delegated client",
			spiffeID:    "spiffe://example.org/test",
			audiences:   []string{"audience1"},
			expectError: true,
			errorMsg:    "not connected to SPIRE",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			config := Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
			}

			client, _ := New(logger, config)
			ctx := context.Background()

			// Setup cached entry if specified
			if tt.cachedToken != "" {
				cacheKey := client.createJWTCacheKey(tt.spiffeID, tt.audiences)
				client.jwtSVIDCache[cacheKey] = &jwtCacheEntry{
					token:     tt.cachedToken,
					expiresAt: tt.cachedExpiry,
					audiences: tt.audiences,
				}
			}

			// Setup mock delegated client if not testing nil client
			if tt.name != "nil delegated client" {
				mockClient := mocks.NewMockDelegatedIdentityClient(ctrl)
				client.delegatedIdentityClient = mockClient

				if !tt.expectCacheHit && tt.fetchResponse != nil {
					mockClient.EXPECT().
						FetchJWTSVIDs(gomock.Any(), gomock.Any()).
						Return(tt.fetchResponse, tt.fetchError)
				} else if !tt.expectCacheHit && tt.fetchError != nil {
					mockClient.EXPECT().
						FetchJWTSVIDs(gomock.Any(), gomock.Any()).
						Return(nil, tt.fetchError)
				}
			}

			token, err := client.FetchJWTSVID(ctx, tt.spiffeID, tt.audiences)

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				} else if tt.errorMsg != "" && !contains(err.Error(), tt.errorMsg) {
					t.Errorf("Expected error containing %q, got %q", tt.errorMsg, err.Error())
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
				if tt.expectCacheHit && token != tt.cachedToken {
					t.Errorf("Expected cached token %q, got %q", tt.cachedToken, token)
				}
				if !tt.expectCacheHit && tt.fetchResponse != nil && token != tt.fetchResponse.Svids[0].Token {
					t.Errorf("Expected fetched token %q, got %q", tt.fetchResponse.Svids[0].Token, token)
				}
			}
		})
	}
}

func TestClient_HandleX509SVIDUpdate(t *testing.T) {
	tests := []struct {
		name                string
		existingSVIDs       map[string]*delegatedapi.X509SVIDWithKey
		updateSVIDs         []*delegatedapi.X509SVIDWithKey
		expectedStore       int
		trustDomainMismatch bool
	}{
		{
			name:          "new SVID added",
			existingSVIDs: map[string]*delegatedapi.X509SVIDWithKey{},
			updateSVIDs: []*delegatedapi.X509SVIDWithKey{
				createTestSVID("example.org", "/test"),
			},
			expectedStore: 1,
		},
		{
			name: "existing SVID updated",
			existingSVIDs: map[string]*delegatedapi.X509SVIDWithKey{
				"spiffe://example.org/test": createTestSVID("example.org", "/test"),
			},
			updateSVIDs: []*delegatedapi.X509SVIDWithKey{
				createTestSVIDWithExpiry("example.org", "/test", time.Now().Add(2*time.Hour)),
			},
			expectedStore: 1,
		},
		{
			name: "SVID deleted",
			existingSVIDs: map[string]*delegatedapi.X509SVIDWithKey{
				"spiffe://example.org/test":  createTestSVID("example.org", "/test"),
				"spiffe://example.org/test2": createTestSVID("example.org", "/test2"),
			},
			updateSVIDs: []*delegatedapi.X509SVIDWithKey{
				createTestSVID("example.org", "/test"),
			},
			expectedStore: 1,
		},
		{
			name:          "trust domain mismatch",
			existingSVIDs: map[string]*delegatedapi.X509SVIDWithKey{},
			updateSVIDs: []*delegatedapi.X509SVIDWithKey{
				createTestSVID("other.org", "/test"),
			},
			trustDomainMismatch: true,
			expectedStore:       0,
		},
		{
			name:          "multiple SVIDs",
			existingSVIDs: map[string]*delegatedapi.X509SVIDWithKey{},
			updateSVIDs: []*delegatedapi.X509SVIDWithKey{
				createTestSVID("example.org", "/test1"),
				createTestSVID("example.org", "/test2"),
				createTestSVID("example.org", "/test3"),
			},
			expectedStore: 3,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			config := Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
			}

			client, _ := New(logger, config)
			client.svidStore = tt.existingSVIDs
			client.svidWaiters = make(map[string]chan struct{})

			// Handle update
			client.handleX509SVIDUpdate(tt.updateSVIDs)

			// Verify store
			if !tt.trustDomainMismatch {
				if len(client.svidStore) != tt.expectedStore {
					t.Errorf("Expected %d SVIDs in store, got %d", tt.expectedStore, len(client.svidStore))
				}
			} else {
				// For trust domain mismatch, store should remain unchanged
				if len(client.svidStore) != len(tt.existingSVIDs) {
					t.Error("Store should not change for trust domain mismatch")
				}
			}
		})
	}
}

func TestClient_HandleX509BundleUpdate(t *testing.T) {
	tests := []struct {
		name            string
		bundles         map[string][]byte
		expectError     bool
		expectedDomains int
		expectedCerts   map[string]int
	}{
		{
			name: "single domain bundle",
			bundles: map[string][]byte{
				"example.org": generateTestCACertificate(t).Raw,
			},
			expectedDomains: 1,
			expectedCerts: map[string]int{
				"example.org": 1,
			},
		},
		{
			name: "multiple domain bundles",
			bundles: map[string][]byte{
				"example.org": generateTestCACertificate(t).Raw,
				"test.org":    generateTestCACertificate(t).Raw,
			},
			expectedDomains: 2,
			expectedCerts: map[string]int{
				"example.org": 1,
				"test.org":    1,
			},
		},
		{
			name: "invalid certificate",
			bundles: map[string][]byte{
				"example.org": []byte("invalid-cert"),
			},
			expectedDomains: 0,
			expectError:     true,
		},
		{
			name:            "empty bundles",
			bundles:         map[string][]byte{},
			expectedDomains: 0,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			config := Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
			}

			client, _ := New(logger, config)

			// Handle update
			client.handleX509BundleUpdate(tt.bundles)

			// Verify parsed certs
			if len(client.parsedCerts) != tt.expectedDomains {
				t.Errorf("Expected %d domains, got %d", tt.expectedDomains, len(client.parsedCerts))
			}

			for domain, expectedCount := range tt.expectedCerts {
				if certs, exists := client.parsedCerts[domain]; exists {
					if len(certs) != expectedCount {
						t.Errorf("Domain %s: expected %d certs, got %d", domain, expectedCount, len(certs))
					}
				} else {
					t.Errorf("Expected domain %s not found", domain)
				}
			}

			// Verify trust bundle is set
			if !tt.expectError && client.trustBundle == nil {
				t.Error("Trust bundle should be set")
			}
		})
	}
}

func TestClient_Status(t *testing.T) {
	tests := []struct {
		name             string
		connected        bool
		lastConnectError error
		expectedStatus   bool
		expectedMsg      string
	}{
		{
			name:           "connected",
			connected:      true,
			expectedStatus: true,
			expectedMsg:    "Connected to SPIRE server",
		},
		{
			name:           "not connected",
			connected:      false,
			expectedStatus: false,
			expectedMsg:    "Not connected to SPIRE server",
		},
		{
			name:             "not connected with error",
			connected:        false,
			lastConnectError: errors.New("connection refused"),
			expectedStatus:   false,
			expectedMsg:      "Cannot connect to SPIRE server",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			config := Config{
				SpireSocketPath:   "/run/spire/socket",
				SpiffeTrustDomain: "example.org",
			}

			client, _ := New(logger, config)
			client.connected = tt.connected
			client.lastConnectError = tt.lastConnectError

			status, msg := client.Status()

			if status != tt.expectedStatus {
				t.Errorf("Expected status %v, got %v", tt.expectedStatus, status)
			}
			if !contains(msg, tt.expectedMsg) {
				t.Errorf("Expected message containing %q, got %q", tt.expectedMsg, msg)
			}
		})
	}
}

func TestClient_ConcurrentOperations(t *testing.T) {
	logger := hclog.NewNullLogger()
	config := Config{
		SpireSocketPath:   "/run/spire/socket",
		SpiffeTrustDomain: "example.org",
	}

	client, _ := New(logger, config)
	ctx := context.Background()

	// Setup some initial data
	cert := generateTestCACertificate(t)
	client.parsedCerts["example.org"] = []*x509.Certificate{cert}

	svid := createTestSVID("example.org", "/test")
	client.svidStore["spiffe://example.org/test"] = svid

	// Run concurrent operations
	var wg sync.WaitGroup
	numGoroutines := 100

	// Concurrent reads
	for i := 0; i < numGoroutines; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			client.GetCACertificates(ctx)
			client.GetCertificateForIdentity("spiffe://example.org/test")
			client.Status()
			client.GetTrustBundle()
		}()
	}

	// Concurrent updates
	for i := 0; i < 10; i++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()
			svids := []*delegatedapi.X509SVIDWithKey{
				createTestSVID("example.org", fmt.Sprintf("/test%d", id)),
			}
			client.handleX509SVIDUpdate(svids)
		}(i)
	}

	wg.Wait()

	// Verify client is still in valid state
	if client.svidStore == nil {
		t.Error("SVID store should not be nil after concurrent operations")
	}
	if client.parsedCerts == nil {
		t.Error("Parsed certs should not be nil after concurrent operations")
	}
}

// Helper functions

func generateTestCACertificate(t *testing.T) *x509.Certificate {
	key, err := rsa.GenerateKey(rand.Reader, 2048)
	if err != nil {
		t.Fatal(err)
	}

	template := x509.Certificate{
		SerialNumber: big.NewInt(1),
		Subject: pkix.Name{
			Organization: []string{"Test CA"},
		},
		NotBefore:             time.Now(),
		NotAfter:              time.Now().Add(365 * 24 * time.Hour),
		KeyUsage:              x509.KeyUsageCertSign | x509.KeyUsageCRLSign,
		BasicConstraintsValid: true,
		IsCA:                  true,
	}

	certDER, err := x509.CreateCertificate(rand.Reader, &template, &template, &key.PublicKey, key)
	if err != nil {
		t.Fatal(err)
	}

	cert, err := x509.ParseCertificate(certDER)
	if err != nil {
		t.Fatal(err)
	}

	return cert
}

func generateTestCertificate(t *testing.T) (*x509.Certificate, *rsa.PrivateKey) {
	key, err := rsa.GenerateKey(rand.Reader, 2048)
	if err != nil {
		t.Fatal(err)
	}

	template := x509.Certificate{
		SerialNumber: big.NewInt(1),
		Subject: pkix.Name{
			Organization: []string{"Test Org"},
		},
		NotBefore:   time.Now(),
		NotAfter:    time.Now().Add(365 * 24 * time.Hour),
		KeyUsage:    x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature,
		ExtKeyUsage: []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth},
	}

	certDER, err := x509.CreateCertificate(rand.Reader, &template, &template, &key.PublicKey, key)
	if err != nil {
		t.Fatal(err)
	}

	cert, err := x509.ParseCertificate(certDER)
	if err != nil {
		t.Fatal(err)
	}

	return cert, key
}

func createTestSVID(trustDomain, path string) *delegatedapi.X509SVIDWithKey {
	cert, key := generateTestCertificate(nil)
	keyBytes, _ := x509.MarshalPKCS8PrivateKey(key)

	return &delegatedapi.X509SVIDWithKey{
		X509Svid: &typesapi.X509SVID{
			Id: &typesapi.SPIFFEID{
				TrustDomain: trustDomain,
				Path:        path,
			},
			CertChain: [][]byte{cert.Raw},
			ExpiresAt: time.Now().Add(1 * time.Hour).Unix(),
		},
		X509SvidKey: keyBytes,
	}
}

func createTestSVIDWithExpiry(trustDomain, path string, expiry time.Time) *delegatedapi.X509SVIDWithKey {
	svid := createTestSVID(trustDomain, path)
	svid.X509Svid.ExpiresAt = expiry.Unix()
	return svid
}

func contains(s, substr string) bool {
	return len(s) >= len(substr) && (strings.Contains(s, substr))
}
</file>

<file path="client/client.go">
package client

import (
	"bytes"
	"context"
	"crypto/tls"
	"crypto/x509"
	"errors"
	"fmt"
	"os"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/hashicorp/go-hclog"
	delegatedapi "github.com/spiffe/spire-api-sdk/proto/spire/api/agent/delegatedidentity/v1"
	typesapi "github.com/spiffe/spire-api-sdk/proto/spire/api/types"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
	"spire-csi-provider/internal/metrics"
)

const (
	// Start refreshing JWT SVIDs 1 hour before expiration
	jwtRefreshBuffer = 1 * time.Hour
)

type CertificateRotationEvent struct {
	Identity string
	Deleted  bool
}

type Config struct {
	SpireSocketPath   string
	SpireSocketPath2  string
	SpiffeTrustDomain string
	Selectors         []*typesapi.Selector
	RotatedQueueSize  int
	PodContext        metrics.PodContext
}

type jwtCacheEntry struct {
	token     string
	expiresAt time.Time
	audiences []string
}

type Client struct {
	config Config
	logger hclog.Logger

	delegatedIdentityClient delegatedapi.DelegatedIdentityClient

	connectionAttempts int

	stream      delegatedapi.DelegatedIdentity_SubscribeToX509SVIDsClient
	trustStream delegatedapi.DelegatedIdentity_SubscribeToX509BundlesClient

	svidStore      map[string]*delegatedapi.X509SVIDWithKey
	svidStoreMutex sync.RWMutex
	trustBundle    *x509.CertPool

	parsedCertsMutex sync.RWMutex
	parsedCerts      map[string][]*x509.Certificate

	cancelListenForUpdates context.CancelFunc

	connected        bool
	lastConnectError error
	connectedMutex   sync.RWMutex

	svidWaiters      map[string]chan struct{}
	svidWaitersMutex sync.Mutex

	trustBundleReady chan struct{}
	trustBundleOnce  sync.Once

	jwtSVIDCache      map[string]*jwtCacheEntry
	jwtSVIDCacheMutex sync.RWMutex

	podContext metrics.PodContext
}

func New(logger hclog.Logger, config Config) (*Client, error) {
	if config.SpireSocketPath == "" {
		return nil, errors.New("SPIRE socket path not specified")
	}

	if config.SpiffeTrustDomain == "" {
		return nil, errors.New("SPIRE trust domain not specified")
	}

	if config.RotatedQueueSize <= 0 {
		config.RotatedQueueSize = 1024
	}

	logger.Info("creating SPIRE client",
		"socket_path", config.SpireSocketPath,
		"trust_domain", config.SpiffeTrustDomain,
	)

	client := &Client{
		config:       config,
		logger:       logger,
		svidStore:    map[string]*delegatedapi.X509SVIDWithKey{},
		parsedCerts:  map[string][]*x509.Certificate{},
		jwtSVIDCache: map[string]*jwtCacheEntry{},
		podContext:   config.PodContext,
	}

	return client, nil
}

func (c *Client) WaitForSVID(ctx context.Context, spiffeID string, timeout time.Duration) error {
	c.logger.Debug("waiting for SVID",
		"spiffe_id", spiffeID,
		"timeout", timeout,
	)

	c.svidStoreMutex.RLock()
	if _, exists := c.svidStore[spiffeID]; exists {
		c.svidStoreMutex.RUnlock()
		c.logger.Debug("SVID already available", "spiffe_id", spiffeID)
		return nil
	}
	c.svidStoreMutex.RUnlock()

	// Register waiter
	c.svidWaitersMutex.Lock()
	if c.svidWaiters == nil {
		c.svidWaiters = make(map[string]chan struct{})
	}
	waitChan := make(chan struct{})
	c.svidWaiters[spiffeID] = waitChan
	c.svidWaitersMutex.Unlock()

	c.logger.Debug("registered SVID waiter", "spiffe_id", spiffeID)

	// Wait
	timeoutCtx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	select {
	case <-waitChan:
		c.logger.Debug("SVID became available", "spiffe_id", spiffeID)
		return nil
	case <-timeoutCtx.Done():
		c.svidWaitersMutex.Lock()
		delete(c.svidWaiters, spiffeID)
		c.svidWaitersMutex.Unlock()
		c.logger.Error("timeout waiting for SVID",
			"spiffe_id", spiffeID,
			"timeout", timeout,
		)
		return fmt.Errorf("timeout waiting for SVID %s", spiffeID)
	}
}

func (c *Client) WaitForTrustBundle(ctx context.Context, timeout time.Duration) error {
	c.logger.Debug("waiting for trust bundle", "timeout", timeout)

	c.parsedCertsMutex.RLock()
	if len(c.parsedCerts) > 0 {
		c.parsedCertsMutex.RUnlock()
		c.logger.Debug("trust bundle already available")
		return nil
	}
	c.parsedCertsMutex.RUnlock()

	// Initialize channel once
	c.trustBundleOnce.Do(func() {
		c.trustBundleReady = make(chan struct{})
	})

	// Wait
	timeoutCtx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	select {
	case <-c.trustBundleReady:
		c.logger.Debug("trust bundle became available")
		return nil
	case <-timeoutCtx.Done():
		c.logger.Error("timeout waiting for trust bundle", "timeout", timeout)
		return fmt.Errorf("timeout waiting for trust bundle")
	}
}

func (c *Client) Start(ctx context.Context) error {
	c.logger.Info("starting SPIRE Delegated Identity client")

	listenCtx, cancel := context.WithCancel(context.Background())
	go c.listenForUpdates(listenCtx)

	c.cancelListenForUpdates = cancel

	return nil
}

func (c *Client) Stop() error {
	c.logger.Info("stopping SPIRE Delegated Identity client")

	if c.cancelListenForUpdates != nil {
		c.cancelListenForUpdates()
	}

	if c.stream != nil {
		c.stream.CloseSend()
	}

	if c.trustStream != nil {
		c.trustStream.CloseSend()
	}

	metrics.UpdateSpireConnectionStatus(false, c.podContext)

	return nil
}

func (c *Client) GetCACertificates(ctx context.Context) ([]*x509.Certificate, error) {
	c.parsedCertsMutex.RLock()
	defer c.parsedCertsMutex.RUnlock()

	if len(c.parsedCerts) == 0 {
		c.logger.Warn("no certificates available in trust bundle")
		return nil, errors.New("no certificates available in trust bundle")
	}

	var allCerts []*x509.Certificate
	certCount := 0
	for trustDomain, certs := range c.parsedCerts {
		allCerts = append(allCerts, certs...)
		certCount += len(certs)
		c.logger.Trace("returning certificates from trust domain",
			"trust_domain", trustDomain,
			"cert_count", len(certs),
		)
	}

	c.logger.Debug("returning CA certificates",
		"total_count", certCount,
		"trust_domain_count", len(c.parsedCerts),
	)

	return allCerts, nil
}

func (c *Client) FetchJWTSVID(ctx context.Context, spiffeID string, audiences []string) (string, error) {
	if c.delegatedIdentityClient == nil {
		c.logger.Error("not connected to SPIRE Delegated Identity API")
		return "", errors.New("not connected to SPIRE Delegated Identity API")
	}

	cacheKey := c.createJWTCacheKey(spiffeID, audiences)

	c.jwtSVIDCacheMutex.RLock()
	cachedEntry, exists := c.jwtSVIDCache[cacheKey]
	c.jwtSVIDCacheMutex.RUnlock()

	now := time.Now()

	if exists && now.Before(cachedEntry.expiresAt) {
		shouldRefresh := now.Add(jwtRefreshBuffer).After(cachedEntry.expiresAt)
		timeUntilExpiry := cachedEntry.expiresAt.Sub(now)

		if !shouldRefresh {
			c.logger.Debug("JWT-SVID cache hit",
				"spiffe_id", spiffeID,
				"audiences", audiences,
				"expires_at", cachedEntry.expiresAt,
				"time_until_expiry", timeUntilExpiry,
			)
			metrics.RecordJWTCacheHit(c.podContext)
			return cachedEntry.token, nil
		}

		c.logger.Debug("JWT-SVID needs refresh",
			"spiffe_id", spiffeID,
			"audiences", audiences,
			"expires_at", cachedEntry.expiresAt,
			"time_until_expiry", timeUntilExpiry,
		)

		resp, err := c.delegatedIdentityClient.FetchJWTSVIDs(ctx, &delegatedapi.FetchJWTSVIDsRequest{
			Selectors: c.config.Selectors,
			Audience:  audiences,
		})

		if err != nil {
			// Fetch failed but we still have a valid cached token
			c.logger.Warn("failed to refresh JWT-SVID, using cached token",
				"spiffe_id", spiffeID,
				"audiences", audiences,
				"error", err,
				"cached_token_expires_at", cachedEntry.expiresAt,
			)
			return cachedEntry.token, nil
		}

		if len(resp.Svids) > 0 {
			svid := resp.Svids[0]
			expiresAt := time.Unix(svid.ExpiresAt, 0)

			c.jwtSVIDCacheMutex.Lock()
			c.jwtSVIDCache[cacheKey] = &jwtCacheEntry{
				token:     svid.Token,
				expiresAt: expiresAt,
				audiences: audiences,
			}
			c.jwtSVIDCacheMutex.Unlock()

			c.logger.Info("JWT-SVID refreshed and cached",
				"spiffe_id", spiffeID,
				"audiences", audiences,
				"expires_at", expiresAt,
			)

			metrics.RecordSpireSVIDReceived("jwt", c.podContext)
			c.updateCacheMetrics()

			return svid.Token, nil
		}
	}

	c.logger.Info("fetching new JWT-SVID from SPIRE agent",
		"spiffe_id", spiffeID,
		"audiences", audiences,
	)
	metrics.RecordJWTCacheMiss(c.podContext)

	resp, err := c.delegatedIdentityClient.FetchJWTSVIDs(ctx, &delegatedapi.FetchJWTSVIDsRequest{
		Selectors: c.config.Selectors,
		Audience:  audiences,
	})
	if err != nil {
		if exists {
			c.logger.Error("failed to fetch JWT-SVID, returning expired cached token",
				"spiffe_id", spiffeID,
				"audiences", audiences,
				"error", err,
				"expired_at", cachedEntry.expiresAt,
			)
			return cachedEntry.token, nil
		}
		c.logger.Error("failed to fetch JWT-SVID",
			"spiffe_id", spiffeID,
			"audiences", audiences,
			"error", err,
		)
		return "", fmt.Errorf("failed to fetch JWT-SVID: %w", err)
	}

	if len(resp.Svids) == 0 {
		c.logger.Error("no JWT-SVIDs returned",
			"spiffe_id", spiffeID,
			"audiences", audiences,
		)
		return "", errors.New("no JWT-SVIDs returned")
	}

	svid := resp.Svids[0]
	expiresAt := time.Unix(svid.ExpiresAt, 0)

	c.jwtSVIDCacheMutex.Lock()
	c.jwtSVIDCache[cacheKey] = &jwtCacheEntry{
		token:     svid.Token,
		expiresAt: expiresAt,
		audiences: audiences,
	}
	c.jwtSVIDCacheMutex.Unlock()

	c.logger.Info("JWT-SVID fetched and cached",
		"spiffe_id", spiffeID,
		"audiences", audiences,
		"expires_at", expiresAt,
	)

	metrics.RecordSpireSVIDReceived("jwt", c.podContext)
	c.updateCacheMetrics()

	return svid.Token, nil
}

func (c *Client) createJWTCacheKey(spiffeID string, audiences []string) string {
	sortedAudiences := make([]string, len(audiences))
	copy(sortedAudiences, audiences)
	sort.Strings(sortedAudiences)

	return fmt.Sprintf("%s:%s", spiffeID, strings.Join(sortedAudiences, ","))
}

func (c *Client) listenForUpdates(ctx context.Context) {
	c.logger.Debug("starting update listener")
	c.openStream(ctx)

	listenCtx, cancel := context.WithCancel(ctx)
	errChan := make(chan error)

	go c.listenForSVIDUpdates(listenCtx, errChan)
	go c.listenForBundleUpdates(listenCtx, errChan)

	for {
		select {
		case <-ctx.Done():
			c.logger.Debug("update listener context cancelled")
			cancel()
			return
		case err := <-errChan:
			c.logger.Error("error in delegate stream, restarting",
				"error", err,
				"connection_attempts", c.connectionAttempts,
			)

			time.Sleep(1 * time.Second)

			cancel()
			c.connectionAttempts++
			go c.listenForUpdates(ctx)
			return
		}
	}
}

func (c *Client) openStream(ctx context.Context) {
	c.logger.Info("opening SPIRE stream connection")

	c.connectedMutex.Lock()
	c.connected = false
	c.connectedMutex.Unlock()

	metrics.UpdateSpireConnectionStatus(false, c.podContext)

	for {
		c.logger.Info("connecting to SPIRE Delegated Identity API",
			"attempt", c.connectionAttempts+1,
			"socket", c.config.SpireSocketPath,
		)

		var err error
		c.stream, c.trustStream, err = c.initWatcher(ctx)
		if err != nil {
			c.logger.Warn("SPIRE Delegated Identity client failed to init watcher",
				"error", err,
				"attempt", c.connectionAttempts+1,
			)

			c.connectedMutex.Lock()
			c.connected = false
			c.lastConnectError = err
			c.connectedMutex.Unlock()

			metrics.RecordSpireConnectionAttempt(c.podContext)
			time.Sleep(1 * time.Second)

			c.connectionAttempts++
			continue
		}

		c.connectedMutex.Lock()
		c.connected = true
		c.lastConnectError = nil
		c.connectedMutex.Unlock()

		metrics.UpdateSpireConnectionStatus(true, c.podContext)
		metrics.RecordSpireConnectionAttempt(c.podContext)

		c.logger.Info("successfully connected to SPIRE Delegated Identity API")
		break
	}
}

func (c *Client) initWatcher(ctx context.Context) (delegatedapi.DelegatedIdentity_SubscribeToX509SVIDsClient,
	delegatedapi.DelegatedIdentity_SubscribeToX509BundlesClient, error) {

	if _, err := os.Stat(c.config.SpireSocketPath); errors.Is(err, os.ErrNotExist) {
		return nil, nil, fmt.Errorf("SPIRE socket (%s) does not exist: %w", c.config.SpireSocketPath, err)
	}

	unixPath := fmt.Sprintf("unix://%s", c.config.SpireSocketPath)

	c.logger.Debug("creating gRPC connection", "path", unixPath)

	conn, err := grpc.NewClient(unixPath, grpc.WithTransportCredentials(insecure.NewCredentials()),
		grpc.WithDefaultCallOptions(
			grpc.MaxCallRecvMsgSize(20*1024*1024),
			grpc.MaxCallSendMsgSize(20*1024*1024)))

	if err != nil {
		return nil, nil, fmt.Errorf("grpc.Dial() failed on %s: %w", unixPath, err)
	}

	client := delegatedapi.NewDelegatedIdentityClient(conn)
	c.delegatedIdentityClient = client

	c.logger.Debug("SPIRE Delegated Identity client successfully initialized")

	for i, selector := range c.config.Selectors {
		c.logger.Debug("subscribing with selector",
			"index", i,
			"type", selector.Type,
			"value", selector.Value,
		)
	}

	stream, err := client.SubscribeToX509SVIDs(ctx, &delegatedapi.SubscribeToX509SVIDsRequest{
		Selectors: c.config.Selectors,
	})
	if err != nil {
		c.logger.Warn("SPIRE Delegated Identity client failed to subscribe to X509 SVIDs",
			"error", err,
		)
		conn.Close()
		return nil, nil, fmt.Errorf("stream failed on %s: %w", unixPath, err)
	}

	trustStream, err := client.SubscribeToX509Bundles(ctx, &delegatedapi.SubscribeToX509BundlesRequest{})
	if err != nil {
		c.logger.Warn("SPIRE Delegated Identity client failed to subscribe to X509 bundles",
			"error", err,
		)
		conn.Close()
		return nil, nil, fmt.Errorf("stream for x509 bundle failed on %s: %w", unixPath, err)
	}

	return stream, trustStream, nil
}

func (c *Client) listenForSVIDUpdates(ctx context.Context, errorChan chan<- error) {
	c.logger.Debug("starting SVID update listener")
	for {
		select {
		case <-ctx.Done():
			c.logger.Debug("SVID update listener stopped")
			return
		default:
			resp, err := c.stream.Recv()
			if err != nil {
				c.logger.Error("error receiving SVID update", "error", err)
				errorChan <- err
				return
			}

			c.logger.Info("received X509-SVID update",
				"svid_count", len(resp.X509Svids),
			)
			c.handleX509SVIDUpdate(resp.X509Svids)
		}
	}
}

func (c *Client) listenForBundleUpdates(ctx context.Context, errorChan chan<- error) {
	c.logger.Debug("starting bundle update listener")
	for {
		select {
		case <-ctx.Done():
			c.logger.Debug("bundle update listener stopped")
			return
		default:
			resp, err := c.trustStream.Recv()
			if err != nil {
				c.logger.Error("error receiving bundle update", "error", err)
				errorChan <- err
				return
			}

			c.logger.Info("received X509-Bundle update",
				"bundle_count", len(resp.CaCertificates),
			)
			c.handleX509BundleUpdate(resp.CaCertificates)
		}
	}
}

func (c *Client) handleX509SVIDUpdate(svids []*delegatedapi.X509SVIDWithKey) {
	newSvidStore := map[string]*delegatedapi.X509SVIDWithKey{}

	c.svidStoreMutex.RLock()
	updatedKeys := []string{}
	deletedKeys := []string{}
	newKeys := []string{}

	for _, svid := range svids {
		if svid.X509Svid.Id.TrustDomain != c.config.SpiffeTrustDomain {
			c.logger.Debug("skipping X509-SVID update - trust domain mismatch",
				"expected", c.config.SpiffeTrustDomain,
				"received", svid.X509Svid.Id.TrustDomain,
			)
			c.svidStoreMutex.RUnlock()
			return
		}

		key := fmt.Sprintf("spiffe://%s%s", svid.X509Svid.Id.TrustDomain, svid.X509Svid.Id.Path)

		if _, exists := c.svidStore[key]; exists {
			old := c.svidStore[key]
			if old.X509Svid.ExpiresAt != svid.X509Svid.ExpiresAt || !equalCertChains(old.X509Svid.CertChain, svid.X509Svid.CertChain) {
				updatedKeys = append(updatedKeys, key)
				c.logger.Debug("updating existing X509-SVID",
					"spiffe_id", key,
					"expires_at", time.Unix(svid.X509Svid.ExpiresAt, 0),
				)
			}
		} else {
			newKeys = append(newKeys, key)
			c.logger.Info("adding new X509-SVID",
				"spiffe_id", key,
				"expires_at", time.Unix(svid.X509Svid.ExpiresAt, 0),
			)
			// Notify any waiters for this new SVID
			c.svidWaitersMutex.Lock()
			if waitChan, exists := c.svidWaiters[key]; exists {
				close(waitChan)
				delete(c.svidWaiters, key)
				c.logger.Debug("notified SVID waiter", "spiffe_id", key)
			}
			c.svidWaitersMutex.Unlock()
			metrics.RecordSpireSVIDReceived("x509", c.podContext)
		}
		newSvidStore[key] = svid
	}

	for key := range c.svidStore {
		if _, exists := newSvidStore[key]; !exists {
			deletedKeys = append(deletedKeys, key)
			c.logger.Info("removing deleted X509-SVID", "spiffe_id", key)
		}
	}

	c.svidStoreMutex.RUnlock()

	c.svidStoreMutex.Lock()
	c.svidStore = newSvidStore
	c.svidStoreMutex.Unlock()

	if len(newKeys) > 0 || len(updatedKeys) > 0 || len(deletedKeys) > 0 {
		c.logger.Info("X509-SVID store updated",
			"new", len(newKeys),
			"updated", len(updatedKeys),
			"deleted", len(deletedKeys),
			"total", len(newSvidStore),
		)
	}

	c.updateCacheMetrics()
}

func (c *Client) handleX509BundleUpdate(bundles map[string][]byte) {
	pool := x509.NewCertPool()

	c.parsedCertsMutex.Lock()
	defer c.parsedCertsMutex.Unlock()

	oldCertCount := 0
	for _, certs := range c.parsedCerts {
		oldCertCount += len(certs)
	}

	c.parsedCerts = make(map[string][]*x509.Certificate)
	newCertCount := 0

	for trustDomain, bundle := range bundles {
		c.logger.Debug("processing trust domain bundle",
			"trust_domain", trustDomain,
			"bundle_size", len(bundle),
		)

		certs, err := x509.ParseCertificates(bundle)
		if err != nil {
			c.logger.Error("failed to parse X.509 DER bundle",
				"trust_domain", trustDomain,
				"error", err,
			)
			continue
		}

		c.parsedCerts[trustDomain] = certs
		newCertCount += len(certs)

		for _, cert := range certs {
			pool.AddCert(cert)
			c.logger.Trace("added certificate to trust bundle",
				"trust_domain", trustDomain,
				"subject", cert.Subject,
				"not_after", cert.NotAfter,
			)
		}
	}

	c.trustBundle = pool

	c.logger.Info("trust bundle updated",
		"trust_domains", len(bundles),
		"old_cert_count", oldCertCount,
		"new_cert_count", newCertCount,
	)

	// Signal that trust bundle is ready
	c.trustBundleOnce.Do(func() {
		c.trustBundleReady = make(chan struct{})
	})
	select {
	case <-c.trustBundleReady:
		// Already closed
	default:
		close(c.trustBundleReady)
		c.logger.Debug("trust bundle ready signal sent")
	}

	metrics.RecordSpireBundleUpdate(c.podContext)
}

func (c *Client) GetTrustBundle() (*x509.CertPool, error) {
	if c.trustBundle == nil {
		c.logger.Warn("trust bundle requested but not yet available")
		return nil, errors.New("trust bundle not yet available")
	}
	return c.trustBundle, nil
}

func (c *Client) GetCertificateForIdentity(spiffeID string) (*tls.Certificate, error) {
	c.logger.Debug("getting certificate for identity", "spiffe_id", spiffeID)

	c.svidStoreMutex.RLock()
	svid, ok := c.svidStore[spiffeID]
	c.svidStoreMutex.RUnlock()
	if !ok {
		c.logger.Error("no SVID found for identity", "spiffe_id", spiffeID)
		return nil, fmt.Errorf("no SPIFFE ID for %s", spiffeID)
	}

	if len(svid.X509Svid.CertChain) == 0 {
		c.logger.Error("empty certificate chain", "spiffe_id", spiffeID)
		return nil, fmt.Errorf("no certificate chain inside %s", spiffeID)
	}

	var leafCert *x509.Certificate
	for _, cert := range svid.X509Svid.CertChain {
		cert, err := x509.ParseCertificate(cert)
		if err != nil {
			c.logger.Error("failed to parse certificate",
				"spiffe_id", spiffeID,
				"error", err,
			)
			return nil, fmt.Errorf("failed to parse certificate: %w", err)
		}

		if !cert.IsCA {
			leafCert = cert
			break
		}
	}
	if leafCert == nil {
		c.logger.Error("no leaf certificate found", "spiffe_id", spiffeID)
		return nil, fmt.Errorf("no leaf certificate inside %s", spiffeID)
	}

	privKey, err := x509.ParsePKCS8PrivateKey(svid.X509SvidKey)
	if err != nil {
		c.logger.Error("failed to parse private key",
			"spiffe_id", spiffeID,
			"error", err,
		)
		return nil, fmt.Errorf("failed to parse private key of %s: %w", spiffeID, err)
	}

	c.logger.Debug("successfully retrieved certificate",
		"spiffe_id", spiffeID,
		"not_after", leafCert.NotAfter,
	)

	return &tls.Certificate{
		Certificate: svid.X509Svid.CertChain,
		PrivateKey:  privKey,
		Leaf:        leafCert,
	}, nil
}

func (c *Client) Status() (bool, string) {
	c.connectedMutex.RLock()
	defer c.connectedMutex.RUnlock()

	if !c.connected {
		msg := "Not connected to SPIRE server"
		if c.lastConnectError != nil {
			msg = fmt.Sprintf("Cannot connect to SPIRE server: %q", c.lastConnectError)
		}
		c.logger.Debug("connection status check", "connected", false, "message", msg)
		return false, msg
	}

	c.logger.Trace("connection status check", "connected", true)
	return true, "Connected to SPIRE server"
}

func (c *Client) updateCacheMetrics() {
	c.jwtSVIDCacheMutex.RLock()
	jwtCacheSize := len(c.jwtSVIDCache)
	c.jwtSVIDCacheMutex.RUnlock()

	c.svidStoreMutex.RLock()
	svidCacheSize := len(c.svidStore)
	c.svidStoreMutex.RUnlock()

	metrics.UpdateCacheSizes(jwtCacheSize, svidCacheSize, c.podContext)
}

func equalCertChains(a, b [][]byte) bool {
	if len(a) != len(b) {
		return false
	}
	for i := range a {
		if !bytes.Equal(a[i], b[i]) {
			return false
		}
	}
	return true
}
</file>

<file path="client/dual_agent_client_test.go">
package client

import (
	"context"
	"crypto/tls"
	"errors"
	"testing"
	"time"

	"github.com/golang/mock/gomock"
	"github.com/hashicorp/go-hclog"
)

func TestNewDualAgentClient(t *testing.T) {
	tests := []struct {
		name    string
		config  Config
		wantErr bool
		errMsg  string
	}{
		{
			name: "valid dual agent config",
			config: Config{
				SpireSocketPath:   "/socket1",
				SpireSocketPath2:  "/socket2",
				SpiffeTrustDomain: "example.org",
			},
			wantErr: false,
		},
		{
			name: "missing second socket path",
			config: Config{
				SpireSocketPath:   "/socket1",
				SpiffeTrustDomain: "example.org",
			},
			wantErr: true,
			errMsg:  "second socket path is required",
		},
		{
			name: "missing first socket path",
			config: Config{
				SpireSocketPath2:  "/socket2",
				SpiffeTrustDomain: "example.org",
			},
			wantErr: true,
			errMsg:  "SPIRE socket path not specified",
		},
		{
			name: "missing trust domain",
			config: Config{
				SpireSocketPath:  "/socket1",
				SpireSocketPath2: "/socket2",
			},
			wantErr: true,
			errMsg:  "SPIRE trust domain not specified",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()

			client, err := NewDualAgentClient(logger, tt.config)

			if tt.wantErr {
				if err == nil {
					t.Error("Expected error but got none")
				} else if tt.errMsg != "" && !contains(err.Error(), tt.errMsg) {
					t.Errorf("Expected error containing %q, got %q", tt.errMsg, err.Error())
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
				if client == nil {
					t.Error("Expected client to be created")
				} else {
					// Verify both clients are initialized
					if client.client1 == nil || client.client2 == nil {
						t.Error("Both clients should be initialized")
					}
					// Verify configs are set correctly
					if client.config.SpireSocketPath != tt.config.SpireSocketPath {
						t.Error("First socket path not set correctly")
					}
					if client.config.SpireSocketPath2 != tt.config.SpireSocketPath2 {
						t.Error("Second socket path not set correctly")
					}
				}
			}
		})
	}
}

func TestDualAgentClient_Start(t *testing.T) {
	tests := []struct {
		name         string
		client1Error error
		client2Error error
		expectError  bool
	}{
		{
			name:        "both clients start successfully",
			expectError: false,
		},
		{
			name:         "client1 fails",
			client1Error: errors.New("client1 start failed"),
			expectError:  false, // Should still succeed if one client starts
		},
		{
			name:         "client2 fails",
			client2Error: errors.New("client2 start failed"),
			expectError:  false, // Should still succeed if one client starts
		},
		{
			name:         "both clients fail",
			client1Error: errors.New("client1 start failed"),
			client2Error: errors.New("client2 start failed"),
			expectError:  true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()

			mockClient1 := NewMockSpireClient(ctrl)
			mockClient1.EXPECT().Start(gomock.Any()).Return(tt.client1Error)

			mockClient2 := NewMockSpireClient(ctrl)
			mockClient2.EXPECT().Start(gomock.Any()).Return(tt.client2Error)

			dac := &DualAgentClient{
				logger:  logger,
				client1: mockClient1,
				client2: mockClient2,
			}

			ctx := context.Background()
			err := dac.Start(ctx)

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
			}
		})
	}
}

func TestDualAgentClient_WaitForSVID(t *testing.T) {
	tests := []struct {
		name         string
		client1Error error
		client2Error error
		expectError  bool
	}{
		{
			name:        "client1 succeeds",
			expectError: false,
		},
		{
			name:         "client1 fails, client2 succeeds",
			client1Error: errors.New("client1 failed"),
			expectError:  false,
		},
		{
			name:         "both clients fail",
			client1Error: errors.New("client1 failed"),
			client2Error: errors.New("client2 failed"),
			expectError:  true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()

			mockClient1 := NewMockSpireClient(ctrl)
			mockClient2 := NewMockSpireClient(ctrl)

			// Set up expectations with MaxTimes for flexibility
			mockClient1.EXPECT().
				WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).
				Return(tt.client1Error).
				MaxTimes(1)

			if tt.client1Error != nil {
				// Only expect client2 call if client1 fails
				mockClient2.EXPECT().
					WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).
					Return(tt.client2Error).
					MaxTimes(1)
			}

			dac := &DualAgentClient{
				logger:  logger,
				client1: mockClient1,
				client2: mockClient2,
			}

			ctx := context.Background()
			err := dac.WaitForSVID(ctx, "spiffe://example.org/test", 1*time.Second)

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
			}
		})
	}
}

//func TestDualAgentClient_WaitForSVID(t *testing.T) {
//	tests := []struct {
//		name         string
//		client1Error error
//		client2Error error
//		expectError  bool
//	}{
//		{
//			name:        "client1 succeeds",
//			expectError: false,
//		},
//		{
//			name:         "client1 fails, client2 succeeds",
//			client1Error: errors.New("client1 failed"),
//			expectError:  false,
//		},
//		{
//			name:         "both clients fail",
//			client1Error: errors.New("client1 failed"),
//			client2Error: errors.New("client2 failed"),
//			expectError:  true,
//		},
//	}
//
//	for _, tt := range tests {
//		t.Run(tt.name, func(t *testing.T) {
//			ctrl := gomock.NewController(t)
//			defer ctrl.Finish()
//
//			logger := hclog.NewNullLogger()
//
//			mockClient1 := NewMockSpireClient(ctrl)
//			mockClient1.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(tt.client1Error)
//
//			mockClient2 := NewMockSpireClient(ctrl)
//			if tt.client1Error != nil {
//				mockClient2.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(tt.client2Error)
//			}
//
//			dac := &DualAgentClient{
//				logger:  logger,
//				client1: mockClient1,
//				client2: mockClient2,
//			}
//
//			ctx := context.Background()
//			err := dac.WaitForSVID(ctx, "spiffe://example.org/test", 1*time.Second)
//
//			if tt.expectError {
//				if err == nil {
//					t.Error("Expected error but got none")
//				}
//			} else {
//				if err != nil {
//					t.Errorf("Unexpected error: %v", err)
//				}
//			}
//		})
//	}
//}

func TestDualAgentClient_GetCertificateForIdentity(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()

	cert := &tls.Certificate{
		Certificate: [][]byte{[]byte("test-cert")},
	}

	tests := []struct {
		name          string
		client1Return *tls.Certificate
		client1Error  error
		client2Return *tls.Certificate
		client2Error  error
		expectError   bool
	}{
		{
			name:          "client1 returns certificate",
			client1Return: cert,
			expectError:   false,
		},
		{
			name:          "client1 fails, client2 succeeds",
			client1Error:  errors.New("client1 failed"),
			client2Return: cert,
			expectError:   false,
		},
		{
			name:         "both clients fail",
			client1Error: errors.New("client1 failed"),
			client2Error: errors.New("client2 failed"),
			expectError:  true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			mockClient1 := NewMockSpireClient(ctrl)
			mockClient1.EXPECT().GetCertificateForIdentity(gomock.Any()).Return(tt.client1Return, tt.client1Error)

			mockClient2 := NewMockSpireClient(ctrl)
			if tt.client1Error != nil {
				mockClient2.EXPECT().GetCertificateForIdentity(gomock.Any()).Return(tt.client2Return, tt.client2Error)
			}

			dac := &DualAgentClient{
				logger:  logger,
				client1: mockClient1,
				client2: mockClient2,
			}

			result, err := dac.GetCertificateForIdentity("spiffe://example.org/test")

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
				if result == nil {
					t.Error("Expected certificate but got nil")
				}
			}
		})
	}
}

func TestDualAgentClient_FetchJWTSVID(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()

	tests := []struct {
		name         string
		client1Token string
		client1Error error
		client2Token string
		client2Error error
		expectError  bool
		expectToken  string
	}{
		{
			name:         "client1 returns token",
			client1Token: "token-from-client1",
			expectToken:  "token-from-client1",
			expectError:  false,
		},
		{
			name:         "client1 fails, client2 succeeds",
			client1Error: errors.New("client1 failed"),
			client2Token: "token-from-client2",
			expectToken:  "token-from-client2",
			expectError:  false,
		},
		{
			name:         "both clients fail",
			client1Error: errors.New("client1 failed"),
			client2Error: errors.New("client2 failed"),
			expectError:  true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			mockClient1 := NewMockSpireClient(ctrl)
			mockClient1.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), gomock.Any()).
				Return(tt.client1Token, tt.client1Error)

			mockClient2 := NewMockSpireClient(ctrl)
			mockClient2.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), gomock.Any()).
				Return(tt.client2Token, tt.client2Error)

			dac := &DualAgentClient{
				logger:  logger,
				client1: mockClient1,
				client2: mockClient2,
			}

			ctx := context.Background()
			token, err := dac.FetchJWTSVID(ctx, "spiffe://example.org/test", []string{"audience1"})

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
				if token != tt.expectToken {
					t.Errorf("Expected token %q, got %q", tt.expectToken, token)
				}
			}
		})
	}
}

func TestDualAgentClient_Status(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	tests := []struct {
		name            string
		client1Status   bool
		client1Msg      string
		client2Status   bool
		client2Msg      string
		expectedStatus  bool
		expectedMsgPart string
	}{
		{
			name:            "both connected",
			client1Status:   true,
			client1Msg:      "Connected",
			client2Status:   true,
			client2Msg:      "Connected",
			expectedStatus:  true,
			expectedMsgPart: "Both agents connected",
		},
		{
			name:            "only client1 connected",
			client1Status:   true,
			client1Msg:      "Connected",
			client2Status:   false,
			client2Msg:      "Not connected",
			expectedStatus:  true,
			expectedMsgPart: "Agent1 connected",
		},
		{
			name:            "only client2 connected",
			client1Status:   false,
			client1Msg:      "Not connected",
			client2Status:   true,
			client2Msg:      "Connected",
			expectedStatus:  true,
			expectedMsgPart: "Agent2 connected",
		},
		{
			name:            "both disconnected",
			client1Status:   false,
			client1Msg:      "Connection failed",
			client2Status:   false,
			client2Msg:      "Connection failed",
			expectedStatus:  false,
			expectedMsgPart: "Both agents disconnected",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			mockClient1 := NewMockSpireClient(ctrl)
			mockClient1.EXPECT().Status().Return(tt.client1Status, tt.client1Msg)

			mockClient2 := NewMockSpireClient(ctrl)
			mockClient2.EXPECT().Status().Return(tt.client2Status, tt.client2Msg)

			dac := &DualAgentClient{
				logger:  hclog.NewNullLogger(),
				client1: mockClient1,
				client2: mockClient2,
			}

			status, msg := dac.Status()

			if status != tt.expectedStatus {
				t.Errorf("Expected status %v, got %v", tt.expectedStatus, status)
			}
			if !contains(msg, tt.expectedMsgPart) {
				t.Errorf("Expected message containing %q, got %q", tt.expectedMsgPart, msg)
			}
		})
	}
}

func TestDualAgentClient_Stop(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	tests := []struct {
		name         string
		client1Error error
		client2Error error
		expectError  bool
	}{
		{
			name:        "both clients stop successfully",
			expectError: false,
		},
		{
			name:         "client1 fails to stop",
			client1Error: errors.New("stop failed"),
			expectError:  true,
		},
		{
			name:         "client2 fails to stop",
			client2Error: errors.New("stop failed"),
			expectError:  true,
		},
		{
			name:         "both clients fail to stop",
			client1Error: errors.New("client1 stop failed"),
			client2Error: errors.New("client2 stop failed"),
			expectError:  true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			mockClient1 := NewMockSpireClient(ctrl)
			mockClient1.EXPECT().Stop().Return(tt.client1Error)

			mockClient2 := NewMockSpireClient(ctrl)
			mockClient2.EXPECT().Stop().Return(tt.client2Error)

			dac := &DualAgentClient{
				logger:  hclog.NewNullLogger(),
				client1: mockClient1,
				client2: mockClient2,
			}

			err := dac.Stop()

			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				}
			} else {
				if err != nil {
					t.Errorf("Unexpected error: %v", err)
				}
			}
		})
	}
}
</file>

<file path="client/dual_agent_client.go">
package client

import (
	"context"
	"crypto/tls"
	"crypto/x509"
	"errors"
	"fmt"
	"time"

	"github.com/hashicorp/go-hclog"
)

// DualAgentClient implements SpireClient interface with two SPIRE agents
type DualAgentClient struct {
	logger  hclog.Logger
	config  Config
	client1 SpireClient
	client2 SpireClient

	// For managing concurrent operations
	cancelFunc context.CancelFunc
}

// NewDualAgentClient creates a new dual agent client
func NewDualAgentClient(logger hclog.Logger, config Config) (*DualAgentClient, error) {
	if config.SpireSocketPath2 == "" {
		return nil, errors.New("second socket path is required for dual agent client")
	}

	dac := &DualAgentClient{
		logger: logger.Named("dual-agent"),
		config: config,
	}

	config1 := config
	config1.SpireSocketPath = config.SpireSocketPath
	client1, err := New(logger.Named("agent1"), config1)
	if err != nil {
		return nil, fmt.Errorf("failed to create client1: %w", err)
	}
	dac.client1 = client1

	config2 := config
	config2.SpireSocketPath = config.SpireSocketPath2
	client2, err := New(logger.Named("agent2"), config2)
	if err != nil {
		return nil, fmt.Errorf("failed to create client2: %w", err)
	}
	dac.client2 = client2

	dac.logger.Info("dual agent client created",
		"socket1", config.SpireSocketPath,
		"socket2", config.SpireSocketPath2)

	return dac, nil
}

// Start starts both clients
func (dac *DualAgentClient) Start(ctx context.Context) error {
	ctx, cancel := context.WithCancel(ctx)
	dac.cancelFunc = cancel

	errChan := make(chan error, 2)

	go func() {
		if err := dac.client1.Start(ctx); err != nil {
			errChan <- fmt.Errorf("client1 start failed: %w", err)
		} else {
			errChan <- nil
		}
	}()

	go func() {
		if err := dac.client2.Start(ctx); err != nil {
			errChan <- fmt.Errorf("client2 start failed: %w", err)
		} else {
			errChan <- nil
		}
	}()

	// Wait for at least one client to start successfully
	var errors []error
	for i := 0; i < 2; i++ {
		if err := <-errChan; err != nil {
			errors = append(errors, err)
			dac.logger.Warn("client failed to start", "error", err)
		}
	}

	if len(errors) == 2 {
		return fmt.Errorf("both clients failed to start: %v", errors)
	}

	dac.logger.Info("dual agent client started successfully")
	return nil
}

// WaitForSVID waits for SVID from either client
func (dac *DualAgentClient) WaitForSVID(ctx context.Context, spiffeID string, timeout time.Duration) error {
	ctx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	errChan := make(chan error, 2)

	go func() {
		errChan <- dac.client1.WaitForSVID(ctx, spiffeID, timeout)
	}()

	go func() {
		errChan <- dac.client2.WaitForSVID(ctx, spiffeID, timeout)
	}()

	// Return when first client succeeds
	for i := 0; i < 2; i++ {
		select {
		case err := <-errChan:
			if err == nil {
				return nil
			}
			dac.logger.Debug("client failed to provide SVID",
				"spiffe_id", spiffeID,
				"error", err)
		case <-ctx.Done():
			return fmt.Errorf("timeout waiting for SVID %s", spiffeID)
		}
	}

	return fmt.Errorf("no client could provide SVID for %s", spiffeID)
}

// WaitForTrustBundle waits for trust bundle from either client
func (dac *DualAgentClient) WaitForTrustBundle(ctx context.Context, timeout time.Duration) error {
	ctx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	errChan := make(chan error, 2)

	go func() {
		errChan <- dac.client1.WaitForTrustBundle(ctx, timeout)
	}()

	go func() {
		errChan <- dac.client2.WaitForTrustBundle(ctx, timeout)
	}()

	// Return when first client succeeds
	for i := 0; i < 2; i++ {
		select {
		case err := <-errChan:
			if err == nil {
				return nil
			}
			dac.logger.Debug("client failed to provide trust bundle", "error", err)
		case <-ctx.Done():
			return fmt.Errorf("timeout waiting for trust bundle")
		}
	}

	return fmt.Errorf("no client could provide trust bundle")
}

// GetCACertificates returns CA certificates from first available client
func (dac *DualAgentClient) GetCACertificates(ctx context.Context) ([]*x509.Certificate, error) {
	// Try client1 first
	certs, err := dac.client1.GetCACertificates(ctx)
	if err == nil {
		return certs, nil
	}

	// Fallback to client2
	certs, err = dac.client2.GetCACertificates(ctx)
	if err == nil {
		return certs, nil
	}

	return nil, fmt.Errorf("failed to get CA certificates from any client")
}

// GetCertificateForIdentity returns certificate from first available client
func (dac *DualAgentClient) GetCertificateForIdentity(spiffeID string) (*tls.Certificate, error) {
	// Try client1 first
	cert, err := dac.client1.GetCertificateForIdentity(spiffeID)
	if err == nil {
		return cert, nil
	}

	dac.logger.Debug("client1 failed to provide certificate, trying client2",
		"spiffe_id", spiffeID,
		"error", err)

	// Fallback to client2
	cert, err = dac.client2.GetCertificateForIdentity(spiffeID)
	if err == nil {
		return cert, nil
	}

	return nil, fmt.Errorf("failed to get certificate from any client")
}

// FetchJWTSVID fetches JWT SVID from both clients concurrently
func (dac *DualAgentClient) FetchJWTSVID(ctx context.Context, spiffeID string, audiences []string) (string, error) {
	type result struct {
		token  string
		err    error
		client string
	}

	resultChan := make(chan result, 2)

	// Fetch from both clients concurrently
	go func() {
		token, err := dac.client1.FetchJWTSVID(ctx, spiffeID, audiences)
		resultChan <- result{token: token, err: err, client: "agent1"}
	}()

	go func() {
		token, err := dac.client2.FetchJWTSVID(ctx, spiffeID, audiences)
		resultChan <- result{token: token, err: err, client: "agent2"}
	}()

	// Return first successful response
	for i := 0; i < 2; i++ {
		select {
		case res := <-resultChan:
			if res.err == nil && res.token != "" {
				dac.logger.Debug("successfully fetched JWT SVID",
					"client", res.client,
					"spiffe_id", spiffeID)
				return res.token, nil
			}
			dac.logger.Warn("client failed to fetch JWT SVID",
				"client", res.client,
				"spiffe_id", spiffeID,
				"error", res.err)
		case <-time.After(30 * time.Second):
			return "", fmt.Errorf("timeout waiting for JWT SVID")
		case <-ctx.Done():
			return "", ctx.Err()
		}
	}

	return "", fmt.Errorf("failed to fetch JWT SVID from any client")
}

// GetTrustBundle returns trust bundle from first available client
func (dac *DualAgentClient) GetTrustBundle() (*x509.CertPool, error) {
	bundle, err := dac.client1.GetTrustBundle()
	if err == nil {
		return bundle, nil
	}

	bundle, err = dac.client2.GetTrustBundle()
	if err == nil {
		return bundle, nil
	}

	return nil, fmt.Errorf("failed to get trust bundle from any client")
}

// Status returns combined status of both clients
func (dac *DualAgentClient) Status() (bool, string) {
	connected1, msg1 := dac.client1.Status()
	connected2, msg2 := dac.client2.Status()

	if connected1 && connected2 {
		return true, "Both agents connected"
	} else if connected1 {
		return true, fmt.Sprintf("Agent1 connected, Agent2: %s", msg2)
	} else if connected2 {
		return true, fmt.Sprintf("Agent2 connected, Agent1: %s", msg1)
	}

	return false, fmt.Sprintf("Both agents disconnected - Agent1: %s, Agent2: %s", msg1, msg2)
}

// Stop stops both clients
func (dac *DualAgentClient) Stop() error {
	dac.logger.Info("stopping dual agent client")

	if dac.cancelFunc != nil {
		dac.cancelFunc()
	}

	// Stop both clients
	var errors []error

	if err := dac.client1.Stop(); err != nil {
		errors = append(errors, fmt.Errorf("failed to stop client1: %w", err))
	}

	if err := dac.client2.Stop(); err != nil {
		errors = append(errors, fmt.Errorf("failed to stop client2: %w", err))
	}

	if len(errors) > 0 {
		return fmt.Errorf("errors during shutdown: %v", errors)
	}

	return nil
}
</file>

<file path="client/factory_test.go">
// internal/client/factory_test.go
package client

import (
	"testing"
	"github.com/hashicorp/go-hclog"
)

func TestNewSpireClient_Factory(t *testing.T) {
	tests := []struct {
		name            string
		config          Config
		expectDualAgent bool
		expectError     bool
	}{
		{
			name: "single agent client",
			config: Config{
				SpireSocketPath:   "/socket",
				SpiffeTrustDomain: "example.org",
			},
			expectDualAgent: false,
			expectError:     false,
		},
		{
			name: "dual agent client",
			config: Config{
				SpireSocketPath:   "/socket1",
				SpireSocketPath2:  "/socket2",
				SpiffeTrustDomain: "example.org",
			},
			expectDualAgent: true,
			expectError:     false,
		},
		{
			name: "missing socket path",
			config: Config{
				SpiffeTrustDomain: "example.org",
			},
			expectError: true,
		},
		{
			name: "missing trust domain",
			config: Config{
				SpireSocketPath: "/socket",
			},
			expectError: true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			
			// Call the actual factory function
			client, err := NewSpireClient(logger, tt.config)
			
			if tt.expectError {
				if err == nil {
					t.Error("Expected error but got none")
				}
				return
			}
			
			if err != nil {
				t.Fatalf("Unexpected error: %v", err)
			}
			
			if client == nil {
				t.Fatal("Expected client to be created")
			}
			
			// Check the type of client returned
			switch c := client.(type) {
			case *DualAgentClient:
				if !tt.expectDualAgent {
					t.Error("Expected single agent client, got dual agent")
				}
				// Verify it has both socket paths
				if c.config.SpireSocketPath == "" || c.config.SpireSocketPath2 == "" {
					t.Error("Dual agent client should have both socket paths")
				}
			case *Client:
				if tt.expectDualAgent {
					t.Error("Expected dual agent client, got single agent")
				}
				// Verify it has only one socket path
				if c.config.SpireSocketPath == "" {
					t.Error("Single agent client should have socket path")
				}
				if c.config.SpireSocketPath2 != "" {
					t.Error("Single agent client should not have second socket path")
				}
			default:
				t.Errorf("Unexpected client type: %T", client)
			}
		})
	}
}

// Test that both New and NewDualAgentClient work correctly
func TestClientConstructors(t *testing.T) {
	logger := hclog.NewNullLogger()
	
	t.Run("New creates single agent client", func(t *testing.T) {
		config := Config{
			SpireSocketPath:   "/socket",
			SpiffeTrustDomain: "example.org",
		}
		
		client, err := New(logger, config)
		if err != nil {
			t.Fatalf("Unexpected error: %v", err)
		}
		
		if client == nil {
			t.Fatal("Expected client to be created")
		}
		
		if client.config.SpireSocketPath != config.SpireSocketPath {
			t.Error("Socket path not set correctly")
		}
	})
	
	t.Run("NewDualAgentClient creates dual agent client", func(t *testing.T) {
		config := Config{
			SpireSocketPath:   "/socket1",
			SpireSocketPath2:  "/socket2",
			SpiffeTrustDomain: "example.org",
		}
		
		client, err := NewDualAgentClient(logger, config)
		if err != nil {
			t.Fatalf("Unexpected error: %v", err)
		}
		
		if client == nil {
			t.Fatal("Expected client to be created")
		}
		
		if client.config.SpireSocketPath != config.SpireSocketPath {
			t.Error("First socket path not set correctly")
		}
		
		if client.config.SpireSocketPath2 != config.SpireSocketPath2 {
			t.Error("Second socket path not set correctly")
		}
	})
}
</file>

<file path="client/factory.go">
package client

import (
	"github.com/hashicorp/go-hclog"
)

// NewSpireClient creates either a Client or DualAgentClient based on configuration
func NewSpireClient(logger hclog.Logger, config Config) (SpireClient, error) {
	// If second socket path is provided, create DualAgentClient
	if config.SpireSocketPath2 != "" {
		logger.Info("creating dual agent client",
			"socket1", config.SpireSocketPath,
			"socket2", config.SpireSocketPath2)
		return NewDualAgentClient(logger, config)
	}

	// Otherwise create regular client
	logger.Info("creating single agent client",
		"socket", config.SpireSocketPath)
	return New(logger, config)
}
</file>

<file path="client/interface.go">
package client

import (
	"context"
	"crypto/tls"
	"crypto/x509"
	"time"
)

// SpireClient defines the interface for interacting with SPIRE agents
type SpireClient interface {
	// Start initializes the client and begins receiving updates
	Start(ctx context.Context) error

	// Stop gracefully shuts down the client
	Stop() error

	// WaitForSVID waits for the specified SVID to be available
	WaitForSVID(ctx context.Context, spiffeID string, timeout time.Duration) error

	// WaitForTrustBundle waits for the trust bundle to be available
	WaitForTrustBundle(ctx context.Context, timeout time.Duration) error

	// GetCACertificates returns the current CA certificates
	GetCACertificates(ctx context.Context) ([]*x509.Certificate, error)

	// GetCertificateForIdentity returns the certificate for the specified SPIFFE ID
	GetCertificateForIdentity(spiffeID string) (*tls.Certificate, error)

	// FetchJWTSVID fetches a JWT SVID for the specified SPIFFE ID and audiences
	FetchJWTSVID(ctx context.Context, spiffeID string, audiences []string) (string, error)

	// GetTrustBundle returns the current trust bundle
	GetTrustBundle() (*x509.CertPool, error)

	// Status returns the connection status
	Status() (bool, string)
}
</file>

<file path="client/mock_client_pool.go">
// Code generated by MockGen. DO NOT EDIT.
// Source: internal/client/pool_interface.go

// Package client is a generated GoMock package.
package client

import (
	context "context"
	reflect "reflect"

	gomock "github.com/golang/mock/gomock"
)

// MockClientPoolInterface is a mock of ClientPoolInterface interface.
type MockClientPoolInterface struct {
	ctrl     *gomock.Controller
	recorder *MockClientPoolInterfaceMockRecorder
}

// MockClientPoolInterfaceMockRecorder is the mock recorder for MockClientPoolInterface.
type MockClientPoolInterfaceMockRecorder struct {
	mock *MockClientPoolInterface
}

// NewMockClientPoolInterface creates a new mock instance.
func NewMockClientPoolInterface(ctrl *gomock.Controller) *MockClientPoolInterface {
	mock := &MockClientPoolInterface{ctrl: ctrl}
	mock.recorder = &MockClientPoolInterfaceMockRecorder{mock}
	return mock
}

// EXPECT returns an object that allows the caller to indicate expected use.
func (m *MockClientPoolInterface) EXPECT() *MockClientPoolInterfaceMockRecorder {
	return m.recorder
}

// AcquireClient mocks base method.
func (m *MockClientPoolInterface) AcquireClient(ctx context.Context, config Config) (SpireClient, error) {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "AcquireClient", ctx, config)
	ret0, _ := ret[0].(SpireClient)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}

// AcquireClient indicates an expected call of AcquireClient.
func (mr *MockClientPoolInterfaceMockRecorder) AcquireClient(ctx, config interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "AcquireClient", reflect.TypeOf((*MockClientPoolInterface)(nil).AcquireClient), ctx, config)
}

// GetPoolStats mocks base method.
func (m *MockClientPoolInterface) GetPoolStats() map[string]interface{} {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "GetPoolStats")
	ret0, _ := ret[0].(map[string]interface{})
	return ret0
}

// GetPoolStats indicates an expected call of GetPoolStats.
func (mr *MockClientPoolInterfaceMockRecorder) GetPoolStats() *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "GetPoolStats", reflect.TypeOf((*MockClientPoolInterface)(nil).GetPoolStats))
}

// ReleaseClient mocks base method.
func (m *MockClientPoolInterface) ReleaseClient(config Config) {
	m.ctrl.T.Helper()
	m.ctrl.Call(m, "ReleaseClient", config)
}

// ReleaseClient indicates an expected call of ReleaseClient.
func (mr *MockClientPoolInterfaceMockRecorder) ReleaseClient(config interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "ReleaseClient", reflect.TypeOf((*MockClientPoolInterface)(nil).ReleaseClient), config)
}

// Shutdown mocks base method.
func (m *MockClientPoolInterface) Shutdown() error {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "Shutdown")
	ret0, _ := ret[0].(error)
	return ret0
}

// Shutdown indicates an expected call of Shutdown.
func (mr *MockClientPoolInterfaceMockRecorder) Shutdown() *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "Shutdown", reflect.TypeOf((*MockClientPoolInterface)(nil).Shutdown))
}
</file>

<file path="client/mock_spire_client.go">
// Code generated by MockGen. DO NOT EDIT.
// Source: internal/client/interface.go

// Package client is a generated GoMock package.
package client

import (
	context "context"
	tls "crypto/tls"
	x509 "crypto/x509"
	reflect "reflect"
	time "time"

	gomock "github.com/golang/mock/gomock"
)

// MockSpireClient is a mock of SpireClient interface.
type MockSpireClient struct {
	ctrl     *gomock.Controller
	recorder *MockSpireClientMockRecorder
}

// MockSpireClientMockRecorder is the mock recorder for MockSpireClient.
type MockSpireClientMockRecorder struct {
	mock *MockSpireClient
}

// NewMockSpireClient creates a new mock instance.
func NewMockSpireClient(ctrl *gomock.Controller) *MockSpireClient {
	mock := &MockSpireClient{ctrl: ctrl}
	mock.recorder = &MockSpireClientMockRecorder{mock}
	return mock
}

// EXPECT returns an object that allows the caller to indicate expected use.
func (m *MockSpireClient) EXPECT() *MockSpireClientMockRecorder {
	return m.recorder
}

// FetchJWTSVID mocks base method.
func (m *MockSpireClient) FetchJWTSVID(ctx context.Context, spiffeID string, audiences []string) (string, error) {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "FetchJWTSVID", ctx, spiffeID, audiences)
	ret0, _ := ret[0].(string)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}

// FetchJWTSVID indicates an expected call of FetchJWTSVID.
func (mr *MockSpireClientMockRecorder) FetchJWTSVID(ctx, spiffeID, audiences interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "FetchJWTSVID", reflect.TypeOf((*MockSpireClient)(nil).FetchJWTSVID), ctx, spiffeID, audiences)
}

// GetCACertificates mocks base method.
func (m *MockSpireClient) GetCACertificates(ctx context.Context) ([]*x509.Certificate, error) {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "GetCACertificates", ctx)
	ret0, _ := ret[0].([]*x509.Certificate)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}

// GetCACertificates indicates an expected call of GetCACertificates.
func (mr *MockSpireClientMockRecorder) GetCACertificates(ctx interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "GetCACertificates", reflect.TypeOf((*MockSpireClient)(nil).GetCACertificates), ctx)
}

// GetCertificateForIdentity mocks base method.
func (m *MockSpireClient) GetCertificateForIdentity(spiffeID string) (*tls.Certificate, error) {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "GetCertificateForIdentity", spiffeID)
	ret0, _ := ret[0].(*tls.Certificate)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}

// GetCertificateForIdentity indicates an expected call of GetCertificateForIdentity.
func (mr *MockSpireClientMockRecorder) GetCertificateForIdentity(spiffeID interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "GetCertificateForIdentity", reflect.TypeOf((*MockSpireClient)(nil).GetCertificateForIdentity), spiffeID)
}

// GetTrustBundle mocks base method.
func (m *MockSpireClient) GetTrustBundle() (*x509.CertPool, error) {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "GetTrustBundle")
	ret0, _ := ret[0].(*x509.CertPool)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}

// GetTrustBundle indicates an expected call of GetTrustBundle.
func (mr *MockSpireClientMockRecorder) GetTrustBundle() *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "GetTrustBundle", reflect.TypeOf((*MockSpireClient)(nil).GetTrustBundle))
}

// Start mocks base method.
func (m *MockSpireClient) Start(ctx context.Context) error {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "Start", ctx)
	ret0, _ := ret[0].(error)
	return ret0
}

// Start indicates an expected call of Start.
func (mr *MockSpireClientMockRecorder) Start(ctx interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "Start", reflect.TypeOf((*MockSpireClient)(nil).Start), ctx)
}

// Status mocks base method.
func (m *MockSpireClient) Status() (bool, string) {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "Status")
	ret0, _ := ret[0].(bool)
	ret1, _ := ret[1].(string)
	return ret0, ret1
}

// Status indicates an expected call of Status.
func (mr *MockSpireClientMockRecorder) Status() *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "Status", reflect.TypeOf((*MockSpireClient)(nil).Status))
}

// Stop mocks base method.
func (m *MockSpireClient) Stop() error {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "Stop")
	ret0, _ := ret[0].(error)
	return ret0
}

// Stop indicates an expected call of Stop.
func (mr *MockSpireClientMockRecorder) Stop() *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "Stop", reflect.TypeOf((*MockSpireClient)(nil).Stop))
}

// WaitForSVID mocks base method.
func (m *MockSpireClient) WaitForSVID(ctx context.Context, spiffeID string, timeout time.Duration) error {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "WaitForSVID", ctx, spiffeID, timeout)
	ret0, _ := ret[0].(error)
	return ret0
}

// WaitForSVID indicates an expected call of WaitForSVID.
func (mr *MockSpireClientMockRecorder) WaitForSVID(ctx, spiffeID, timeout interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "WaitForSVID", reflect.TypeOf((*MockSpireClient)(nil).WaitForSVID), ctx, spiffeID, timeout)
}

// WaitForTrustBundle mocks base method.
func (m *MockSpireClient) WaitForTrustBundle(ctx context.Context, timeout time.Duration) error {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "WaitForTrustBundle", ctx, timeout)
	ret0, _ := ret[0].(error)
	return ret0
}

// WaitForTrustBundle indicates an expected call of WaitForTrustBundle.
func (mr *MockSpireClientMockRecorder) WaitForTrustBundle(ctx, timeout interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "WaitForTrustBundle", reflect.TypeOf((*MockSpireClient)(nil).WaitForTrustBundle), ctx, timeout)
}
</file>

<file path="client/pool_interface.go">
package client

import (
	"context"
)

// ClientPoolInterface defines the interface for client pool operations
type ClientPoolInterface interface {
	AcquireClient(ctx context.Context, config Config) (SpireClient, error)
	ReleaseClient(config Config)
	Shutdown() error
	GetPoolStats() map[string]interface{}
}
</file>

<file path="config/config_test.go">
package config

import (
	"encoding/json"
	"os"
	"testing"
)

func TestParse(t *testing.T) {
	tests := []struct {
		name          string
		parametersStr string
		targetPath    string
		permissionStr string
		want          Config
		wantErr       bool
		errorContains string
	}{
		{
			name: "valid configuration with x509-svid",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: x509-svid
  type: x509-svid
  filePermission: 0644
  paths:
    - /cert.pem
    - /key.pem
    - /bundle.pem`,
			}),
			targetPath: "/var/run/secrets",
			// 0644 in decimal
			permissionStr: "420",
			want: Config{
				TargetPath:     "/var/run/secrets",
				FilePermission: 0644,
				Parameters: Parameters{
					UseCase:     "default",
					TrustDomain: "example.org",
					Selectors: []Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test-sa"},
						{Type: "k8s", Value: "pod-uid:123-456"},
					},
					Objects: []Object{
						{
							ObjectName:     "x509-svid",
							Type:           "x509-svid",
							FilePermission: 0644,
							Paths:          []string{"/cert.pem", "/key.pem", "/bundle.pem"},
						},
					},
					PodInfo: PodInfo{
						Name:               "test-pod",
						UID:                "123-456",
						Namespace:          "default",
						ServiceAccountName: "test-sa",
					},
				},
			},
			wantErr: false,
		},
		{
			name: "valid configuration with jwt-svid",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "jwt",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: jwt-svid
  type: jwt-svid
  audience:
    - audience1
    - audience2
  paths:
    - /token.jwt`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			want: Config{
				TargetPath:     "/var/run/secrets",
				FilePermission: 0644,
				Parameters: Parameters{
					UseCase:     "jwt",
					TrustDomain: "example.org",
					Selectors: []Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test-sa"},
						{Type: "k8s", Value: "pod-uid:123-456"},
					},
					Objects: []Object{
						{
							ObjectName: "jwt-svid",
							Type:       "jwt-svid",
							Audience:   []string{"audience1", "audience2"},
							Paths:      []string{"/token.jwt"},
						},
					},
					PodInfo: PodInfo{
						Name:               "test-pod",
						UID:                "123-456",
						Namespace:          "default",
						ServiceAccountName: "test-sa",
					},
				},
			},
			wantErr: false,
		},
		{
			name: "multiple objects",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "mixed",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: x509-svid
  type: x509-svid
  paths:
    - /cert.pem
    - /key.pem
    - /bundle.pem
- objectName: jwt-svid
  type: jwt-svid
  audience:
    - audience1
  paths:
    - /token.jwt`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			want: Config{
				TargetPath:     "/var/run/secrets",
				FilePermission: 0644,
				Parameters: Parameters{
					UseCase:     "mixed",
					TrustDomain: "example.org",
					Selectors: []Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test-sa"},
						{Type: "k8s", Value: "pod-uid:123-456"},
					},
					Objects: []Object{
						{
							ObjectName: "x509-svid",
							Type:       "x509-svid",
							Paths:      []string{"/cert.pem", "/key.pem", "/bundle.pem"},
						},
						{
							ObjectName: "jwt-svid",
							Type:       "jwt-svid",
							Audience:   []string{"audience1"},
							Paths:      []string{"/token.jwt"},
						},
					},
					PodInfo: PodInfo{
						Name:               "test-pod",
						UID:                "123-456",
						Namespace:          "default",
						ServiceAccountName: "test-sa",
					},
				},
			},
			wantErr: false,
		},
		{
			name:          "invalid JSON parameters",
			parametersStr: "not-valid-json",
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "invalid character",
		},
		{
			name: "invalid YAML objects",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects":                                `not valid yaml`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "failed to parse objects",
		},
		{
			name: "missing target path",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: x509-svid
  type: x509-svid
  paths:
    - /cert.pem
    - /key.pem
    - /bundle.pem`,
			}),
			targetPath:    "",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "missing target path",
		},
		{
			name: "no objects configured",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "no objects configured",
		},
		{
			name: "duplicate object names",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: duplicate
  type: x509-svid
  paths:
    - /cert1.pem
    - /key1.pem
    - /bundle1.pem
- objectName: duplicate
  type: x509-svid
  paths:
    - /cert2.pem
    - /key2.pem
    - /bundle2.pem`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "must be unique",
		},
		{
			name: "invalid object type",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: invalid
  type: invalid-type
  paths:
    - /test.txt`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "invalid type",
		},
		{
			name: "jwt-svid without audience",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "jwt",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: jwt-svid
  type: jwt-svid
  paths:
    - /token.jwt`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "audience is required",
		},
		{
			name: "object without paths",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: no-paths
  type: x509-svid`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "no paths defined",
		},
		{
			name: "x509-svid with wrong number of paths",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: wrong-paths
  type: x509-svid
  paths:
    - /cert.pem
    - /key.pem`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "should have exactly 3 paths",
		},
		{
			name: "jwt-svid with wrong number of paths",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "jwt",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: wrong-paths
  type: jwt-svid
  audience:
    - test
  paths:
    - /token1.jwt
    - /token2.jwt`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "420",
			wantErr:       true,
			errorContains: "should have exactly 1 path",
		},
		{
			name: "invalid permission string",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"objects": `
- objectName: x509-svid
  type: x509-svid
  paths:
    - /cert.pem
    - /key.pem
    - /bundle.pem`,
			}),
			targetPath:    "/var/run/secrets",
			permissionStr: "not-a-number",
			wantErr:       true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			got, err := Parse(tt.parametersStr, tt.targetPath, tt.permissionStr)
			if (err != nil) != tt.wantErr {
				t.Errorf("Parse() error = %v, wantErr %v", err, tt.wantErr)
				return
			}
			if err != nil && tt.errorContains != "" {
				if !contains(err.Error(), tt.errorContains) {
					t.Errorf("Parse() error = %v, should contain %v", err, tt.errorContains)
				}
				return
			}
			if !tt.wantErr {
				compareConfigs(t, got, tt.want)
			}
		})
	}
}

func TestParseParameters(t *testing.T) {
	tests := []struct {
		name          string
		parametersStr string
		want          Parameters
		wantErr       bool
	}{
		{
			name: "complete parameters",
			parametersStr: buildParametersJSON(map[string]string{
				"useCase":                                "default",
				"trustDomain":                            "example.org",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
			}),
			want: Parameters{
				UseCase:     "default",
				TrustDomain: "example.org",
				PodInfo: PodInfo{
					Name:               "test-pod",
					UID:                "123-456",
					Namespace:          "default",
					ServiceAccountName: "test-sa",
				},
				Selectors: []Selector{
					{Type: "k8s", Value: "ns:default"},
					{Type: "k8s", Value: "sa:test-sa"},
					{Type: "k8s", Value: "pod-uid:123-456"},
				},
			},
			wantErr: false,
		},
		{
			name: "minimal parameters",
			parametersStr: buildParametersJSON(map[string]string{
				"csi.storage.k8s.io/pod.namespace":       "kube-system",
				"csi.storage.k8s.io/serviceAccount.name": "admin",
				"csi.storage.k8s.io/pod.uid":             "abc-123",
			}),
			want: Parameters{
				PodInfo: PodInfo{
					UID:                "abc-123",
					Namespace:          "kube-system",
					ServiceAccountName: "admin",
				},
				Selectors: []Selector{
					{Type: "k8s", Value: "ns:kube-system"},
					{Type: "k8s", Value: "sa:admin"},
					{Type: "k8s", Value: "pod-uid:abc-123"},
				},
			},
			wantErr: false,
		},
		{
			name:          "invalid JSON",
			parametersStr: "{invalid json}",
			wantErr:       true,
		},
		{
			name:          "empty string",
			parametersStr: "",
			wantErr:       true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			got, err := parseParameters(tt.parametersStr)
			if (err != nil) != tt.wantErr {
				t.Errorf("parseParameters() error = %v, wantErr %v", err, tt.wantErr)
				return
			}
			if !tt.wantErr {
				compareParameters(t, got, tt.want)
			}
		})
	}
}

func TestConfigValidate(t *testing.T) {
	tests := []struct {
		name          string
		config        Config
		wantErr       bool
		errorContains string
	}{
		{
			name: "valid config",
			config: Config{
				TargetPath:     "/var/run/secrets",
				FilePermission: 0644,
				Parameters: Parameters{
					Objects: []Object{
						{
							ObjectName: "x509",
							Type:       "x509-svid",
							Paths:      []string{"/cert", "/key", "/bundle"},
						},
					},
					Selectors: []Selector{
						{Type: "k8s", Value: "ns:default"},
					},
				},
			},
			wantErr: false,
		},
		{
			name: "empty target path",
			config: Config{
				TargetPath: "",
				Parameters: Parameters{
					Objects: []Object{
						{
							ObjectName: "x509",
							Type:       "x509-svid",
							Paths:      []string{"/cert", "/key", "/bundle"},
						},
					},
					Selectors: []Selector{
						{Type: "k8s", Value: "ns:default"},
					},
				},
			},
			wantErr:       true,
			errorContains: "missing target path",
		},
		{
			name: "empty selector type",
			config: Config{
				TargetPath: "/path",
				Parameters: Parameters{
					Objects: []Object{
						{
							ObjectName: "x509",
							Type:       "x509-svid",
							Paths:      []string{"/cert", "/key", "/bundle"},
						},
					},
					Selectors: []Selector{
						{Type: "", Value: "ns:default"},
					},
				},
			},
			wantErr:       true,
			errorContains: "selector type cannot be empty",
		},
		{
			name: "empty selector value",
			config: Config{
				TargetPath: "/path",
				Parameters: Parameters{
					Objects: []Object{
						{
							ObjectName: "x509",
							Type:       "x509-svid",
							Paths:      []string{"/cert", "/key", "/bundle"},
						},
					},
					Selectors: []Selector{
						{Type: "k8s", Value: ""},
					},
				},
			},
			wantErr:       true,
			errorContains: "selector value cannot be empty",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			err := tt.config.validate()
			if (err != nil) != tt.wantErr {
				t.Errorf("validate() error = %v, wantErr %v", err, tt.wantErr)
				return
			}
			if err != nil && tt.errorContains != "" {
				if !contains(err.Error(), tt.errorContains) {
					t.Errorf("validate() error = %v, should contain %v", err, tt.errorContains)
				}
			}
		})
	}
}

// Helper functions
func buildParametersJSON(params map[string]string) string {
	data, _ := json.Marshal(params)
	return string(data)
}

func contains(s, substr string) bool {
	return len(s) >= len(substr) && s[:len(substr)] == substr ||
		len(s) >= len(substr) && contains(s[1:], substr)
}

func compareConfigs(t *testing.T, got, want Config) {
	if got.TargetPath != want.TargetPath {
		t.Errorf("TargetPath = %v, want %v", got.TargetPath, want.TargetPath)
	}
	if got.FilePermission != want.FilePermission {
		t.Errorf("FilePermission = %v, want %v", got.FilePermission, want.FilePermission)
	}
	compareParameters(t, got.Parameters, want.Parameters)
}

func compareParameters(t *testing.T, got, want Parameters) {
	if got.UseCase != want.UseCase {
		t.Errorf("UseCase = %v, want %v", got.UseCase, want.UseCase)
	}
	if got.TrustDomain != want.TrustDomain {
		t.Errorf("TrustDomain = %v, want %v", got.TrustDomain, want.TrustDomain)
	}
	if got.PodInfo.Name != want.PodInfo.Name {
		t.Errorf("PodInfo.Name = %v, want %v", got.PodInfo.Name, want.PodInfo.Name)
	}
	if got.PodInfo.UID != want.PodInfo.UID {
		t.Errorf("PodInfo.UID = %v, want %v", got.PodInfo.UID, want.PodInfo.UID)
	}
	if got.PodInfo.Namespace != want.PodInfo.Namespace {
		t.Errorf("PodInfo.Namespace = %v, want %v", got.PodInfo.Namespace, want.PodInfo.Namespace)
	}
	if got.PodInfo.ServiceAccountName != want.PodInfo.ServiceAccountName {
		t.Errorf("PodInfo.ServiceAccountName = %v, want %v", got.PodInfo.ServiceAccountName, want.PodInfo.ServiceAccountName)
	}
	if len(got.Selectors) != len(want.Selectors) {
		t.Errorf("Selectors length = %v, want %v", len(got.Selectors), len(want.Selectors))
	}
	for i := range got.Selectors {
		if i < len(want.Selectors) {
			if got.Selectors[i].Type != want.Selectors[i].Type {
				t.Errorf("Selector[%d].Type = %v, want %v", i, got.Selectors[i].Type, want.Selectors[i].Type)
			}
			if got.Selectors[i].Value != want.Selectors[i].Value {
				t.Errorf("Selector[%d].Value = %v, want %v", i, got.Selectors[i].Value, want.Selectors[i].Value)
			}
		}
	}
	if len(got.Objects) != len(want.Objects) {
		t.Errorf("Objects length = %v, want %v", len(got.Objects), len(want.Objects))
	}
	// Compare objects in detail
	for i := range got.Objects {
		if i < len(want.Objects) {
			if got.Objects[i].ObjectName != want.Objects[i].ObjectName {
				t.Errorf("Object[%d].ObjectName = %v, want %v", i, got.Objects[i].ObjectName, want.Objects[i].ObjectName)
			}
			if got.Objects[i].Type != want.Objects[i].Type {
				t.Errorf("Object[%d].Type = %v, want %v", i, got.Objects[i].Type, want.Objects[i].Type)
			}
			if got.Objects[i].FilePermission != want.Objects[i].FilePermission {
				t.Errorf("Object[%d].FilePermission = %v, want %v", i, got.Objects[i].FilePermission, want.Objects[i].FilePermission)
			}
			if len(got.Objects[i].Paths) != len(want.Objects[i].Paths) {
				t.Errorf("Object[%d].Paths length = %v, want %v", i, len(got.Objects[i].Paths), len(want.Objects[i].Paths))
			}
			for j := range got.Objects[i].Paths {
				if j < len(want.Objects[i].Paths) && got.Objects[i].Paths[j] != want.Objects[i].Paths[j] {
					t.Errorf("Object[%d].Paths[%d] = %v, want %v", i, j, got.Objects[i].Paths[j], want.Objects[i].Paths[j])
				}
			}
			if len(got.Objects[i].Audience) != len(want.Objects[i].Audience) {
				t.Errorf("Object[%d].Audience length = %v, want %v", i, len(got.Objects[i].Audience), len(want.Objects[i].Audience))
			}
			for j := range got.Objects[i].Audience {
				if j < len(want.Objects[i].Audience) && got.Objects[i].Audience[j] != want.Objects[i].Audience[j] {
					t.Errorf("Object[%d].Audience[%d] = %v, want %v", i, j, got.Objects[i].Audience[j], want.Objects[i].Audience[j])
				}
			}
		}
	}
}

func TestObjectFilePermission(t *testing.T) {
	tests := []struct {
		name     string
		object   Object
		expected os.FileMode
	}{
		{
			name: "default permission",
			object: Object{
				ObjectName: "test",
				Type:       "x509-svid",
				Paths:      []string{"/test"},
			},
			expected: 0,
		},
		{
			name: "custom permission 0600",
			object: Object{
				ObjectName:     "test",
				Type:           "x509-svid",
				FilePermission: 0600,
				Paths:          []string{"/test"},
			},
			expected: 0600,
		},
		{
			name: "custom permission 0644",
			object: Object{
				ObjectName:     "test",
				Type:           "x509-svid",
				FilePermission: 0644,
				Paths:          []string{"/test"},
			},
			expected: 0644,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			if tt.object.FilePermission != tt.expected {
				t.Errorf("FilePermission = %v, want %v", tt.object.FilePermission, tt.expected)
			}
		})
	}
}
</file>

<file path="config/config.go">
package config

import (
	"encoding/json"
	"errors"
	"fmt"
	"os"
	"time"

	"gopkg.in/yaml.v3"
	"k8s.io/apimachinery/pkg/types"
)

type Config struct {
	Parameters     Parameters
	TargetPath     string
	FilePermission os.FileMode
}

type FlagsConfig struct {
	Endpoint         string
	LogLevel         string
	Version          bool
	HealthAddr       string
	HMACSecretName   string
	CacheSize        int
	SpireSocketPath  string
	SpireSocketPath2 string
	MetricsAddr      string

	ProviderStaleTimeout    time.Duration
	ProviderCleanupInterval time.Duration
}

type Parameters struct {
	UseCase     string
	TrustDomain string
	Selectors   []Selector
	Rotation    RotationConfig
	Objects     []Object
	PodInfo     PodInfo
}

type Selector struct {
	Type  string `yaml:"type,omitempty"`
	Value string `yaml:"value,omitempty"`
}

type RotationConfig struct {
	Enabled      bool
	PollInterval time.Duration
	RenewBefore  time.Duration
}

type Object struct {
	ObjectName     string      `yaml:"objectName,omitempty"`
	Type           string      `yaml:"type,omitempty"`
	Audience       []string    `yaml:"audience,omitempty"`
	FilePermission os.FileMode `yaml:"filePermission,omitempty"`
	Paths          []string    `yaml:"paths,omitempty"`
}

type PodInfo struct {
	Name               string
	UID                types.UID
	Namespace          string
	ServiceAccountName string
}

func Parse(parametersStr, targetPath, permissionStr string) (Config, error) {
	config := Config{
		TargetPath: targetPath,
	}

	var err error
	config.Parameters, err = parseParameters(parametersStr)
	if err != nil {
		return Config{}, err
	}

	if err := json.Unmarshal([]byte(permissionStr), &config.FilePermission); err != nil {
		return Config{}, err
	}

	if err := config.validate(); err != nil {
		return Config{}, err
	}

	return config, nil
}

func parseParameters(parametersStr string) (Parameters, error) {
	var params map[string]string
	err := json.Unmarshal([]byte(parametersStr), &params)
	if err != nil {
		return Parameters{}, err
	}

	var parameters Parameters

	parameters.UseCase = params["useCase"]
	parameters.TrustDomain = params["trustDomain"]

	parameters.PodInfo.Name = params["csi.storage.k8s.io/pod.name"]
	parameters.PodInfo.UID = types.UID(params["csi.storage.k8s.io/pod.uid"])
	parameters.PodInfo.Namespace = params["csi.storage.k8s.io/pod.namespace"]
	parameters.PodInfo.ServiceAccountName = params["csi.storage.k8s.io/serviceAccount.name"]

	parameters.Selectors = []Selector{
		{
			Type:  "k8s",
			Value: fmt.Sprintf("ns:%s", parameters.PodInfo.Namespace),
		},
		{
			Type:  "k8s",
			Value: fmt.Sprintf("sa:%s", parameters.PodInfo.ServiceAccountName),
		},
		{
			Type:  "k8s",
			Value: fmt.Sprintf("pod-uid:%s", parameters.PodInfo.UID),
		},
	}

	objectsYaml := params["objects"]
	if objectsYaml != "" {
		err = yaml.Unmarshal([]byte(objectsYaml), &parameters.Objects)
		if err != nil {
			return Parameters{}, fmt.Errorf("failed to parse objects: %w", err)
		}
	}

	return parameters, nil
}

func (c *Config) validate() error {

	if c.TargetPath == "" {
		return errors.New("missing target path field")
	}

	if len(c.Parameters.Objects) == 0 {
		return errors.New("no objects configured - the provider will not fetch any SPIRE SVIDs")
	}

	objectNames := map[string]struct{}{}
	duplicates := []string{}

	for _, object := range c.Parameters.Objects {
		if _, exists := objectNames[object.ObjectName]; exists {
			duplicates = append(duplicates, object.ObjectName)
		}
		objectNames[object.ObjectName] = struct{}{}

		switch object.Type {
		case "x509-svid", "jwt-svid":

		default:
			return fmt.Errorf("invalid type %q for object %q", object.Type, object.ObjectName)
		}

		if object.Type == "jwt-svid" && len(object.Audience) == 0 {
			return fmt.Errorf("audience is required for JWT SVID object %q", object.ObjectName)
		}

		if len(object.Paths) == 0 {
			return fmt.Errorf("no paths defined for object %q", object.ObjectName)
		}

		if object.Type == "x509-svid" && len(object.Paths) != 3 {
			return fmt.Errorf("x509-svid object %q should have exactly 3 paths (cert, key, bundle)", object.ObjectName)
		}

		if object.Type == "jwt-svid" && len(object.Paths) != 1 {
			return fmt.Errorf("jwt-svid object %q should have exactly 1 path", object.ObjectName)
		}
	}

	if len(duplicates) > 0 {
		return fmt.Errorf("each 'objectName' within a SecretProviderClass must be unique")
	}

	for _, selector := range c.Parameters.Selectors {
		if selector.Type == "" {
			return errors.New("selector type cannot be empty")
		}
		if selector.Value == "" {
			return errors.New("selector value cannot be empty")
		}
	}

	return nil
}
</file>

<file path="hmac/hmac_test.go">
// internal/hmac/hmac_test.go
package hmac

import (
	"context"
	"encoding/base64"
	"testing"

	"spire-csi-provider/internal/config"
)

func TestNewHMACGenerator(t *testing.T) {
	tests := []struct {
		name      string
		staticKey []byte
		wantKey   []byte
	}{
		{
			name:      "with custom key",
			staticKey: []byte("custom-key-12345"),
			wantKey:   []byte("custom-key-12345"),
		},
		{
			name:      "with nil key uses default",
			staticKey: nil,
			wantKey:   []byte("spire-csi-provider-static-hmac-key-12345"),
		},
		{
			name:      "with empty key uses default",
			staticKey: []byte{},
			wantKey:   []byte("spire-csi-provider-static-hmac-key-12345"),
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			gen := NewHMACGenerator(tt.staticKey)
			if gen == nil {
				t.Fatal("NewHMACGenerator returned nil")
			}
			
			key, err := gen.GetOrCreateHMACKey(context.Background())
			if err != nil {
				t.Fatalf("GetOrCreateHMACKey() error = %v", err)
			}
			
			if string(key) != string(tt.wantKey) {
				t.Errorf("GetOrCreateHMACKey() = %v, want %v", key, tt.wantKey)
			}
		})
	}
}

func TestGenerateObjectVersion(t *testing.T) {
	gen := NewHMACGenerator([]byte("test-key"))

	tests := []struct {
		name    string
		object  config.Object
		content []byte
		wantErr bool
	}{
		{
			name: "x509-svid object",
			object: config.Object{
				ObjectName: "test-x509",
				Type:       "x509-svid",
				Paths:      []string{"/cert", "/key", "/bundle"},
			},
			content: []byte("test-content"),
			wantErr: false,
		},
		{
			name: "jwt-svid object",
			object: config.Object{
				ObjectName: "test-jwt",
				Type:       "jwt-svid",
				Audience:   []string{"audience1"},
				Paths:      []string{"/token"},
			},
			content: []byte("jwt-token-content"),
			wantErr: false,
		},
		{
			name: "empty content",
			object: config.Object{
				ObjectName: "test-empty",
				Type:       "x509-svid",
				Paths:      []string{"/cert", "/key", "/bundle"},
			},
			content: []byte{},
			wantErr: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			version, err := gen.GenerateObjectVersion(tt.object, tt.content)
			if (err != nil) != tt.wantErr {
				t.Errorf("GenerateObjectVersion() error = %v, wantErr %v", err, tt.wantErr)
				return
			}
			if !tt.wantErr {
				if version == nil {
					t.Fatal("GenerateObjectVersion() returned nil version")
				}
				if version.Id != tt.object.ObjectName {
					t.Errorf("Version.Id = %v, want %v", version.Id, tt.object.ObjectName)
				}
				if version.Version == "" {
					t.Error("Version.Version is empty")
				}
				// Verify it's a valid base64
				_, err := base64.URLEncoding.DecodeString(version.Version)
				if err != nil {
					t.Errorf("Version.Version is not valid base64: %v", err)
				}
			}
		})
	}
}

func TestGenerateObjectVersion_Deterministic(t *testing.T) {
	gen := NewHMACGenerator([]byte("test-key"))
	
	object := config.Object{
		ObjectName: "test-object",
		Type:       "x509-svid",
		Paths:      []string{"/cert", "/key", "/bundle"},
	}
	content := []byte("test-content")

	// Generate version multiple times
	version1, err1 := gen.GenerateObjectVersion(object, content)
	if err1 != nil {
		t.Fatalf("First GenerateObjectVersion() error = %v", err1)
	}

	version2, err2 := gen.GenerateObjectVersion(object, content)
	if err2 != nil {
		t.Fatalf("Second GenerateObjectVersion() error = %v", err2)
	}

	// Versions should be identical for same input
	if version1.Version != version2.Version {
		t.Errorf("HMAC not deterministic: %v != %v", version1.Version, version2.Version)
	}
}

func TestGenerateObjectVersion_DifferentContent(t *testing.T) {
	gen := NewHMACGenerator([]byte("test-key"))
	
	object := config.Object{
		ObjectName: "test-object",
		Type:       "x509-svid",
		Paths:      []string{"/cert", "/key", "/bundle"},
	}

	version1, _ := gen.GenerateObjectVersion(object, []byte("content1"))
	version2, _ := gen.GenerateObjectVersion(object, []byte("content2"))

	// Versions should be different for different content
	if version1.Version == version2.Version {
		t.Error("HMAC should differ for different content")
	}
}

func TestGenerateObjectVersion_DifferentObjects(t *testing.T) {
	gen := NewHMACGenerator([]byte("test-key"))
	
	object1 := config.Object{
		ObjectName: "object1",
		Type:       "x509-svid",
		Paths:      []string{"/cert", "/key", "/bundle"},
	}
	
	object2 := config.Object{
		ObjectName: "object2",
		Type:       "x509-svid",
		Paths:      []string{"/cert", "/key", "/bundle"},
	}
	
	content := []byte("same-content")

	version1, _ := gen.GenerateObjectVersion(object1, content)
	version2, _ := gen.GenerateObjectVersion(object2, content)

	// Versions should be different for different objects
	if version1.Version == version2.Version {
		t.Error("HMAC should differ for different objects")
	}
}

func TestGenerateObjectVersion_NilStaticKey(t *testing.T) {
	gen := &HMACGenerator{
		staticKey: nil,
	}

	object := config.Object{
		ObjectName: "test",
		Type:       "x509-svid",
		Paths:      []string{"/test"},
	}

	_, err := gen.GenerateObjectVersion(object, []byte("content"))
	if err == nil {
		t.Error("Expected error with nil static key")
	}
	if err.Error() != "no static hmac key provided" {
		t.Errorf("Unexpected error: %v", err)
	}
}
</file>

<file path="hmac/hmac.go">
package hmac

import (
	"context"
	cryptohmac "crypto/hmac"
	"crypto/sha256"
	"encoding/base64"
	"encoding/json"
	"fmt"

	pb "sigs.k8s.io/secrets-store-csi-driver/provider/v1alpha1"
	"spire-csi-provider/internal/config"
)

const (
	staticHMACKey = "spire-csi-provider-static-hmac-key-12345"
)

type HMACGenerator struct {
	staticKey []byte
}

func NewHMACGenerator(staticKey []byte) *HMACGenerator {
	if staticKey == nil || len(staticKey) == 0 {
		return &HMACGenerator{
			staticKey: []byte(staticHMACKey),
		}
	}

	return &HMACGenerator{
		staticKey: staticKey,
	}
}

func (g *HMACGenerator) GetOrCreateHMACKey(ctx context.Context) ([]byte, error) {
	return g.staticKey, nil
}

func (g *HMACGenerator) GenerateObjectVersion(object config.Object, content []byte) (*pb.ObjectVersion, error) {
	if g.staticKey == nil {
		return nil, fmt.Errorf("no static hmac key provided")
	}

	hash := cryptohmac.New(sha256.New, g.staticKey)
	cfg, err := json.Marshal(object)
	if err != nil {
		return nil, err
	}
	if _, err := hash.Write(cfg); err != nil {
		return nil, err
	}
	if _, err := hash.Write(content); err != nil {
		return nil, err
	}

	return &pb.ObjectVersion{
		Id:      object.ObjectName,
		Version: base64.URLEncoding.EncodeToString(hash.Sum(nil)),
	}, nil
}
</file>

<file path="metrics/metrics.go">
package metrics

import (
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

var (
	MountRequestsTotal = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_mount_requests_total",
			Help: "Total number of mount requests",
		},
		[]string{"status", "namespace", "service_account", "pod_uid"},
	)

	MountRequestDuration = promauto.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "spire_csi_mount_request_duration_seconds",
			Help:    "Duration of mount requests in seconds",
			Buckets: prometheus.DefBuckets,
		},
		[]string{"status", "namespace", "service_account", "pod_uid"},
	)

	ObjectsProcessedTotal = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_objects_processed_total",
			Help: "Total number of objects processed",
		},
		[]string{"type", "status", "namespace", "service_account", "pod_uid"},
	)

	SpireConnectionStatus = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "spire_csi_spire_connection_status",
			Help: "SPIRE connection status (1 = connected, 0 = disconnected)",
		},
		[]string{"namespace", "service_account", "pod_uid"},
	)

	SpireConnectionAttempts = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_spire_connection_attempts_total",
			Help: "Total number of SPIRE connection attempts",
		},
		[]string{"namespace", "service_account", "pod_uid"},
	)

	SpireSVIDsReceived = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_svids_received_total",
			Help: "Total number of SVIDs received from SPIRE",
		},
		[]string{"type", "namespace", "service_account", "pod_uid"},
	)

	SpireBundleUpdates = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_bundle_updates_total",
			Help: "Total number of trust bundle updates received",
		},
		[]string{"namespace", "service_account", "pod_uid"},
	)

	JWTCacheHits = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_jwt_cache_hits_total",
			Help: "Total number of JWT cache hits",
		},
		[]string{"namespace", "service_account", "pod_uid"},
	)

	JWTCacheMisses = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_jwt_cache_misses_total",
			Help: "Total number of JWT cache misses",
		},
		[]string{"namespace", "service_account", "pod_uid"},
	)

	JWTCacheSize = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "spire_csi_jwt_cache_size",
			Help: "Current size of JWT cache",
		},
		[]string{"namespace", "service_account", "pod_uid"},
	)

	SVIDCacheSize = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "spire_csi_svid_cache_size",
			Help: "Current size of SVID cache",
		},
		[]string{"namespace", "service_account", "pod_uid"},
	)

	HealthCheckStatus = promauto.NewGauge(
		prometheus.GaugeOpts{
			Name: "spire_csi_health_check_status",
			Help: "Health check status (1 = healthy, 0 = unhealthy)",
		},
	)

	ProviderPoolSize = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "spire_csi_provider_pool_size",
			Help: "Current size of SPIRE client pool",
		},
		[]string{"trust_domain"},
	)

	ProviderPoolHits = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_provider_pool_hits_total",
			Help: "Total number of SPIRE client pool hits",
		},
		[]string{"trust_domain", "namespace", "service_account"},
	)

	ProviderPoolMisses = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_provider_pool_misses_total",
			Help: "Total number of SPIRE client pool misses",
		},
		[]string{"trust_domain", "namespace", "service_account"},
	)

	ProviderPoolEvictions = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "spire_csi_provider_pool_evictions_total",
			Help: "Total number of SPIRE client evictions from pool",
		},
		[]string{"reason"},
	)
)

type PodContext struct {
	Namespace      string
	ServiceAccount string
	PodUID         string
	PodName        string
}

func RecordMountRequest(status string, duration float64, ctx PodContext) {
	MountRequestsTotal.WithLabelValues(status, ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Inc()
	MountRequestDuration.WithLabelValues(status, ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Observe(duration)
}

func RecordObjectProcessed(objectType, status string, ctx PodContext) {
	ObjectsProcessedTotal.WithLabelValues(objectType, status, ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Inc()
}

func UpdateSpireConnectionStatus(connected bool, ctx PodContext) {
	value := 0.0
	if connected {
		value = 1.0
	}
	SpireConnectionStatus.WithLabelValues(ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Set(value)
}

func RecordSpireConnectionAttempt(ctx PodContext) {
	SpireConnectionAttempts.WithLabelValues(ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Inc()
}

func RecordSpireSVIDReceived(svidType string, ctx PodContext) {
	SpireSVIDsReceived.WithLabelValues(svidType, ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Inc()
}

func RecordSpireBundleUpdate(ctx PodContext) {
	SpireBundleUpdates.WithLabelValues(ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Inc()
}

func RecordJWTCacheHit(ctx PodContext) {
	JWTCacheHits.WithLabelValues(ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Inc()
}

func RecordJWTCacheMiss(ctx PodContext) {
	JWTCacheMisses.WithLabelValues(ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Inc()
}

func UpdateCacheSizes(jwtCacheSize, svidCacheSize int, ctx PodContext) {
	JWTCacheSize.WithLabelValues(ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Set(float64(jwtCacheSize))
	SVIDCacheSize.WithLabelValues(ctx.Namespace, ctx.ServiceAccount, ctx.PodUID).Set(float64(svidCacheSize))
}

// Client pool metrics
func UpdateProviderPoolSize(trustDomain string, size int) {
	ProviderPoolSize.WithLabelValues(trustDomain).Set(float64(size))
}

func RecordProviderPoolHit(trustDomain, namespace, serviceAccount string) {
	ProviderPoolHits.WithLabelValues(trustDomain, namespace, serviceAccount).Inc()
}

func RecordProviderPoolMiss(trustDomain, namespace, serviceAccount string) {
	ProviderPoolMisses.WithLabelValues(trustDomain, namespace, serviceAccount).Inc()
}

func RecordProviderEviction(reason string) {
	ProviderPoolEvictions.WithLabelValues(reason).Inc()
}
</file>

<file path="provider/provider_test.go">
package provider

import (
	"context"
	"crypto/rand"
	"crypto/rsa"
	"crypto/tls"
	"crypto/x509"
	"crypto/x509/pkix"
	"errors"
	"math/big"
	"net"
	"os"
	"strings"
	"sync"
	"testing"
	"time"

	"github.com/golang/mock/gomock"
	"github.com/hashicorp/go-hclog"
	"spire-csi-provider/internal/client"
	"spire-csi-provider/internal/config"
	"spire-csi-provider/internal/hmac"
	"spire-csi-provider/internal/metrics"
)

func TestNewProviderWithContext(t *testing.T) {
	tests := []struct {
		name       string
		logger     hclog.Logger
		hmacGen    *hmac.HMACGenerator
		podContext metrics.PodContext
		wantNil    bool
	}{
		{
			name:    "valid inputs",
			logger:  hclog.NewNullLogger(),
			hmacGen: hmac.NewHMACGenerator([]byte("test-key")),
			podContext: metrics.PodContext{
				Namespace:      "default",
				ServiceAccount: "test-sa",
				PodUID:         "123",
				PodName:        "test-pod",
			},
			wantNil: false,
		},
		{
			name:    "nil logger",
			logger:  nil,
			hmacGen: hmac.NewHMACGenerator([]byte("test-key")),
			podContext: metrics.PodContext{
				Namespace: "default",
			},
			wantNil: false,
		},
		{
			name:       "nil hmac generator",
			logger:     hclog.NewNullLogger(),
			hmacGen:    nil,
			podContext: metrics.PodContext{},
			wantNil:    false,
		},
		{
			name:       "empty pod context",
			logger:     hclog.NewNullLogger(),
			hmacGen:    hmac.NewHMACGenerator([]byte("test")),
			podContext: metrics.PodContext{},
			wantNil:    false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			provider := NewProviderWithContext(tt.logger, tt.hmacGen, tt.podContext)
			if (provider == nil) != tt.wantNil {
				t.Errorf("NewProviderWithContext() returned nil = %v, want %v", provider == nil, tt.wantNil)
			}
			if provider != nil {
				if provider.logger != tt.logger && tt.logger != nil {
					t.Error("Logger not set correctly")
				}
				if provider.hmacGenerator != tt.hmacGen {
					t.Error("HMAC generator not set correctly")
				}
				if provider.podContext != tt.podContext {
					t.Error("Pod context not set correctly")
				}
			}
		})
	}
}

func TestHandleMountRequest_Success_X509(t *testing.T) {
	tests := []struct {
		name           string
		config         config.Config
		filePermission os.FileMode
		expectFiles    int
		expectVersions int
	}{
		{
			name: "single x509 object with custom permission",
			config: config.Config{
				TargetPath:     "/var/run/secrets",
				FilePermission: 0644,
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					PodInfo: config.PodInfo{
						Namespace:          "default",
						ServiceAccountName: "test-sa",
						UID:                "123",
						Name:               "test-pod",
					},
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test-sa"},
					},
					Objects: []config.Object{
						{
							ObjectName:     "x509-svid",
							Type:           "x509-svid",
							Paths:          []string{"/cert.pem", "/key.pem", "/bundle.pem"},
							FilePermission: 0600,
						},
					},
				},
			},
			filePermission: 0600,
			expectFiles:    3,
			expectVersions: 1,
		},
		{
			name: "x509 with default permission",
			config: config.Config{
				TargetPath:     "/var/run/secrets",
				FilePermission: 0644,
				Parameters: config.Parameters{
					TrustDomain: "prod.example.org",
					PodInfo: config.PodInfo{
						Namespace:          "production",
						ServiceAccountName: "prod-sa",
						UID:                "456",
						Name:               "prod-pod",
					},
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:production"},
						{Type: "k8s", Value: "sa:prod-sa"},
						{Type: "k8s", Value: "pod-uid:456"},
					},
					Objects: []config.Object{
						{
							ObjectName: "prod-x509",
							Type:       "x509-svid",
							Paths:      []string{"/tls/cert.pem", "/tls/key.pem", "/tls/ca.pem"},
						},
					},
				},
			},
			filePermission: 0644,
			expectFiles:    3,
			expectVersions: 1,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
			podContext := metrics.PodContext{
				Namespace:      tt.config.Parameters.PodInfo.Namespace,
				ServiceAccount: tt.config.Parameters.PodInfo.ServiceAccountName,
				PodUID:         string(tt.config.Parameters.PodInfo.UID),
				PodName:        tt.config.Parameters.PodInfo.Name,
			}

			cert, key := generateTestCertificate(t)
			caCert := generateTestCACertificate(t)

			tlsCert := &tls.Certificate{
				Certificate: [][]byte{cert.Raw},
				PrivateKey:  key,
				Leaf:        cert,
			}

			mockClient := client.NewMockSpireClient(ctrl)
			mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
			mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)
			mockClient.EXPECT().GetCertificateForIdentity(gomock.Any()).Return(tlsCert, nil)
			mockClient.EXPECT().GetCACertificates(gomock.Any()).Return([]*x509.Certificate{caCert}, nil)

			mockPool := client.NewMockClientPoolInterface(ctrl)
			mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
			mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()

			provider := NewProviderWithClientPool(logger, hmacGen, podContext, mockPool)

			flagsConfig := config.FlagsConfig{
				SpireSocketPath: "/run/spire/socket",
			}

			ctx := context.Background()
			resp, err := provider.HandleMountRequest(ctx, tt.config, flagsConfig)

			if err != nil {
				t.Fatalf("HandleMountRequest failed: %v", err)
			}

			if len(resp.Files) != tt.expectFiles {
				t.Errorf("Expected %d files, got %d", tt.expectFiles, len(resp.Files))
			}
			if len(resp.ObjectVersion) != tt.expectVersions {
				t.Errorf("Expected %d object versions, got %d", tt.expectVersions, len(resp.ObjectVersion))
			}

			for i, file := range resp.Files {
				expectedMode := int32(tt.filePermission)
				if file.Mode != expectedMode {
					t.Errorf("File %d: expected mode %o, got %o", i, expectedMode, file.Mode)
				}
			}
		})
	}
}

func TestHandleMountRequest_Success_JWT(t *testing.T) {
	tests := []struct {
		name      string
		audiences []string
		jwtToken  string
		paths     []string
	}{
		{
			name:      "single audience",
			audiences: []string{"audience1"},
			jwtToken:  "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIn0.dozjgNryP4J3jVmNHl0w5N_XgL0n3I9PlFUP0THsR8U",
			paths:     []string{"/token.jwt"},
		},
		{
			name:      "multiple audiences",
			audiences: []string{"audience1", "audience2", "audience3"},
			jwtToken:  "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsiYXVkMSIsImF1ZDIiXX0.2sSJKWgOcvXj0pJ_Uw6RkF8w0e_PINkucBLsVeGQoKY",
			paths:     []string{"/var/run/secrets/token"},
		},
		{
			name:      "special characters in audience",
			audiences: []string{"https://api.example.com", "urn:audience:test"},
			jwtToken:  "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJzcGVjaWFsIn0.hc6l8bLMqS7Kic7OFoVvTvNTLV7TEuySJyzpq-1WdBE",
			paths:     []string{"/jwt/token"},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
			podContext := metrics.PodContext{
				Namespace:      "default",
				ServiceAccount: "test-sa",
				PodUID:         "123",
				PodName:        "test-pod",
			}

			mockClient := client.NewMockSpireClient(ctrl)
			mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
			mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)
			mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), tt.audiences).Return(tt.jwtToken, nil)

			mockPool := client.NewMockClientPoolInterface(ctrl)
			mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
			mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()

			provider := NewProviderWithClientPool(logger, hmacGen, podContext, mockPool)

			cfg := config.Config{
				TargetPath:     "/var/run/secrets",
				FilePermission: 0644,
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					PodInfo: config.PodInfo{
						Namespace:          "default",
						ServiceAccountName: "test-sa",
						UID:                "123",
						Name:               "test-pod",
					},
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test-sa"},
					},
					Objects: []config.Object{
						{
							ObjectName: "jwt-svid",
							Type:       "jwt-svid",
							Audience:   tt.audiences,
							Paths:      tt.paths,
						},
					},
				},
			}

			flagsConfig := config.FlagsConfig{
				SpireSocketPath: "/run/spire/socket",
			}

			ctx := context.Background()
			resp, err := provider.HandleMountRequest(ctx, cfg, flagsConfig)

			if err != nil {
				t.Fatalf("HandleMountRequest failed: %v", err)
			}

			if len(resp.Files) != 1 {
				t.Errorf("Expected 1 file, got %d", len(resp.Files))
			}
			if resp.Files[0].Path != tt.paths[0] {
				t.Errorf("Expected path %s, got %s", tt.paths[0], resp.Files[0].Path)
			}
			if string(resp.Files[0].Contents) != tt.jwtToken {
				t.Error("JWT token content mismatch")
			}
		})
	}
}

func TestHandleMountRequest_MultipleObjects(t *testing.T) {
	tests := []struct {
		name           string
		objects        []config.Object
		expectedFiles  int
		expectedObjVer int
	}{
		{
			name: "x509 and jwt",
			objects: []config.Object{
				{
					ObjectName: "x509-svid",
					Type:       "x509-svid",
					Paths:      []string{"/cert.pem", "/key.pem", "/bundle.pem"},
				},
				{
					ObjectName: "jwt-svid",
					Type:       "jwt-svid",
					Audience:   []string{"audience1"},
					Paths:      []string{"/token.jwt"},
				},
			},
			expectedFiles:  4,
			expectedObjVer: 2,
		},
		{
			name: "multiple x509 objects",
			objects: []config.Object{
				{
					ObjectName: "x509-1",
					Type:       "x509-svid",
					Paths:      []string{"/tls1/cert.pem", "/tls1/key.pem", "/tls1/bundle.pem"},
				},
				{
					ObjectName: "x509-2",
					Type:       "x509-svid",
					Paths:      []string{"/tls2/cert.pem", "/tls2/key.pem", "/tls2/bundle.pem"},
				},
			},
			expectedFiles:  6,
			expectedObjVer: 2,
		},
		{
			name: "multiple jwt objects",
			objects: []config.Object{
				{
					ObjectName: "jwt-1",
					Type:       "jwt-svid",
					Audience:   []string{"aud1"},
					Paths:      []string{"/token1.jwt"},
				},
				{
					ObjectName: "jwt-2",
					Type:       "jwt-svid",
					Audience:   []string{"aud2", "aud3"},
					Paths:      []string{"/token2.jwt"},
				},
			},
			expectedFiles:  2,
			expectedObjVer: 2,
		},
		{
			name: "three mixed objects",
			objects: []config.Object{
				{
					ObjectName:     "x509-main",
					Type:           "x509-svid",
					Paths:          []string{"/main/cert.pem", "/main/key.pem", "/main/bundle.pem"},
					FilePermission: 0600,
				},
				{
					ObjectName: "jwt-api",
					Type:       "jwt-svid",
					Audience:   []string{"api.example.com"},
					Paths:      []string{"/api/token.jwt"},
				},
				{
					ObjectName:     "x509-backup",
					Type:           "x509-svid",
					Paths:          []string{"/backup/cert.pem", "/backup/key.pem", "/backup/bundle.pem"},
					FilePermission: 0400,
				},
			},
			expectedFiles:  7,
			expectedObjVer: 3,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
			podContext := metrics.PodContext{
				Namespace:      "default",
				ServiceAccount: "test-sa",
				PodUID:         "123",
				PodName:        "test-pod",
			}

			cert, key := generateTestCertificate(t)
			caCert := generateTestCACertificate(t)

			tlsCert := &tls.Certificate{
				Certificate: [][]byte{cert.Raw},
				PrivateKey:  key,
				Leaf:        cert,
			}

			mockClient := client.NewMockSpireClient(ctrl)
			mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
			mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)

			for _, obj := range tt.objects {
				if obj.Type == "x509-svid" {
					mockClient.EXPECT().GetCertificateForIdentity(gomock.Any()).Return(tlsCert, nil)
					mockClient.EXPECT().GetCACertificates(gomock.Any()).Return([]*x509.Certificate{caCert}, nil)
				} else if obj.Type == "jwt-svid" {
					mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), obj.Audience).Return("test-jwt-token", nil)
				}
			}

			mockPool := client.NewMockClientPoolInterface(ctrl)
			mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
			mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()

			provider := NewProviderWithClientPool(logger, hmacGen, podContext, mockPool)

			cfg := config.Config{
				TargetPath:     "/var/run/secrets",
				FilePermission: 0644,
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					PodInfo: config.PodInfo{
						Namespace:          "default",
						ServiceAccountName: "test-sa",
						UID:                "123",
						Name:               "test-pod",
					},
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test-sa"},
					},
					Objects: tt.objects,
				},
			}

			flagsConfig := config.FlagsConfig{
				SpireSocketPath: "/run/spire/socket",
			}

			ctx := context.Background()
			resp, err := provider.HandleMountRequest(ctx, cfg, flagsConfig)

			if err != nil {
				t.Fatalf("HandleMountRequest failed: %v", err)
			}

			if len(resp.Files) != tt.expectedFiles {
				t.Errorf("Expected %d files, got %d", tt.expectedFiles, len(resp.Files))
			}
			if len(resp.ObjectVersion) != tt.expectedObjVer {
				t.Errorf("Expected %d object versions, got %d", tt.expectedObjVer, len(resp.ObjectVersion))
			}
		})
	}
}

func TestHandleMountRequest_Errors(t *testing.T) {
	tests := []struct {
		name        string
		setupMock   func(*gomock.Controller) (client.SpireClient, client.ClientPoolInterface)
		config      config.Config
		flagsConfig config.FlagsConfig
		wantErr     string
	}{
		{
			name: "empty socket path",
			setupMock: func(ctrl *gomock.Controller) (client.SpireClient, client.ClientPoolInterface) {
				mockClient := client.NewMockSpireClient(ctrl)
				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil).AnyTimes()
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return().AnyTimes()
				return mockClient, mockPool
			},
			config: config.Config{
				TargetPath: "/var/run/secrets",
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					// Add valid selectors to avoid early SPIFFE ID failure
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test-sa"},
					},
					Objects: []config.Object{
						{ObjectName: "test", Type: "x509-svid", Paths: []string{"/a", "/b", "/c"}},
					},
				},
			},
			flagsConfig: config.FlagsConfig{SpireSocketPath: ""},
			wantErr:     "SPIRE socket path not specified",
		},
		{
			name: "client pool acquire error",
			setupMock: func(ctrl *gomock.Controller) (client.SpireClient, client.ClientPoolInterface) {
				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(nil, errors.New("pool error"))
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return().AnyTimes()
				return nil, mockPool
			},
			config: config.Config{
				TargetPath: "/var/run/secrets",
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					// Add valid selectors
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test-sa"},
					},
					Objects: []config.Object{
						{ObjectName: "test", Type: "x509-svid", Paths: []string{"/a", "/b", "/c"}},
					},
				},
			},
			flagsConfig: config.FlagsConfig{SpireSocketPath: "/socket"},
			wantErr:     "failed to acquire SPIRE client from pool",
		},
		{
			name: "wait for SVID timeout",
			setupMock: func(ctrl *gomock.Controller) (client.SpireClient, client.ClientPoolInterface) {
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(errors.New("timeout waiting for SVID"))

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()
				return mockClient, mockPool
			},
			config: config.Config{
				TargetPath: "/var/run/secrets",
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test"},
					},
					Objects: []config.Object{
						{ObjectName: "test", Type: "x509-svid", Paths: []string{"/a", "/b", "/c"}},
					},
				},
			},
			flagsConfig: config.FlagsConfig{SpireSocketPath: "/socket"},
			wantErr:     "failed waiting for SVID",
		},
		{
			name: "wait for trust bundle timeout",
			setupMock: func(ctrl *gomock.Controller) (client.SpireClient, client.ClientPoolInterface) {
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(errors.New("timeout waiting for trust bundle"))

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()
				return mockClient, mockPool
			},
			config: config.Config{
				TargetPath: "/var/run/secrets",
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test"},
					},
					Objects: []config.Object{
						{ObjectName: "test", Type: "x509-svid", Paths: []string{"/a", "/b", "/c"}},
					},
				},
			},
			flagsConfig: config.FlagsConfig{SpireSocketPath: "/socket"},
			wantErr:     "failed waiting for trust bundle",
		},
		{
			name: "unsupported object type",
			setupMock: func(ctrl *gomock.Controller) (client.SpireClient, client.ClientPoolInterface) {
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()
				return mockClient, mockPool
			},
			config: config.Config{
				TargetPath: "/var/run/secrets",
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test"},
					},
					Objects: []config.Object{
						{ObjectName: "bad", Type: "unsupported", Paths: []string{"/test"}},
					},
				},
			},
			flagsConfig: config.FlagsConfig{SpireSocketPath: "/socket"},
			wantErr:     "unsupported object type",
		},
		{
			name: "empty SPIFFE ID - missing selectors",
			setupMock: func(ctrl *gomock.Controller) (client.SpireClient, client.ClientPoolInterface) {
				// This test should fail before acquiring client
				mockPool := client.NewMockClientPoolInterface(ctrl)
				// Don't expect any calls since we should fail early
				return nil, mockPool
			},
			config: config.Config{
				TargetPath: "/var/run/secrets",
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					// No selectors - will fail at SPIFFE ID building
					Objects: []config.Object{
						{ObjectName: "test", Type: "x509-svid", Paths: []string{"/a", "/b", "/c"}},
					},
				},
			},
			flagsConfig: config.FlagsConfig{SpireSocketPath: "/socket"},
			wantErr:     "unable to build valid SPIFFE ID from selectors",
		},
		{
			name: "empty SPIFFE ID - missing namespace selector",
			setupMock: func(ctrl *gomock.Controller) (client.SpireClient, client.ClientPoolInterface) {
				// This test should fail before acquiring client
				mockPool := client.NewMockClientPoolInterface(ctrl)
				// Don't expect any calls since we should fail early
				return nil, mockPool
			},
			config: config.Config{
				TargetPath: "/var/run/secrets",
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					Selectors: []config.Selector{
						// Missing namespace selector
						{Type: "k8s", Value: "sa:test-sa"},
						{Type: "k8s", Value: "pod-uid:123"},
					},
					Objects: []config.Object{
						{ObjectName: "test", Type: "x509-svid", Paths: []string{"/a", "/b", "/c"}},
					},
				},
			},
			flagsConfig: config.FlagsConfig{SpireSocketPath: "/socket"},
			wantErr:     "unable to build valid SPIFFE ID from selectors",
		},
		{
			name: "empty SPIFFE ID - missing service account selector",
			setupMock: func(ctrl *gomock.Controller) (client.SpireClient, client.ClientPoolInterface) {
				// This test should fail before acquiring client
				mockPool := client.NewMockClientPoolInterface(ctrl)
				// Don't expect any calls since we should fail early
				return nil, mockPool
			},
			config: config.Config{
				TargetPath: "/var/run/secrets",
				Parameters: config.Parameters{
					TrustDomain: "example.org",
					Selectors: []config.Selector{
						// Missing service account selector
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "pod-uid:123"},
					},
					Objects: []config.Object{
						{ObjectName: "test", Type: "x509-svid", Paths: []string{"/a", "/b", "/c"}},
					},
				},
			},
			flagsConfig: config.FlagsConfig{SpireSocketPath: "/socket"},
			wantErr:     "unable to build valid SPIFFE ID from selectors",
		},
		{
			name: "empty SPIFFE ID - missing trust domain",
			setupMock: func(ctrl *gomock.Controller) (client.SpireClient, client.ClientPoolInterface) {
				// This test should fail before acquiring client
				mockPool := client.NewMockClientPoolInterface(ctrl)
				// Don't expect any calls since we should fail early
				return nil, mockPool
			},
			config: config.Config{
				TargetPath: "/var/run/secrets",
				Parameters: config.Parameters{
					// Missing TrustDomain
					Selectors: []config.Selector{
						{Type: "k8s", Value: "ns:default"},
						{Type: "k8s", Value: "sa:test-sa"},
					},
					Objects: []config.Object{
						{ObjectName: "test", Type: "x509-svid", Paths: []string{"/a", "/b", "/c"}},
					},
				},
			},
			flagsConfig: config.FlagsConfig{SpireSocketPath: "/socket"},
			wantErr:     "unable to build valid SPIFFE ID from selectors",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
			podContext := metrics.PodContext{}

			_, mockPool := tt.setupMock(ctrl)

			provider := NewProviderWithClientPool(logger, hmacGen, podContext, mockPool)

			ctx := context.Background()
			_, err := provider.HandleMountRequest(ctx, tt.config, tt.flagsConfig)

			if err == nil {
				t.Fatal("Expected error but got none")
			}
			if !contains(err.Error(), tt.wantErr) {
				t.Errorf("Expected error containing %q, got %q", tt.wantErr, err.Error())
			}
		})
	}
}

func TestHandleMountRequest_WithoutPool(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
	podContext := metrics.PodContext{
		Namespace:      "default",
		ServiceAccount: "test-sa",
		PodUID:         "123",
		PodName:        "test-pod",
	}

	provider := NewProviderWithContext(logger, hmacGen, podContext)

	cfg := config.Config{
		TargetPath:     "/var/run/secrets",
		FilePermission: 0644,
		Parameters: config.Parameters{
			TrustDomain: "example.org",
			PodInfo: config.PodInfo{
				Namespace:          "default",
				ServiceAccountName: "test-sa",
				UID:                "123",
				Name:               "test-pod",
			},
			Selectors: []config.Selector{
				{Type: "k8s", Value: "ns:default"},
				{Type: "k8s", Value: "sa:test-sa"},
			},
			Objects: []config.Object{
				{
					ObjectName: "jwt-svid",
					Type:       "jwt-svid",
					Audience:   []string{"audience1"},
					Paths:      []string{"/token.jwt"},
				},
			},
		},
	}

	flagsConfig := config.FlagsConfig{
		SpireSocketPath: "/run/spire/socket",
	}

	mockClient := client.NewMockSpireClient(ctrl)
	mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
	mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)
	mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return("test-jwt", nil)

	// Manually set the client (simulating an already initialized client)
	provider.spireClient = mockClient
	provider.clientConfig = client.Config{
		SpireSocketPath:   flagsConfig.SpireSocketPath,
		SpiffeTrustDomain: cfg.Parameters.TrustDomain,
	}

	ctx := context.Background()
	resp, err := provider.HandleMountRequest(ctx, cfg, flagsConfig)

	if err != nil {
		t.Fatalf("HandleMountRequest failed: %v", err)
	}

	if len(resp.Files) != 1 {
		t.Errorf("Expected 1 file, got %d", len(resp.Files))
	}
	if resp.Files[0].Path != "/token.jwt" {
		t.Errorf("Expected path /token.jwt, got %s", resp.Files[0].Path)
	}
}

func TestBuildSpiffeIDFromSelectors(t *testing.T) {
	logger := hclog.NewNullLogger()
	hmacGen := hmac.NewHMACGenerator([]byte("test"))
	podContext := metrics.PodContext{}
	provider := NewProviderWithContext(logger, hmacGen, podContext)

	tests := []struct {
		name   string
		params config.Parameters
		want   string
	}{
		{
			name: "complete SPIFFE ID",
			params: config.Parameters{
				TrustDomain: "example.org",
				Selectors: []config.Selector{
					{Type: "k8s", Value: "ns:production"},
					{Type: "k8s", Value: "sa:frontend"},
					{Type: "k8s", Value: "pod-uid:123"},
				},
			},
			want: "spiffe://example.org/ns/production/sa/frontend",
		},
		{
			name: "selectors in different order",
			params: config.Parameters{
				TrustDomain: "example.org",
				Selectors: []config.Selector{
					{Type: "k8s", Value: "pod-uid:123"},
					{Type: "k8s", Value: "sa:backend"},
					{Type: "k8s", Value: "ns:staging"},
				},
			},
			want: "spiffe://example.org/ns/staging/sa/backend",
		},
		{
			name: "with extra selectors",
			params: config.Parameters{
				TrustDomain: "example.org",
				Selectors: []config.Selector{
					{Type: "k8s", Value: "ns:default"},
					{Type: "k8s", Value: "sa:admin"},
					{Type: "k8s", Value: "pod-uid:abc"},
					{Type: "k8s", Value: "pod-name:test-pod"},
					{Type: "custom", Value: "extra:value"},
				},
			},
			want: "spiffe://example.org/ns/default/sa/admin",
		},
		{
			name: "missing namespace",
			params: config.Parameters{
				TrustDomain: "example.org",
				Selectors: []config.Selector{
					{Type: "k8s", Value: "sa:frontend"},
					{Type: "k8s", Value: "pod-uid:123"},
				},
			},
			want: "",
		},
		{
			name: "missing service account",
			params: config.Parameters{
				TrustDomain: "example.org",
				Selectors: []config.Selector{
					{Type: "k8s", Value: "ns:production"},
					{Type: "k8s", Value: "pod-uid:123"},
				},
			},
			want: "",
		},
		{
			name: "missing trust domain",
			params: config.Parameters{
				Selectors: []config.Selector{
					{Type: "k8s", Value: "ns:production"},
					{Type: "k8s", Value: "sa:frontend"},
				},
			},
			want: "",
		},
		{
			name: "empty selectors",
			params: config.Parameters{
				TrustDomain: "example.org",
				Selectors:   []config.Selector{},
			},
			want: "",
		},
		{
			name: "nil selectors",
			params: config.Parameters{
				TrustDomain: "example.org",
				Selectors:   nil,
			},
			want: "",
		},
		{
			name: "non-k8s selectors only",
			params: config.Parameters{
				TrustDomain: "example.org",
				Selectors: []config.Selector{
					{Type: "unix", Value: "uid:1000"},
					{Type: "unix", Value: "gid:1000"},
					{Type: "docker", Value: "label:app=test"},
				},
			},
			want: "",
		},
		{
			name: "mixed selector types",
			params: config.Parameters{
				TrustDomain: "example.org",
				Selectors: []config.Selector{
					{Type: "k8s", Value: "ns:hybrid"},
					{Type: "unix", Value: "uid:1000"},
					{Type: "k8s", Value: "sa:hybrid-sa"},
					{Type: "docker", Value: "image:test"},
				},
			},
			want: "spiffe://example.org/ns/hybrid/sa/hybrid-sa",
		},
		{
			name: "special characters in values",
			params: config.Parameters{
				TrustDomain: "test.example.org",
				Selectors: []config.Selector{
					{Type: "k8s", Value: "ns:kube-system"},
					{Type: "k8s", Value: "sa:dns-controller"},
				},
			},
			want: "spiffe://test.example.org/ns/kube-system/sa/dns-controller",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			got := provider.buildSpiffeIDFromSelectors(tt.params)
			if got != tt.want {
				t.Errorf("buildSpiffeIDFromSelectors() = %v, want %v", got, tt.want)
			}
		})
	}
}

func TestFetchX509SVID_Success(t *testing.T) {
	tests := []struct {
		name        string
		certChain   int
		caCerts     int
		keyType     interface{}
		expectError bool
	}{
		{
			name:      "single cert with RSA key",
			certChain: 1,
			caCerts:   1,
			keyType:   &rsa.PrivateKey{},
		},
		{
			name:      "cert chain with intermediate",
			certChain: 2,
			caCerts:   2,
			keyType:   &rsa.PrivateKey{},
		},
		{
			name:      "multiple CA certs",
			certChain: 1,
			caCerts:   3,
			keyType:   &rsa.PrivateKey{},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			hmacGen := hmac.NewHMACGenerator([]byte("test"))
			podContext := metrics.PodContext{}
			provider := NewProviderWithContext(logger, hmacGen, podContext)

			var certChain [][]byte
			for i := 0; i < tt.certChain; i++ {
				cert, _ := generateTestCertificate(t)
				certChain = append(certChain, cert.Raw)
			}

			var caCerts []*x509.Certificate
			for i := 0; i < tt.caCerts; i++ {
				caCerts = append(caCerts, generateTestCACertificate(t))
			}

			key, _ := rsa.GenerateKey(rand.Reader, 2048)
			tlsCert := &tls.Certificate{
				Certificate: certChain,
				PrivateKey:  key,
			}

			mockClient := client.NewMockSpireClient(ctrl)
			mockClient.EXPECT().GetCertificateForIdentity(gomock.Any()).Return(tlsCert, nil)
			mockClient.EXPECT().GetCACertificates(gomock.Any()).Return(caCerts, nil)

			object := config.Object{
				ObjectName: "test",
				Type:       "x509-svid",
				Paths:      []string{"/cert", "/key", "/bundle"},
			}

			ctx := context.Background()
			result, err := provider.fetchX509SVID(ctx, mockClient, object, "spiffe://example.org/test")

			if tt.expectError {
				if err == nil {
					t.Fatal("Expected error but got none")
				}
			} else {
				if err != nil {
					t.Fatalf("Unexpected error: %v", err)
				}

				if len(result) != 3 {
					t.Errorf("Expected 3 paths in result, got %d", len(result))
				}

				if !strings.Contains(string(result["/cert"]), "BEGIN CERTIFICATE") {
					t.Error("Certificate PEM not found")
				}

				if !strings.Contains(string(result["/key"]), "BEGIN PRIVATE KEY") {
					t.Error("Private key PEM not found")
				}

				bundleCertCount := strings.Count(string(result["/bundle"]), "BEGIN CERTIFICATE")
				if bundleCertCount != tt.caCerts {
					t.Errorf("Expected %d CA certs in bundle, found %d", tt.caCerts, bundleCertCount)
				}
			}
		})
	}
}

func TestFetchJWTSVID_Success(t *testing.T) {
	tests := []struct {
		name      string
		audiences []string
		token     string
		paths     []string
	}{
		{
			name:      "standard JWT",
			audiences: []string{"test-audience"},
			token:     "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c",
			paths:     []string{"/token.jwt"},
		},
		{
			name:      "empty JWT",
			audiences: []string{"empty"},
			token:     "",
			paths:     []string{"/empty.jwt"},
		},
		{
			name:      "very long JWT",
			audiences: []string{"long"},
			token:     strings.Repeat("a", 10000),
			paths:     []string{"/long.jwt"},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			hmacGen := hmac.NewHMACGenerator([]byte("test"))
			podContext := metrics.PodContext{}
			provider := NewProviderWithContext(logger, hmacGen, podContext)

			mockClient := client.NewMockSpireClient(ctrl)
			mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), tt.audiences).Return(tt.token, nil)

			object := config.Object{
				ObjectName: "test",
				Type:       "jwt-svid",
				Audience:   tt.audiences,
				Paths:      tt.paths,
			}

			ctx := context.Background()
			result, err := provider.fetchJWTSVID(ctx, mockClient, object, "spiffe://example.org/test")

			if err != nil {
				t.Fatalf("Unexpected error: %v", err)
			}

			if len(result) != 1 {
				t.Errorf("Expected 1 path in result, got %d", len(result))
			}

			if string(result[tt.paths[0]]) != tt.token {
				t.Errorf("Token mismatch: got %s, want %s", result[tt.paths[0]], tt.token)
			}
		})
	}
}

func TestProvider_ConcurrentRequests(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
	podContext := metrics.PodContext{
		Namespace:      "default",
		ServiceAccount: "test-sa",
		PodUID:         "123",
		PodName:        "test-pod",
	}

	// Create mock client that can handle concurrent calls
	mockClient := client.NewMockSpireClient(ctrl)
	mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil).AnyTimes()
	mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil).AnyTimes()
	mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return("test-jwt", nil).AnyTimes()

	// Create mock pool
	mockPool := client.NewMockClientPoolInterface(ctrl)
	mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil).AnyTimes()
	mockPool.EXPECT().ReleaseClient(gomock.Any()).Return().AnyTimes()

	provider := NewProviderWithClientPool(logger, hmacGen, podContext, mockPool)

	cfg := config.Config{
		TargetPath:     "/var/run/secrets",
		FilePermission: 0644,
		Parameters: config.Parameters{
			TrustDomain: "example.org",
			PodInfo: config.PodInfo{
				Namespace:          "default",
				ServiceAccountName: "test-sa",
				UID:                "123",
				Name:               "test-pod",
			},
			Selectors: []config.Selector{
				{Type: "k8s", Value: "ns:default"},
				{Type: "k8s", Value: "sa:test-sa"},
			},
			Objects: []config.Object{
				{
					ObjectName: "jwt-svid",
					Type:       "jwt-svid",
					Audience:   []string{"audience1"},
					Paths:      []string{"/token.jwt"},
				},
			},
		},
	}

	flagsConfig := config.FlagsConfig{
		SpireSocketPath: "/run/spire/socket",
	}

	// Run multiple concurrent requests
	numRequests := 10
	var wg sync.WaitGroup
	errors := make(chan error, numRequests)

	for i := 0; i < numRequests; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			ctx := context.Background()
			_, err := provider.HandleMountRequest(ctx, cfg, flagsConfig)
			if err != nil {
				errors <- err
			}
		}()
	}

	wg.Wait()
	close(errors)

	// Check for errors
	for err := range errors {
		t.Errorf("Concurrent request failed: %v", err)
	}
}

func TestProvider_Stop(t *testing.T) {
	tests := []struct {
		name        string
		hasClient   bool
		stopError   error
		expectError bool
	}{
		{
			name:        "with client",
			hasClient:   true,
			stopError:   nil,
			expectError: false,
		},
		{
			name:        "without client",
			hasClient:   false,
			stopError:   nil,
			expectError: false,
		},
		{
			name:        "with client stop error",
			hasClient:   true,
			stopError:   errors.New("stop failed"),
			expectError: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			hmacGen := hmac.NewHMACGenerator([]byte("test"))
			podContext := metrics.PodContext{}
			provider := NewProviderWithContext(logger, hmacGen, podContext)

			if tt.hasClient {
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().Stop().Return(tt.stopError)
				provider.spireClient = mockClient
			}

			err := provider.Stop()
			if (err != nil) != tt.expectError {
				t.Errorf("Stop() error = %v, expectError %v", err, tt.expectError)
			}
		})
	}
}

func TestConvertConfigSelectorsToAPISelectors(t *testing.T) {
	tests := []struct {
		name            string
		configSelectors []config.Selector
		expected        int
	}{
		{
			name: "standard selectors",
			configSelectors: []config.Selector{
				{Type: "k8s", Value: "ns:default"},
				{Type: "k8s", Value: "sa:test"},
				{Type: "unix", Value: "uid:1000"},
			},
			expected: 3,
		},
		{
			name:            "empty selectors",
			configSelectors: []config.Selector{},
			expected:        0,
		},
		{
			name:            "nil selectors",
			configSelectors: nil,
			expected:        0,
		},
		{
			name: "single selector",
			configSelectors: []config.Selector{
				{Type: "test", Value: "value"},
			},
			expected: 1,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			apiSelectors := convertConfigSelectorsToAPISelectors(tt.configSelectors)

			if len(apiSelectors) != tt.expected {
				t.Errorf("Expected %d selectors, got %d", tt.expected, len(apiSelectors))
			}

			for i, sel := range apiSelectors {
				if i < len(tt.configSelectors) {
					if sel.Type != tt.configSelectors[i].Type {
						t.Errorf("Selector %d: Type = %v, want %v", i, sel.Type, tt.configSelectors[i].Type)
					}
					if sel.Value != tt.configSelectors[i].Value {
						t.Errorf("Selector %d: Value = %v, want %v", i, sel.Value, tt.configSelectors[i].Value)
					}
				}
			}
		})
	}
}

func generateTestCertificate(t *testing.T) (*x509.Certificate, *rsa.PrivateKey) {
	key, err := rsa.GenerateKey(rand.Reader, 2048)
	if err != nil {
		t.Fatal(err)
	}

	template := x509.Certificate{
		SerialNumber: big.NewInt(1),
		Subject: pkix.Name{
			Organization: []string{"Test Org"},
			CommonName:   "test.example.org",
		},
		NotBefore:   time.Now(),
		NotAfter:    time.Now().Add(365 * 24 * time.Hour),
		KeyUsage:    x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature,
		ExtKeyUsage: []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth},
		IPAddresses: []net.IP{net.IPv4(127, 0, 0, 1)},
		DNSNames:    []string{"test.example.org", "localhost"},
	}

	certDER, err := x509.CreateCertificate(rand.Reader, &template, &template, &key.PublicKey, key)
	if err != nil {
		t.Fatal(err)
	}

	cert, err := x509.ParseCertificate(certDER)
	if err != nil {
		t.Fatal(err)
	}

	return cert, key
}

func generateTestCACertificate(t *testing.T) *x509.Certificate {
	key, err := rsa.GenerateKey(rand.Reader, 2048)
	if err != nil {
		t.Fatal(err)
	}

	template := x509.Certificate{
		SerialNumber: big.NewInt(1),
		Subject: pkix.Name{
			Organization: []string{"Test CA"},
			Country:      []string{"US"},
			CommonName:   "Test CA Root",
		},
		NotBefore:             time.Now(),
		NotAfter:              time.Now().Add(365 * 24 * time.Hour),
		KeyUsage:              x509.KeyUsageCertSign | x509.KeyUsageCRLSign,
		BasicConstraintsValid: true,
		IsCA:                  true,
		MaxPathLen:            2,
	}

	certDER, err := x509.CreateCertificate(rand.Reader, &template, &template, &key.PublicKey, key)
	if err != nil {
		t.Fatal(err)
	}

	cert, err := x509.ParseCertificate(certDER)
	if err != nil {
		t.Fatal(err)
	}

	return cert
}

func contains(s, substr string) bool {
	return strings.Contains(s, substr)
}
</file>

<file path="provider/provider.go">
package provider

import (
	"context"
	"crypto/x509"
	"encoding/pem"
	"fmt"
	"strings"
	"sync"
	"time"

	"spire-csi-provider/internal/client"
	"spire-csi-provider/internal/config"
	"spire-csi-provider/internal/hmac"
	"spire-csi-provider/internal/metrics"

	"github.com/hashicorp/go-hclog"
	typesapi "github.com/spiffe/spire-api-sdk/proto/spire/api/types"
	pb "sigs.k8s.io/secrets-store-csi-driver/provider/v1alpha1"
)

type Provider struct {
	logger        hclog.Logger
	hmacGenerator *hmac.HMACGenerator
	podContext    metrics.PodContext

	spireClient      client.SpireClient
	spireClientMutex sync.RWMutex
	clientConfig     client.Config
	clientPool       client.ClientPoolInterface
}

func NewProviderWithContext(logger hclog.Logger, hmacGenerator *hmac.HMACGenerator, podContext metrics.PodContext) *Provider {
	return &Provider{
		logger:        logger,
		hmacGenerator: hmacGenerator,
		podContext:    podContext,
	}
}

func NewProviderWithClientPool(logger hclog.Logger, hmacGenerator *hmac.HMACGenerator, podContext metrics.PodContext, clientPool client.ClientPoolInterface) *Provider {
	return &Provider{
		logger:        logger,
		hmacGenerator: hmacGenerator,
		podContext:    podContext,
		clientPool:    clientPool,
	}
}

func (p *Provider) HandleMountRequest(ctx context.Context, cfg config.Config, flagsConfig config.FlagsConfig) (*pb.MountResponse, error) {
	start := time.Now()

	socketPath := flagsConfig.SpireSocketPath
	if socketPath == "" {
		p.logger.Error("SPIRE socket path not specified")
		return nil, fmt.Errorf("SPIRE socket path not specified")
	}

	p.logger.Info("handling mount request",
		"target_path", cfg.TargetPath,
		"trust_domain", cfg.Parameters.TrustDomain,
		"object_count", len(cfg.Parameters.Objects),
		"socket_path", socketPath,
		"using_pool", p.clientPool != nil,
	)

	spiffeID := p.buildSpiffeIDFromSelectors(cfg.Parameters)
	p.logger.Debug("built SPIFFE ID from selectors", "spiffe_id", spiffeID)

	if spiffeID == "" {
		p.logger.Error("unable to build valid SPIFFE ID from selectors")
		return nil, fmt.Errorf("unable to build valid SPIFFE ID from selectors")
	}

	var spireClient client.SpireClient
	var releaseFunc func()
	var err error

	if p.clientPool != nil {
		clientConfig := client.Config{
			SpireSocketPath:   socketPath,
			SpireSocketPath2:  flagsConfig.SpireSocketPath2,
			SpiffeTrustDomain: cfg.Parameters.TrustDomain,
			Selectors:         convertConfigSelectorsToAPISelectors(cfg.Parameters.Selectors),
			RotatedQueueSize:  1024,
			PodContext:        p.podContext,
		}

		spireClient, err = p.clientPool.AcquireClient(ctx, clientConfig)
		if err != nil {
			p.logger.Error("failed to acquire SPIRE client from pool", "error", err)
			return nil, fmt.Errorf("failed to acquire SPIRE client from pool: %w", err)
		}

		releaseFunc = func() {
			p.clientPool.ReleaseClient(clientConfig)
		}
	} else {
		spireClient, err = p.getOrCreateSpireClient(ctx, socketPath, cfg.Parameters.TrustDomain, cfg.Parameters.Selectors, flagsConfig)
		if err != nil {
			p.logger.Error("failed to get SPIRE client", "error", err)
			return nil, fmt.Errorf("failed to get SPIRE client: %w", err)
		}
		releaseFunc = func() {} // No-op for non-pooled clients
	}

	defer releaseFunc()

	p.logger.Info("waiting for SVID and trust bundle",
		"spiffe_id", spiffeID,
		"timeout", "30s",
	)

	waitStart := time.Now()
	if err := spireClient.WaitForSVID(ctx, spiffeID, 30*time.Second); err != nil {
		p.logger.Error("failed waiting for SVID",
			"spiffe_id", spiffeID,
			"error", err,
			"wait_duration_ms", time.Since(waitStart).Milliseconds(),
		)
		return nil, fmt.Errorf("failed waiting for SVID: %w", err)
	}
	p.logger.Debug("SVID available",
		"spiffe_id", spiffeID,
		"wait_duration_ms", time.Since(waitStart).Milliseconds(),
	)

	bundleWaitStart := time.Now()
	if err := spireClient.WaitForTrustBundle(ctx, 30*time.Second); err != nil {
		p.logger.Error("failed waiting for trust bundle",
			"error", err,
			"wait_duration_ms", time.Since(bundleWaitStart).Milliseconds(),
		)
		return nil, fmt.Errorf("failed waiting for trust bundle: %w", err)
	}
	p.logger.Debug("trust bundle available",
		"wait_duration_ms", time.Since(bundleWaitStart).Milliseconds(),
	)

	var files []*pb.File
	var objectVersions []*pb.ObjectVersion

	for _, object := range cfg.Parameters.Objects {
		objectStart := time.Now()
		p.logger.Debug("processing object",
			"object_name", object.ObjectName,
			"type", object.Type,
			"paths", len(object.Paths),
			"file_permission", fmt.Sprintf("%o", object.FilePermission),
		)

		var contents map[string][]byte
		var err error

		switch object.Type {
		case "x509-svid":
			contents, err = p.fetchX509SVID(ctx, spireClient, object, spiffeID)
		case "jwt-svid":
			contents, err = p.fetchJWTSVID(ctx, spireClient, object, spiffeID)
		default:
			p.logger.Error("unsupported object type",
				"object_name", object.ObjectName,
				"type", object.Type,
			)
			metrics.RecordObjectProcessed(object.Type, "error_unsupported", p.podContext)
			return nil, fmt.Errorf("unsupported object type: %s", object.Type)
		}

		if err != nil {
			p.logger.Error("failed to fetch object",
				"object_name", object.ObjectName,
				"type", object.Type,
				"error", err,
				"duration_ms", time.Since(objectStart).Milliseconds(),
			)
			metrics.RecordObjectProcessed(object.Type, "error", p.podContext)
			return nil, fmt.Errorf("failed to fetch object %q: %w", object.ObjectName, err)
		}

		var combinedContent []byte
		for _, path := range object.Paths {
			combinedContent = append(combinedContent, contents[path]...)
		}

		version, err := p.hmacGenerator.GenerateObjectVersion(object, combinedContent)
		if err != nil {
			p.logger.Error("failed to generate version for object",
				"object_name", object.ObjectName,
				"error", err,
			)
			metrics.RecordObjectProcessed(object.Type, "error_version", p.podContext)
			return nil, fmt.Errorf("failed to generate version for object %q: %w", object.ObjectName, err)
		}
		objectVersions = append(objectVersions, version)

		filePermission := int32(cfg.FilePermission)
		if object.FilePermission != 0 {
			filePermission = int32(object.FilePermission)
		}

		for _, path := range object.Paths {
			files = append(files, &pb.File{
				Path:     path,
				Mode:     filePermission,
				Contents: contents[path],
			})

			p.logger.Info("file created",
				"path", path,
				"size", len(contents[path]),
				"mode", fmt.Sprintf("%o", filePermission),
				"object_name", object.ObjectName,
				"type", object.Type,
			)
		}

		p.logger.Debug("object processed successfully",
			"object_name", object.ObjectName,
			"type", object.Type,
			"duration_ms", time.Since(objectStart).Milliseconds(),
			"version", version.Version,
		)
		metrics.RecordObjectProcessed(object.Type, "success", p.podContext)
	}

	duration := time.Since(start)
	p.logger.Info("mount request completed",
		"duration_ms", duration.Milliseconds(),
		"file_count", len(files),
		"object_count", len(objectVersions),
		"target_path", cfg.TargetPath,
	)

	return &pb.MountResponse{
		Files:         files,
		ObjectVersion: objectVersions,
	}, nil
}

func convertConfigSelectorsToAPISelectors(configSelectors []config.Selector) []*typesapi.Selector {
	selectors := make([]*typesapi.Selector, len(configSelectors))
	for i, selector := range configSelectors {
		selectors[i] = &typesapi.Selector{
			Type:  selector.Type,
			Value: selector.Value,
		}
	}
	return selectors
}

func (p *Provider) buildSpiffeIDFromSelectors(params config.Parameters) string {
	if len(params.Selectors) == 0 {
		p.logger.Warn("no selectors provided")
		return ""
	}

	var namespace, serviceAccount string
	for _, selector := range params.Selectors {
		if selector.Type == "k8s" {
			if strings.HasPrefix(selector.Value, "ns:") {
				namespace = strings.TrimPrefix(selector.Value, "ns:")
			} else if strings.HasPrefix(selector.Value, "sa:") {
				serviceAccount = strings.TrimPrefix(selector.Value, "sa:")
			}
		}
	}

	if namespace != "" && serviceAccount != "" && params.TrustDomain != "" {
		spiffeID := fmt.Sprintf("spiffe://%s/ns/%s/sa/%s", params.TrustDomain, namespace, serviceAccount)
		p.logger.Debug("built SPIFFE ID",
			"trust_domain", params.TrustDomain,
			"namespace", namespace,
			"service_account", serviceAccount,
			"spiffe_id", spiffeID,
		)
		return spiffeID
	}

	p.logger.Warn("unable to build complete SPIFFE ID",
		"trust_domain", params.TrustDomain,
		"namespace", namespace,
		"service_account", serviceAccount,
	)
	return ""
}

func (p *Provider) fetchX509SVID(ctx context.Context, spireClient client.SpireClient, object config.Object, spiffeID string) (map[string][]byte, error) {
	start := time.Now()
	p.logger.Debug("fetching X509 SVID",
		"spiffe_id", spiffeID,
		"object_name", object.ObjectName,
	)

	tlsCert, err := spireClient.GetCertificateForIdentity(spiffeID)
	if err != nil {
		p.logger.Error("failed to get certificate",
			"spiffe_id", spiffeID,
			"error", err,
			"duration_ms", time.Since(start).Milliseconds(),
		)
		return nil, fmt.Errorf("failed to get certificate: %w", err)
	}

	if len(object.Paths) != 3 {
		p.logger.Error("invalid path count for X.509 SVID",
			"expected", 3,
			"actual", len(object.Paths),
			"object_name", object.ObjectName,
		)
		return nil, fmt.Errorf("expected 3 paths for X.509 SVID but got %d", len(object.Paths))
	}

	result := make(map[string][]byte)

	certPath := object.Paths[0]
	keyPath := object.Paths[1]
	bundlePath := object.Paths[2]

	var certPEM strings.Builder
	certCount := 0
	for i, certBytes := range tlsCert.Certificate {
		cert, err := x509.ParseCertificate(certBytes)
		if err != nil {
			p.logger.Error("failed to parse certificate in chain",
				"error", err,
				"cert_index", i,
				"object_name", object.ObjectName,
			)
			return nil, fmt.Errorf("failed to parse certificate: %w", err)
		}

		certPEM.WriteString(string(pem.EncodeToMemory(&pem.Block{
			Type:  "CERTIFICATE",
			Bytes: cert.Raw,
		})))
		certCount++

		p.logger.Trace("added certificate to chain",
			"index", i,
			"subject", cert.Subject,
			"issuer", cert.Issuer,
			"not_before", cert.NotBefore,
			"not_after", cert.NotAfter,
			"is_ca", cert.IsCA,
			"serial_number", cert.SerialNumber.String(),
		)
	}
	result[certPath] = []byte(certPEM.String())
	p.logger.Debug("certificate chain created",
		"path", certPath,
		"cert_count", certCount,
		"size", len(result[certPath]),
	)

	privateKey := tlsCert.PrivateKey
	keyStart := time.Now()

	pkBytes, err := x509.MarshalPKCS8PrivateKey(privateKey)
	if err != nil {
		p.logger.Error("failed to marshal private key",
			"error", err,
			"object_name", object.ObjectName,
		)
		return nil, fmt.Errorf("failed to marshal private key: %w", err)
	}

	keyBytes := pem.EncodeToMemory(&pem.Block{
		Type:  "PRIVATE KEY",
		Bytes: pkBytes,
	})
	result[keyPath] = keyBytes
	p.logger.Debug("private key created",
		"path", keyPath,
		"size", len(result[keyPath]),
		"duration_ms", time.Since(keyStart).Milliseconds(),
		"key_type", fmt.Sprintf("%T", privateKey),
	)

	bundleStart := time.Now()
	var bundlePEM strings.Builder

	certs, err := spireClient.GetCACertificates(ctx)
	if err != nil {
		p.logger.Error("failed to get CA certificates",
			"error", err,
			"object_name", object.ObjectName,
			"duration_ms", time.Since(bundleStart).Milliseconds(),
		)
		return nil, fmt.Errorf("failed to get certificates from trust bundle: %w", err)
	}

	bundleCertCount := 0
	for i, cert := range certs {
		bundlePEM.WriteString(string(pem.EncodeToMemory(&pem.Block{
			Type:  "CERTIFICATE",
			Bytes: cert.Raw,
		})))
		bundleCertCount++

		p.logger.Trace("added CA certificate to bundle",
			"index", i,
			"subject", cert.Subject,
			"issuer", cert.Issuer,
			"not_after", cert.NotAfter,
			"is_ca", cert.IsCA,
		)
	}

	result[bundlePath] = []byte(bundlePEM.String())
	p.logger.Debug("trust bundle created",
		"path", bundlePath,
		"cert_count", bundleCertCount,
		"size", len(result[bundlePath]),
		"duration_ms", time.Since(bundleStart).Milliseconds(),
	)

	totalDuration := time.Since(start)
	p.logger.Info("X509 SVID fetched successfully",
		"object_name", object.ObjectName,
		"spiffe_id", spiffeID,
		"cert_count", certCount,
		"bundle_cert_count", bundleCertCount,
		"total_duration_ms", totalDuration.Milliseconds(),
		"total_size", len(result[certPath])+len(result[keyPath])+len(result[bundlePath]),
	)

	return result, nil
}

func (p *Provider) getOrCreateSpireClient(ctx context.Context, socketPath string, trustDomain string, selectors []config.Selector, flagsConfig config.FlagsConfig) (client.SpireClient, error) {
	p.spireClientMutex.RLock()
	if p.spireClient != nil {
		// Check if the configuration matches
		if p.clientConfig.SpireSocketPath == socketPath &&
			p.clientConfig.SpiffeTrustDomain == trustDomain {
			p.spireClientMutex.RUnlock()
			p.logger.Debug("reusing existing SPIRE client")
			return p.spireClient, nil
		}
		p.spireClientMutex.RUnlock()

		p.logger.Info("SPIRE client configuration changed, recreating client")
		p.stopSpireClient()
	} else {
		p.spireClientMutex.RUnlock()
	}

	p.spireClientMutex.Lock()
	defer p.spireClientMutex.Unlock()

	if p.spireClient != nil {
		return p.spireClient, nil
	}

	clientConfig := client.Config{
		SpireSocketPath:   socketPath,
		SpireSocketPath2:  flagsConfig.SpireSocketPath2,
		SpiffeTrustDomain: trustDomain,
		Selectors:         convertConfigSelectorsToAPISelectors(selectors),
		RotatedQueueSize:  1024,
		PodContext:        p.podContext,
	}

	spireClient, err := client.NewSpireClient(p.logger.Named("spire-client"), clientConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to create SPIRE client: %w", err)
	}

	err = spireClient.Start(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to start SPIRE client: %w", err)
	}

	p.spireClient = spireClient
	p.clientConfig = clientConfig
	p.logger.Info("created new SPIRE client")

	return spireClient, nil
}

func (p *Provider) stopSpireClient() {
	p.spireClientMutex.Lock()
	defer p.spireClientMutex.Unlock()

	if p.spireClient != nil {
		p.logger.Info("stopping SPIRE client")
		p.spireClient.Stop()
		p.spireClient = nil
	}
}

func (p *Provider) Stop() error {
	p.stopSpireClient()
	return nil
}

func (p *Provider) fetchJWTSVID(ctx context.Context, spireClient client.SpireClient, object config.Object, spiffeID string) (map[string][]byte, error) {
	start := time.Now()
	p.logger.Debug("fetching JWT SVID",
		"spiffe_id", spiffeID,
		"object_name", object.ObjectName,
		"audiences", object.Audience,
		"audience_count", len(object.Audience),
	)

	if len(object.Audience) == 0 {
		p.logger.Error("no audience specified for JWT SVID",
			"object_name", object.ObjectName,
		)
		return nil, fmt.Errorf("no audience specified for JWT SVID")
	}

	if len(object.Paths) != 1 {
		p.logger.Error("invalid path count for JWT SVID",
			"expected", 1,
			"actual", len(object.Paths),
			"object_name", object.ObjectName,
		)
		return nil, fmt.Errorf("expected 1 path for JWT SVID but got %d", len(object.Paths))
	}

	token, err := spireClient.FetchJWTSVID(ctx, spiffeID, object.Audience)
	if err != nil {
		p.logger.Error("failed to fetch JWT SVID",
			"spiffe_id", spiffeID,
			"audiences", object.Audience,
			"error", err,
			"duration_ms", time.Since(start).Milliseconds(),
		)
		return nil, fmt.Errorf("failed to fetch JWT SVID: %w", err)
	}

	result := make(map[string][]byte)
	result[object.Paths[0]] = []byte(token)

	p.logger.Debug("JWT token details",
		"token_size", len(token),
		"has_header", strings.HasPrefix(token, "eyJ"),
		"part_count", len(strings.Split(token, ".")),
	)

	duration := time.Since(start)
	p.logger.Info("JWT SVID fetched successfully",
		"object_name", object.ObjectName,
		"spiffe_id", spiffeID,
		"audiences", object.Audience,
		"token_size", len(token),
		"path", object.Paths[0],
		"duration_ms", duration.Milliseconds(),
	)

	return result, nil
}
</file>

<file path="server/server_test.go">
package server

import (
	"context"
	"crypto/rand"
	"crypto/rsa"
	"crypto/tls"
	"crypto/x509"
	"crypto/x509/pkix"
	"encoding/json"
	"errors"
	"fmt"
	"math/big"
	"spire-csi-provider/internal/client"
	"strings"
	"sync"
	"testing"
	"time"

	"github.com/golang/mock/gomock"
	"github.com/hashicorp/go-hclog"
	healthpb "google.golang.org/grpc/health/grpc_health_v1"
	pb "sigs.k8s.io/secrets-store-csi-driver/provider/v1alpha1"
	"spire-csi-provider/internal/config"
	"spire-csi-provider/internal/hmac"
	"spire-csi-provider/internal/version"
)

func TestNewServer(t *testing.T) {
	tests := []struct {
		name        string
		logger      hclog.Logger
		flagsConfig config.FlagsConfig
		hmacGen     *hmac.HMACGenerator
		wantPanic   bool
	}{
		{
			name:   "valid configuration",
			logger: hclog.NewNullLogger(),
			flagsConfig: config.FlagsConfig{
				ProviderStaleTimeout:    10 * time.Minute,
				ProviderCleanupInterval: 5 * time.Minute,
				SpireSocketPath:         "/socket",
			},
			hmacGen:   hmac.NewHMACGenerator([]byte("test-key")),
			wantPanic: false,
		},
		{
			name:   "nil logger should panic",
			logger: nil,
			flagsConfig: config.FlagsConfig{
				ProviderStaleTimeout:    10 * time.Minute,
				ProviderCleanupInterval: 5 * time.Minute,
			},
			hmacGen:   hmac.NewHMACGenerator([]byte("test-key")),
			wantPanic: true,
		},
		{
			name:   "nil hmac generator",
			logger: hclog.NewNullLogger(),
			flagsConfig: config.FlagsConfig{
				ProviderStaleTimeout:    10 * time.Minute,
				ProviderCleanupInterval: 5 * time.Minute,
			},
			hmacGen:   nil,
			wantPanic: false,
		},
		{
			name:   "zero timeouts",
			logger: hclog.NewNullLogger(),
			flagsConfig: config.FlagsConfig{
				ProviderStaleTimeout:    0,
				ProviderCleanupInterval: 0,
			},
			hmacGen:   hmac.NewHMACGenerator([]byte("test-key")),
			wantPanic: false,
		},
		{
			name:   "dual agent mode",
			logger: hclog.NewNullLogger(),
			flagsConfig: config.FlagsConfig{
				SpireSocketPath:         "/socket1",
				SpireSocketPath2:        "/socket2",
				ProviderStaleTimeout:    10 * time.Minute,
				ProviderCleanupInterval: 5 * time.Minute,
			},
			hmacGen:   hmac.NewHMACGenerator([]byte("test-key")),
			wantPanic: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			if tt.wantPanic {
				defer func() {
					if r := recover(); r == nil {
						t.Error("Expected panic but didn't get one")
					}
				}()
			}

			server := NewServer(tt.logger, tt.flagsConfig, tt.hmacGen)

			if tt.wantPanic {
				t.Error("Should have panicked but didn't")
				return
			}

			if server == nil {
				t.Error("Expected non-nil server")
				return
			}

			if server.logger == nil && tt.logger != nil {
				t.Error("Logger not set correctly")
			}
			if server.hmacGenerator != tt.hmacGen {
				t.Error("HMAC generator not set correctly")
			}
			if server.clientPool == nil {
				t.Error("Client pool should be initialized")
			}
			if server.flagsConfig.SpireSocketPath != tt.flagsConfig.SpireSocketPath {
				t.Error("Socket path not set correctly")
			}
			if server.flagsConfig.SpireSocketPath2 != tt.flagsConfig.SpireSocketPath2 {
				t.Error("Socket path 2 not set correctly")
			}
		})
	}
}

func TestServer_Version(t *testing.T) {
	tests := []struct {
		name           string
		buildVersion   string
		driverVersion  string
		expectedRT     string
		expectedRTName string
	}{
		{
			name:           "standard version",
			buildVersion:   "v1.2.3",
			driverVersion:  "v0.0.1",
			expectedRT:     "v1.2.3",
			expectedRTName: "spire-csi-provider",
		},
		{
			name:           "development version",
			buildVersion:   "dev",
			driverVersion:  "v0.0.2",
			expectedRT:     "dev",
			expectedRTName: "spire-csi-provider",
		},
		{
			name:           "empty version",
			buildVersion:   "",
			driverVersion:  "",
			expectedRT:     "",
			expectedRTName: "spire-csi-provider",
		},
		{
			name:           "semantic version",
			buildVersion:   "v2.0.0-rc1",
			driverVersion:  "v1.0.0",
			expectedRT:     "v2.0.0-rc1",
			expectedRTName: "spire-csi-provider",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			flagsConfig := config.FlagsConfig{}
			hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
			server := NewServer(logger, flagsConfig, hmacGen)

			// Set version for testing
			version.BuildVersion = tt.buildVersion

			req := &pb.VersionRequest{
				Version: tt.driverVersion,
			}

			ctx := context.Background()
			resp, err := server.Version(ctx, req)

			if err != nil {
				t.Fatalf("Version() error = %v", err)
			}

			if resp.Version != "v1alpha1" {
				t.Errorf("Expected API version v1alpha1, got %s", resp.Version)
			}
			if resp.RuntimeName != tt.expectedRTName {
				t.Errorf("Expected runtime name %s, got %s", tt.expectedRTName, resp.RuntimeName)
			}
			if resp.RuntimeVersion != tt.expectedRT {
				t.Errorf("Expected runtime version %s, got %s", tt.expectedRT, resp.RuntimeVersion)
			}
		})
	}
}

func TestServer_Mount_VariousConfigurations(t *testing.T) {
	tests := []struct {
		name            string
		attributes      map[string]string
		permission      string
		targetPath      string
		currentVersions []*pb.ObjectVersion
		setupMock       func(*gomock.Controller) *client.MockClientPoolInterface
		expectFiles     int
		expectVersions  int
		expectError     bool
		errorContains   string
	}{
		{
			name: "successful JWT mount",
			attributes: map[string]string{
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"trustDomain":                            "example.org",
				"objects": `
- objectName: test-jwt
  type: jwt-svid
  audience:
    - audience1
  paths:
    - /token.jwt`,
			},
			permission: "420",
			targetPath: "/var/run/secrets",
			setupMock: func(ctrl *gomock.Controller) *client.MockClientPoolInterface {
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return("test-jwt-token", nil)

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()
				mockPool.EXPECT().GetPoolStats().Return(map[string]interface{}{
					"total_clients":  1,
					"active_clients": 1,
					"total_refs":     1,
				})
				return mockPool
			},
			expectFiles:    1,
			expectVersions: 1,
			expectError:    false,
		},
		{
			name: "successful X509 mount",
			attributes: map[string]string{
				"csi.storage.k8s.io/pod.namespace":       "production",
				"csi.storage.k8s.io/pod.name":            "prod-pod",
				"csi.storage.k8s.io/pod.uid":             "789-012",
				"csi.storage.k8s.io/serviceAccount.name": "prod-sa",
				"trustDomain":                            "prod.example.org",
				"objects": `
- objectName: x509-cert
  type: x509-svid
  paths:
    - /tls/cert.pem
    - /tls/key.pem
    - /tls/ca.pem`,
			},
			permission: "384", // 0600
			targetPath: "/var/run/tls",
			setupMock: func(ctrl *gomock.Controller) *client.MockClientPoolInterface {
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)

				// For X509, we need certificate and CA certs
				cert, key := generateTestCertAndKey()
				mockClient.EXPECT().GetCertificateForIdentity(gomock.Any()).Return(&tls.Certificate{
					Certificate: [][]byte{cert},
					PrivateKey:  key,
				}, nil)
				mockClient.EXPECT().GetCACertificates(gomock.Any()).Return([]*x509.Certificate{
					generateTestCA(),
				}, nil)

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()
				mockPool.EXPECT().GetPoolStats().Return(map[string]interface{}{
					"total_clients": 1,
				})
				return mockPool
			},
			expectFiles:    3,
			expectVersions: 1,
			expectError:    false,
		},
		{
			name: "multiple objects",
			attributes: map[string]string{
				"csi.storage.k8s.io/pod.namespace":       "staging",
				"csi.storage.k8s.io/pod.name":            "multi-pod",
				"csi.storage.k8s.io/pod.uid":             "multi-123",
				"csi.storage.k8s.io/serviceAccount.name": "multi-sa",
				"trustDomain":                            "staging.example.org",
				"objects": `
- objectName: jwt-token
  type: jwt-svid
  audience:
    - api.staging
  paths:
    - /tokens/api.jwt
- objectName: x509-cert
  type: x509-svid
  paths:
    - /certs/cert.pem
    - /certs/key.pem
    - /certs/bundle.pem`,
			},
			permission: "420",
			targetPath: "/var/run/secrets",
			setupMock: func(ctrl *gomock.Controller) *client.MockClientPoolInterface {
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return("staging-jwt", nil)

				cert, key := generateTestCertAndKey()
				mockClient.EXPECT().GetCertificateForIdentity(gomock.Any()).Return(&tls.Certificate{
					Certificate: [][]byte{cert},
					PrivateKey:  key,
				}, nil)
				mockClient.EXPECT().GetCACertificates(gomock.Any()).Return([]*x509.Certificate{
					generateTestCA(),
				}, nil)

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()
				mockPool.EXPECT().GetPoolStats().Return(map[string]interface{}{
					"total_clients": 2,
				})
				return mockPool
			},
			expectFiles:    4,
			expectVersions: 2,
			expectError:    false,
		},
		{
			name: "with current object versions",
			attributes: map[string]string{
				"csi.storage.k8s.io/pod.namespace":       "default",
				"csi.storage.k8s.io/pod.name":            "test-pod",
				"csi.storage.k8s.io/pod.uid":             "123-456",
				"csi.storage.k8s.io/serviceAccount.name": "test-sa",
				"trustDomain":                            "example.org",
				"objects": `
- objectName: test-jwt
  type: jwt-svid
  audience:
    - audience1
  paths:
    - /token.jwt`,
			},
			permission: "420",
			targetPath: "/var/run/secrets",
			currentVersions: []*pb.ObjectVersion{
				{
					Id:      "test-jwt",
					Version: "old-version-123",
				},
			},
			setupMock: func(ctrl *gomock.Controller) *client.MockClientPoolInterface {
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return("new-jwt-token", nil)

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()
				mockPool.EXPECT().GetPoolStats().Return(map[string]interface{}{
					"total_clients": 1,
				})
				return mockPool
			},
			expectFiles:    1,
			expectVersions: 1,
			expectError:    false,
		},
		{
			name: "kube-system namespace",
			attributes: map[string]string{
				"csi.storage.k8s.io/pod.namespace":       "kube-system",
				"csi.storage.k8s.io/pod.name":            "system-pod",
				"csi.storage.k8s.io/pod.uid":             "sys-123",
				"csi.storage.k8s.io/serviceAccount.name": "system-sa",
				"trustDomain":                            "cluster.local",
				"objects": `
- objectName: system-jwt
  type: jwt-svid
  audience:
    - kube-apiserver
  paths:
    - /system/token.jwt`,
			},
			permission: "256", // 0400
			targetPath: "/var/run/system",
			setupMock: func(ctrl *gomock.Controller) *client.MockClientPoolInterface {
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)
				mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), []string{"kube-apiserver"}).Return("system-jwt", nil)

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()
				mockPool.EXPECT().GetPoolStats().Return(map[string]interface{}{
					"total_clients": 1,
				})
				return mockPool
			},
			expectFiles:    1,
			expectVersions: 1,
			expectError:    false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			flagsConfig := config.FlagsConfig{
				SpireSocketPath: "/run/spire/socket",
			}
			hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
			server := NewServer(logger, flagsConfig, hmacGen)

			attributesJSON, _ := json.Marshal(tt.attributes)

			req := &pb.MountRequest{
				Attributes:           string(attributesJSON),
				TargetPath:           tt.targetPath,
				Permission:           tt.permission,
				Secrets:              "{}",
				CurrentObjectVersion: tt.currentVersions,
			}

			server.clientPool = tt.setupMock(ctrl)

			ctx := context.Background()
			resp, err := server.Mount(ctx, req)

			if tt.expectError {
				if err == nil {
					t.Fatal("Expected error but got none")
				}
				if tt.errorContains != "" && !contains(err.Error(), tt.errorContains) {
					t.Errorf("Error should contain %q, got %q", tt.errorContains, err.Error())
				}
			} else {
				if err != nil {
					t.Fatalf("Mount() error = %v", err)
				}

				if resp == nil {
					t.Fatal("Expected non-nil response")
				}

				if len(resp.Files) != tt.expectFiles {
					t.Errorf("Expected %d files, got %d", tt.expectFiles, len(resp.Files))
				}
				if len(resp.ObjectVersion) != tt.expectVersions {
					t.Errorf("Expected %d object versions, got %d", tt.expectVersions, len(resp.ObjectVersion))
				}
			}
		})
	}
}

// internal/server/server_test.go - Fixed version

func TestServer_Mount_ErrorCases(t *testing.T) {
	tests := []struct {
		name          string
		attributes    string
		permission    string
		targetPath    string
		setupMock     func(*gomock.Controller) *client.MockClientPoolInterface
		errorContains string
	}{
		{
			name:          "invalid JSON attributes",
			attributes:    "not-valid-json{",
			permission:    "420",
			targetPath:    "/var/run/secrets",
			setupMock:     nil,
			errorContains: "error parsing configuration",
		},
		{
			name:          "invalid permission format",
			attributes:    `{"trustDomain":"example.org"}`,
			permission:    "not-a-number",
			targetPath:    "/var/run/secrets",
			setupMock:     nil,
			errorContains: "error parsing configuration",
		},
		{
			name:          "empty attributes",
			attributes:    "",
			permission:    "420",
			targetPath:    "/var/run/secrets",
			setupMock:     nil,
			errorContains: "error parsing configuration",
		},
		{
			name: "missing pod info - no namespace",
			attributes: func() string {
				attrs := map[string]string{
					// Missing csi.storage.k8s.io/pod.namespace
					"csi.storage.k8s.io/pod.name":            "test-pod",
					"csi.storage.k8s.io/pod.uid":             "123",
					"csi.storage.k8s.io/serviceAccount.name": "test-sa",
					"trustDomain":                            "example.org",
					"objects": `
- objectName: test
  type: jwt-svid
  audience: ["test"]
  paths: ["/token"]`,
				}
				data, _ := json.Marshal(attrs)
				return string(data)
			}(),
			permission: "420",
			targetPath: "/var/run/secrets",
			setupMock: func(ctrl *gomock.Controller) *client.MockClientPoolInterface {
				// Even with missing namespace, the config might pass parsing
				// but we should fail fast at the provider level
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).
					Return(errors.New("invalid SPIFFE ID")).MaxTimes(1)

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil).MaxTimes(1)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return().MaxTimes(1)
				return mockPool
			},
			errorContains: "error handling mount request",
		},
		{
			name: "completely missing pod info fields",
			attributes: func() string {
				attrs := map[string]string{
					"trustDomain": "example.org",
					"objects": `
- objectName: test
  type: jwt-svid
  audience: ["test"]
  paths: ["/token"]`,
				}
				data, _ := json.Marshal(attrs)
				return string(data)
			}(),
			permission: "420",
			targetPath: "/var/run/secrets",
			setupMock: func(ctrl *gomock.Controller) *client.MockClientPoolInterface {
				// With completely missing pod info, it should build an empty SPIFFE ID
				// and fail immediately
				mockClient := client.NewMockSpireClient(ctrl)
				mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).
					Return(errors.New("empty SPIFFE ID")).MaxTimes(1)

				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil).MaxTimes(1)
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return().MaxTimes(1)
				return mockPool
			},
			errorContains: "error handling mount request",
		},
		{
			name: "no objects configured",
			attributes: func() string {
				attrs := map[string]string{
					"csi.storage.k8s.io/pod.namespace":       "default",
					"csi.storage.k8s.io/pod.name":            "test-pod",
					"csi.storage.k8s.io/pod.uid":             "123",
					"csi.storage.k8s.io/serviceAccount.name": "test-sa",
					"trustDomain":                            "example.org",
					// No objects field
				}
				data, _ := json.Marshal(attrs)
				return string(data)
			}(),
			permission:    "420",
			targetPath:    "/var/run/secrets",
			setupMock:     nil,
			errorContains: "no objects configured",
		},
		{
			name: "invalid object type in YAML",
			attributes: func() string {
				attrs := map[string]string{
					"csi.storage.k8s.io/pod.namespace":       "default",
					"csi.storage.k8s.io/pod.name":            "test-pod",
					"csi.storage.k8s.io/pod.uid":             "123",
					"csi.storage.k8s.io/serviceAccount.name": "test-sa",
					"trustDomain":                            "example.org",
					"objects": `
- objectName: test
  type: invalid-type
  paths: ["/token"]`,
				}
				data, _ := json.Marshal(attrs)
				return string(data)
			}(),
			permission:    "420",
			targetPath:    "/var/run/secrets",
			setupMock:     nil,
			errorContains: "invalid type",
		},
		{
			name: "provider pool error",
			attributes: func() string {
				attrs := map[string]string{
					"csi.storage.k8s.io/pod.namespace":       "default",
					"csi.storage.k8s.io/pod.name":            "test-pod",
					"csi.storage.k8s.io/pod.uid":             "123",
					"csi.storage.k8s.io/serviceAccount.name": "test-sa",
					"trustDomain":                            "example.org",
					"objects": `
- objectName: test
  type: jwt-svid
  audience: ["test"]
  paths: ["/token"]`,
				}
				data, _ := json.Marshal(attrs)
				return string(data)
			}(),
			permission: "420",
			targetPath: "/var/run/secrets",
			setupMock: func(ctrl *gomock.Controller) *client.MockClientPoolInterface {
				mockPool := client.NewMockClientPoolInterface(ctrl)
				mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(nil, errors.New("pool error"))
				mockPool.EXPECT().ReleaseClient(gomock.Any()).Return().AnyTimes()
				return mockPool
			},
			errorContains: "error handling mount request",
		},
		{
			name: "missing target path",
			attributes: func() string {
				attrs := map[string]string{
					"csi.storage.k8s.io/pod.namespace":       "default",
					"csi.storage.k8s.io/pod.name":            "test-pod",
					"csi.storage.k8s.io/pod.uid":             "123",
					"csi.storage.k8s.io/serviceAccount.name": "test-sa",
					"trustDomain":                            "example.org",
					"objects": `
- objectName: test
  type: jwt-svid
  audience: ["test"]
  paths: ["/token"]`,
				}
				data, _ := json.Marshal(attrs)
				return string(data)
			}(),
			permission:    "420",
			targetPath:    "", // Empty target path
			setupMock:     nil,
			errorContains: "missing target path",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			flagsConfig := config.FlagsConfig{
				SpireSocketPath: "/run/spire/socket",
			}
			hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
			server := NewServer(logger, flagsConfig, hmacGen)

			req := &pb.MountRequest{
				Attributes: tt.attributes,
				TargetPath: tt.targetPath,
				Permission: tt.permission,
				Secrets:    "{}",
			}

			if tt.setupMock != nil {
				server.clientPool = tt.setupMock(ctrl)
			}

			// Use a context with a shorter timeout to avoid waiting 30s
			ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
			defer cancel()

			_, err := server.Mount(ctx, req)

			if err == nil {
				t.Fatal("Expected error but got none")
			}
			if !contains(err.Error(), tt.errorContains) {
				t.Errorf("Expected error containing %q, got %q", tt.errorContains, err.Error())
			}
		})
	}
}

func TestServer_Mount_ConcurrentRequests(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	logger := hclog.NewNullLogger()
	flagsConfig := config.FlagsConfig{
		SpireSocketPath: "/run/spire/socket",
	}
	hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
	server := NewServer(logger, flagsConfig, hmacGen)

	// Setup mock that can handle concurrent calls
	mockClient := client.NewMockSpireClient(ctrl)
	mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil).AnyTimes()
	mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil).AnyTimes()
	mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return("concurrent-jwt", nil).AnyTimes()

	mockPool := client.NewMockClientPoolInterface(ctrl)
	mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil).AnyTimes()
	mockPool.EXPECT().ReleaseClient(gomock.Any()).Return().AnyTimes()
	mockPool.EXPECT().GetPoolStats().Return(map[string]interface{}{
		"total_clients":  1,
		"active_clients": 1,
	}).AnyTimes()

	server.clientPool = mockPool

	// Prepare request
	attributes := map[string]string{
		"csi.storage.k8s.io/pod.namespace":       "concurrent",
		"csi.storage.k8s.io/pod.name":            "concurrent-pod",
		"csi.storage.k8s.io/pod.uid":             "concurrent-123",
		"csi.storage.k8s.io/serviceAccount.name": "concurrent-sa",
		"trustDomain":                            "example.org",
		"objects": `
- objectName: jwt
  type: jwt-svid
  audience: ["test"]
  paths: ["/token.jwt"]`,
	}
	attributesJSON, _ := json.Marshal(attributes)

	// Run concurrent requests
	numRequests := 20
	var wg sync.WaitGroup
	errorsChan := make(chan error, numRequests)

	for i := 0; i < numRequests; i++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()

			// Create unique request for each goroutine
			req := &pb.MountRequest{
				Attributes: string(attributesJSON),
				TargetPath: fmt.Sprintf("/var/run/secrets/%d", id),
				Permission: "420",
				Secrets:    "{}",
			}

			ctx := context.Background()
			resp, err := server.Mount(ctx, req)
			if err != nil {
				errorsChan <- err
				return
			}
			if resp == nil || len(resp.Files) == 0 {
				errorsChan <- errors.New("invalid response")
			}
		}(i)
	}

	wg.Wait()
	close(errorsChan)

	// Check for errors
	var errorCount int
	for err := range errorsChan {
		t.Errorf("Concurrent request failed: %v", err)
		errorCount++
	}

	if errorCount > 0 {
		t.Errorf("%d out of %d concurrent requests failed", errorCount, numRequests)
	}
}

func TestServer_Shutdown(t *testing.T) {
	tests := []struct {
		name        string
		shutdownErr error
		expectError bool
	}{
		{
			name:        "successful shutdown",
			shutdownErr: nil,
			expectError: false,
		},
		{
			name:        "shutdown with error",
			shutdownErr: errors.New("shutdown failed"),
			expectError: true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctrl := gomock.NewController(t)
			defer ctrl.Finish()

			logger := hclog.NewNullLogger()
			flagsConfig := config.FlagsConfig{}
			hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
			server := NewServer(logger, flagsConfig, hmacGen)

			// Create mock pool
			mockPool := client.NewMockClientPoolInterface(ctrl)
			mockPool.EXPECT().Shutdown().Return(tt.shutdownErr)

			server.clientPool = mockPool

			err := server.Shutdown()

			if (err != nil) != tt.expectError {
				t.Errorf("Shutdown() error = %v, expectError %v", err, tt.expectError)
			}
			if err != nil && tt.shutdownErr != nil && err.Error() != tt.shutdownErr.Error() {
				t.Errorf("Expected error %v, got %v", tt.shutdownErr, err)
			}
		})
	}
}

func TestHealthServer_Check(t *testing.T) {
	tests := []struct {
		name    string
		service string
		want    healthpb.HealthCheckResponse_ServingStatus
	}{
		{
			name:    "check default service",
			service: "",
			want:    healthpb.HealthCheckResponse_SERVING,
		},
		{
			name:    "check specific service",
			service: "spire-csi-provider",
			want:    healthpb.HealthCheckResponse_SERVING,
		},
		{
			name:    "check unknown service",
			service: "unknown-service",
			want:    healthpb.HealthCheckResponse_SERVING,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			logger := hclog.NewNullLogger()
			hs := &healthServer{logger: logger}

			req := &healthpb.HealthCheckRequest{
				Service: tt.service,
			}

			ctx := context.Background()
			resp, err := hs.Check(ctx, req)

			if err != nil {
				t.Fatalf("Check() error = %v", err)
			}

			if resp.Status != tt.want {
				t.Errorf("Expected status %v, got %v", tt.want, resp.Status)
			}
		})
	}
}

func TestHealthServer_Watch(t *testing.T) {
	logger := hclog.NewNullLogger()
	hs := &healthServer{logger: logger}

	req := &healthpb.HealthCheckRequest{
		Service: "test-service",
	}

	// Watch currently returns nil (not implemented)
	err := hs.Watch(req, nil)
	if err != nil {
		t.Errorf("Watch() error = %v", err)
	}
}

func TestGenerateRequestID(t *testing.T) {
	// Test uniqueness
	ids := make(map[string]bool)
	for i := 0; i < 100; i++ {
		id := generateRequestID()
		if id == "" {
			t.Error("Generated empty request ID")
		}
		if ids[id] {
			t.Errorf("Duplicate request ID generated: %s", id)
		}
		ids[id] = true
		time.Sleep(1 * time.Microsecond) // Ensure different timestamps
	}
}

func TestServer_Mount_MetricsLogging(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()

	// Create a custom logger to capture logs
	logger := hclog.NewNullLogger()
	flagsConfig := config.FlagsConfig{
		SpireSocketPath: "/run/spire/socket",
	}
	hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
	server := NewServer(logger, flagsConfig, hmacGen)

	// Setup successful mount
	mockClient := client.NewMockSpireClient(ctrl)
	mockClient.EXPECT().WaitForSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
	mockClient.EXPECT().WaitForTrustBundle(gomock.Any(), gomock.Any()).Return(nil)
	mockClient.EXPECT().FetchJWTSVID(gomock.Any(), gomock.Any(), gomock.Any()).Return("metrics-jwt", nil)

	mockPool := client.NewMockClientPoolInterface(ctrl)
	mockPool.EXPECT().AcquireClient(gomock.Any(), gomock.Any()).Return(mockClient, nil)
	mockPool.EXPECT().ReleaseClient(gomock.Any()).Return()

	// Expect GetPoolStats to be called
	poolStats := map[string]interface{}{
		"total_clients":  5,
		"active_clients": 3,
		"total_refs":     10,
	}
	mockPool.EXPECT().GetPoolStats().Return(poolStats)

	server.clientPool = mockPool

	attributes := map[string]string{
		"csi.storage.k8s.io/pod.namespace":       "monitoring",
		"csi.storage.k8s.io/pod.name":            "metrics-collector",
		"csi.storage.k8s.io/pod.uid":             "metrics-123",
		"csi.storage.k8s.io/serviceAccount.name": "metrics-sa",
		"trustDomain":                            "metrics.example.org",
		"objects": `
- objectName: metrics-jwt
  type: jwt-svid
  audience: ["prometheus"]
  paths: ["/metrics/token.jwt"]`,
	}
	attributesJSON, _ := json.Marshal(attributes)

	req := &pb.MountRequest{
		Attributes: string(attributesJSON),
		TargetPath: "/var/run/metrics",
		Permission: "420",
		Secrets:    "{}",
	}

	ctx := context.Background()
	resp, err := server.Mount(ctx, req)

	if err != nil {
		t.Fatalf("Mount() error = %v", err)
	}

	// Verify response
	if len(resp.Files) != 1 {
		t.Errorf("Expected 1 file, got %d", len(resp.Files))
	}

	// Verify that pool stats were retrieved (this confirms GetPoolStats was called)
	// The actual metrics recording would be tested in integration tests
}

func TestServer_Version_EdgeCases(t *testing.T) {
	logger := hclog.NewNullLogger()
	flagsConfig := config.FlagsConfig{}
	hmacGen := hmac.NewHMACGenerator([]byte("test-key"))
	server := NewServer(logger, flagsConfig, hmacGen)

	tests := []struct {
		name        string
		request     *pb.VersionRequest
		expectError bool
	}{
		{
			name:        "nil request",
			request:     nil,
			expectError: false,
		},
		{
			name:        "empty version in request",
			request:     &pb.VersionRequest{Version: ""},
			expectError: false,
		},
		{
			name:        "very long version string",
			request:     &pb.VersionRequest{Version: strings.Repeat("v", 1000)},
			expectError: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctx := context.Background()
			resp, err := server.Version(ctx, tt.request)

			if (err != nil) != tt.expectError {
				t.Errorf("Version() error = %v, expectError %v", err, tt.expectError)
			}

			if !tt.expectError && resp != nil {
				if resp.Version != "v1alpha1" {
					t.Errorf("Expected API version v1alpha1, got %s", resp.Version)
				}
				if resp.RuntimeName != "spire-csi-provider" {
					t.Errorf("Expected runtime name spire-csi-provider, got %s", resp.RuntimeName)
				}
			}
		})
	}
}

// Helper functions
func generateTestCertAndKey() ([]byte, *rsa.PrivateKey) {
	key, _ := rsa.GenerateKey(rand.Reader, 2048)
	template := x509.Certificate{
		SerialNumber: big.NewInt(1),
		Subject: pkix.Name{
			Organization: []string{"Test"},
		},
		NotBefore: time.Now(),
		NotAfter:  time.Now().Add(365 * 24 * time.Hour),
		KeyUsage:  x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature,
	}
	certDER, _ := x509.CreateCertificate(rand.Reader, &template, &template, &key.PublicKey, key)
	return certDER, key
}

func generateTestCA() *x509.Certificate {
	key, _ := rsa.GenerateKey(rand.Reader, 2048)
	template := x509.Certificate{
		SerialNumber: big.NewInt(1),
		Subject: pkix.Name{
			Organization: []string{"Test CA"},
		},
		NotBefore:             time.Now(),
		NotAfter:              time.Now().Add(365 * 24 * time.Hour),
		KeyUsage:              x509.KeyUsageCertSign,
		BasicConstraintsValid: true,
		IsCA:                  true,
	}
	certDER, _ := x509.CreateCertificate(rand.Reader, &template, &template, &key.PublicKey, key)
	cert, _ := x509.ParseCertificate(certDER)
	return cert
}

func contains(s, substr string) bool {
	return strings.Contains(s, substr)
}
</file>

<file path="server/server.go">
package server

import (
	"context"
	"encoding/json"
	"fmt"
	healthpb "google.golang.org/grpc/health/grpc_health_v1"
	"time"

	"github.com/hashicorp/go-hclog"
	pb "sigs.k8s.io/secrets-store-csi-driver/provider/v1alpha1"
	"spire-csi-provider/internal/client"
	"spire-csi-provider/internal/config"
	"spire-csi-provider/internal/hmac"
	"spire-csi-provider/internal/metrics"
	"spire-csi-provider/internal/provider"
	"spire-csi-provider/internal/version"
)

type healthServer struct {
	logger hclog.Logger
}

func (s *healthServer) Check(ctx context.Context, req *healthpb.HealthCheckRequest) (*healthpb.HealthCheckResponse, error) {
	s.logger.Trace("health check requested", "service", req.Service)
	metrics.HealthCheckStatus.Set(1)
	return &healthpb.HealthCheckResponse{Status: healthpb.HealthCheckResponse_SERVING}, nil
}

func (s *healthServer) Watch(req *healthpb.HealthCheckRequest, ws healthpb.Health_WatchServer) error {
	s.logger.Trace("health watch requested", "service", req.Service)
	return nil
}

type Server struct {
	logger        hclog.Logger
	flagsConfig   config.FlagsConfig
	hmacGenerator *hmac.HMACGenerator

	clientPool client.ClientPoolInterface

	pb.UnimplementedCSIDriverProviderServer
}

func NewServer(logger hclog.Logger, flagsConfig config.FlagsConfig, hmacGenerator *hmac.HMACGenerator) *Server {
	s := &Server{
		logger:        logger.Named("server"),
		flagsConfig:   flagsConfig,
		hmacGenerator: hmacGenerator,
	}

	poolConfig := client.PoolConfig{
		StaleTimeout:    flagsConfig.ProviderStaleTimeout,
		CleanupInterval: flagsConfig.ProviderCleanupInterval,
	}
	s.clientPool = client.NewClientPool(logger, poolConfig)

	s.logger.Info("SPIRE client pool initialized",
		"stale_timeout", poolConfig.StaleTimeout,
		"cleanup_interval", poolConfig.CleanupInterval,
	)

	return s
}

func (s *Server) Version(ctx context.Context, req *pb.VersionRequest) (*pb.VersionResponse, error) {
	s.logger.Debug("version request received",
		"driver_version", req.GetVersion(),
		"request_id", generateRequestID(),
	)

	response := &pb.VersionResponse{
		Version:        "v1alpha1",
		RuntimeName:    "spire-csi-provider",
		RuntimeVersion: version.BuildVersion,
	}

	s.logger.Debug("version response sent",
		"runtime_version", response.RuntimeVersion,
		"api_version", response.Version,
	)

	return response, nil
}

func (s *Server) Mount(ctx context.Context, req *pb.MountRequest) (*pb.MountResponse, error) {
	start := time.Now()
	requestID := generateRequestID()

	var podNamespace, podName, podUID, serviceAccount string
	if req.Attributes != "" {
		var attrs map[string]string
		if err := json.Unmarshal([]byte(req.Attributes), &attrs); err != nil {
			s.logger.Warn("failed to parse attributes for logging",
				"request_id", requestID,
				"error", err,
			)
		} else {
			podNamespace = attrs["csi.storage.k8s.io/pod.namespace"]
			podName = attrs["csi.storage.k8s.io/pod.name"]
			podUID = attrs["csi.storage.k8s.io/pod.uid"]
			serviceAccount = attrs["csi.storage.k8s.io/serviceAccount.name"]
		}
	}

	// Create pod context for metrics
	podContext := metrics.PodContext{
		Namespace:      podNamespace,
		ServiceAccount: serviceAccount,
		PodUID:         podUID,
		PodName:        podName,
	}

	s.logger.Info("mount request received",
		"request_id", requestID,
		"target_path", req.GetTargetPath(),
		"permission", req.GetPermission(),
		"pod_namespace", podNamespace,
		"pod_name", podName,
		"pod_uid", podUID,
		"service_account", serviceAccount,
	)

	s.logger.Trace("mount request details",
		"request_id", requestID,
		"attributes_length", len(req.Attributes),
		"secrets_length", len(req.Secrets),
		"current_object_versions", len(req.CurrentObjectVersion),
	)

	if s.logger.IsTrace() {
		s.logger.Trace("mount request raw attributes",
			"request_id", requestID,
			"attributes", req.Attributes,
		)
	}

	cfg, err := config.Parse(req.Attributes, req.TargetPath, req.Permission)
	if err != nil {
		duration := time.Since(start)
		s.logger.Error("failed to parse configuration",
			"request_id", requestID,
			"error", err,
			"duration_ms", duration.Milliseconds(),
			"pod_namespace", podNamespace,
			"pod_name", podName,
		)
		metrics.RecordMountRequest("error_parse_config", duration.Seconds(), podContext)
		return nil, fmt.Errorf("error parsing configuration: %w", err)
	}

	s.logger.Debug("configuration parsed successfully",
		"request_id", requestID,
		"trust_domain", cfg.Parameters.TrustDomain,
		"use_case", cfg.Parameters.UseCase,
		"object_count", len(cfg.Parameters.Objects),
		"pod_namespace", cfg.Parameters.PodInfo.Namespace,
		"pod_name", cfg.Parameters.PodInfo.Name,
		"service_account", cfg.Parameters.PodInfo.ServiceAccountName,
	)

	for i, selector := range cfg.Parameters.Selectors {
		s.logger.Debug("parsed selector",
			"request_id", requestID,
			"index", i,
			"type", selector.Type,
			"value", selector.Value,
		)
	}

	for _, obj := range cfg.Parameters.Objects {
		s.logger.Debug("processing object",
			"request_id", requestID,
			"object_name", obj.ObjectName,
			"object_type", obj.Type,
			"paths", obj.Paths,
			"audience", obj.Audience,
			"file_permission", fmt.Sprintf("%o", obj.FilePermission),
		)
	}

	if len(req.CurrentObjectVersion) > 0 {
		s.logger.Debug("current object versions",
			"request_id", requestID,
			"count", len(req.CurrentObjectVersion),
		)
		for _, objVer := range req.CurrentObjectVersion {
			s.logger.Trace("current object version",
				"request_id", requestID,
				"id", objVer.Id,
				"version", objVer.Version,
			)
		}
	}

	var spireProvider *provider.Provider

	s.logger.Debug("creating provider with client pool",
		"request_id", requestID,
	)
	spireProvider = provider.NewProviderWithClientPool(
		s.logger.Named("provider"),
		s.hmacGenerator,
		podContext,
		s.clientPool,
	)

	resp, err := spireProvider.HandleMountRequest(ctx, cfg, s.flagsConfig)
	if err != nil {
		duration := time.Since(start)
		s.logger.Error("failed to handle mount request",
			"request_id", requestID,
			"error", err,
			"duration_ms", duration.Milliseconds(),
			"pod_namespace", podNamespace,
			"pod_name", podName,
			"trust_domain", cfg.Parameters.TrustDomain,
		)
		metrics.RecordMountRequest("error", duration.Seconds(), podContext)
		return nil, fmt.Errorf("error handling mount request: %w", err)
	}

	duration := time.Since(start)
	s.logger.Info("mount request completed successfully",
		"request_id", requestID,
		"target_path", req.GetTargetPath(),
		"file_count", len(resp.GetFiles()),
		"object_count", len(resp.GetObjectVersion()),
		"duration_ms", duration.Milliseconds(),
		"pod_namespace", podNamespace,
		"pod_name", podName,
	)

	for _, file := range resp.GetFiles() {
		s.logger.Debug("file created",
			"request_id", requestID,
			"path", file.Path,
			"mode", fmt.Sprintf("%o", file.Mode),
			"size", len(file.Contents),
		)
	}

	for _, objVer := range resp.GetObjectVersion() {
		s.logger.Debug("object version",
			"request_id", requestID,
			"id", objVer.Id,
			"version", objVer.Version,
		)
	}

	stats := s.clientPool.GetPoolStats()
	s.logger.Debug("client pool stats",
		"request_id", requestID,
		"total_clients", stats["total_clients"],
		"active_clients", stats["active_clients"],
		"total_refs", stats["total_refs"],
	)

	metrics.RecordMountRequest("success", duration.Seconds(), podContext)

	return resp, nil
}

func (s *Server) Shutdown() error {
	s.logger.Info("shutting down server")

	if err := s.clientPool.Shutdown(); err != nil {
		s.logger.Error("failed to shutdown client pool", "error", err)
		return err
	}

	return nil
}

func generateRequestID() string {
	return fmt.Sprintf("%d", time.Now().UnixNano())
}
</file>

<file path="version/version_test.go">
// internal/version/version_test.go
package version

import (
	"encoding/json"
	"testing"
)

func TestGetVersion(t *testing.T) {
	// Set test values
	BuildVersion = "v1.2.3"
	BuildDate = "2024-01-01"
	GoVersion = "1.21"

	versionStr, err := GetVersion()
	if err != nil {
		t.Fatalf("GetVersion() error = %v", err)
	}

	var pv providerVersion
	if err := json.Unmarshal([]byte(versionStr), &pv); err != nil {
		t.Fatalf("Failed to unmarshal version JSON: %v", err)
	}

	if pv.Version != BuildVersion {
		t.Errorf("Version = %v, want %v", pv.Version, BuildVersion)
	}
	if pv.BuildDate != BuildDate {
		t.Errorf("BuildDate = %v, want %v", pv.BuildDate, BuildDate)
	}
	if pv.GoVersion != GoVersion {
		t.Errorf("GoVersion = %v, want %v", pv.GoVersion, GoVersion)
	}
	if pv.MinDriverVersion != minDriverVersion {
		t.Errorf("MinDriverVersion = %v, want %v", pv.MinDriverVersion, minDriverVersion)
	}
}

func TestGetVersion_EmptyValues(t *testing.T) {
	// Reset to empty values
	BuildVersion = ""
	BuildDate = ""
	GoVersion = ""

	versionStr, err := GetVersion()
	if err != nil {
		t.Fatalf("GetVersion() error = %v", err)
	}

	var pv providerVersion
	if err := json.Unmarshal([]byte(versionStr), &pv); err != nil {
		t.Fatalf("Failed to unmarshal version JSON: %v", err)
	}

	if pv.Version != "" {
		t.Errorf("Expected empty Version, got %v", pv.Version)
	}
	if pv.MinDriverVersion != minDriverVersion {
		t.Errorf("MinDriverVersion should always be %v, got %v", minDriverVersion, pv.MinDriverVersion)
	}
}

func TestMinDriverVersion(t *testing.T) {
	if minDriverVersion != "v0.0.1" {
		t.Errorf("minDriverVersion = %v, want v0.0.1", minDriverVersion)
	}
}
</file>

<file path="version/version.go">
package version

import (
	"encoding/json"
)

const minDriverVersion = "v0.0.1"

var (
	BuildDate string

	BuildVersion string

	GoVersion string
)

type providerVersion struct {
	Version          string `json:"version"`
	BuildDate        string `json:"buildDate"`
	GoVersion        string `json:"goVersion"`
	MinDriverVersion string `json:"minDriverVersion"`
}

func GetVersion() (string, error) {
	pv := providerVersion{
		Version:          BuildVersion,
		BuildDate:        BuildDate,
		GoVersion:        GoVersion,
		MinDriverVersion: minDriverVersion,
	}

	res, err := json.Marshal(pv)
	if err != nil {
		return "", err
	}

	return string(res), nil
}
</file>

</files>
